{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Paper approach\n",
    "This notebook implements the method described in the research paper. The approach involves two main stages:\n",
    "\n",
    "Feature Engineering:\n",
    "\n",
    "Filtering features:\n",
    "Selecting the most informative events based on a relevance metric.\n",
    "Extracting sets of features: Mining recurring sets of events using an estimator of the Longest Common Subsequence (LCSS) algorithm.\n",
    "\n",
    "Classification:\n",
    "Building a classifier based on Naive Bayes, (the time-windows and classifiers for each time-window were not implemented since it was advised to put more effort in our own model implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>vehicles_sequence</th>\n",
       "      <th>events_sequence</th>\n",
       "      <th>seconds_to_incident_sequence</th>\n",
       "      <th>approx_lat</th>\n",
       "      <th>approx_lon</th>\n",
       "      <th>train_kph_sequence</th>\n",
       "      <th>dj_ac_state_sequence</th>\n",
       "      <th>dj_dc_state_sequence</th>\n",
       "      <th>incident_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4432881</td>\n",
       "      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n",
       "      <td>[2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...</td>\n",
       "      <td>[-5510, -5510, -5507, -5507, -5506, -5506, -55...</td>\n",
       "      <td>50.876601</td>\n",
       "      <td>4.718143</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4432943</td>\n",
       "      <td>[526, 526, 526, 526, 526, 526, 526, 526, 526, ...</td>\n",
       "      <td>[2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...</td>\n",
       "      <td>[-8573, -8573, -8032, -8032, -8032, -7859, -61...</td>\n",
       "      <td>51.037435</td>\n",
       "      <td>4.431218</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id                                  vehicles_sequence  \\\n",
       "0      4432881  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n",
       "1      4432943  [526, 526, 526, 526, 526, 526, 526, 526, 526, ...   \n",
       "\n",
       "                                     events_sequence  \\\n",
       "0  [2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...   \n",
       "1  [2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...   \n",
       "\n",
       "                        seconds_to_incident_sequence  approx_lat  approx_lon  \\\n",
       "0  [-5510, -5510, -5507, -5507, -5506, -5506, -55...   50.876601    4.718143   \n",
       "1  [-8573, -8573, -8032, -8032, -8032, -7859, -61...   51.037435    4.431218   \n",
       "\n",
       "                                  train_kph_sequence  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...   \n",
       "\n",
       "                                dj_ac_state_sequence  \\\n",
       "0  [False, False, False, False, False, False, Fal...   \n",
       "1  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                dj_dc_state_sequence  incident_type  \n",
       "0  [False, False, False, False, False, False, Fal...              4  \n",
       "1  [True, True, True, True, True, True, True, Tru...             13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting `events_sequence` and `vehicles_sequence` from string to list of ints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['events_sequence'] = df['events_sequence'].apply(ast.literal_eval)\n",
    "df['vehicles_sequence'] = df['vehicles_sequence'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next calculate total frequency of events in total and frequency of events within each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total occurrences of each event across all classes\n",
    "total_event_counts = Counter()\n",
    "# Occurrences of each event within each class\n",
    "event_counts_per_class = {}\n",
    "\n",
    "for incident_type in df['incident_type'].unique():\n",
    "    event_counts_per_class[incident_type] = Counter()\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    events = set(row['events_sequence'])  # Use set to avoid duplicate events in the same sequence\n",
    "    incident_type = row['incident_type']\n",
    "    total_event_counts.update(events)\n",
    "    event_counts_per_class[incident_type].update(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r is described in the paper as: $$ r = \\frac{h_{\\text{in class}}}{h_{\\text{in all classes}}} $$ \n",
    "where â„Ž is an event frequency in class or in all classes. This metric is calculated:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_metric = {}\n",
    "\n",
    "for event in total_event_counts:\n",
    "    #The maximum h_in class is used\n",
    "    max_h_in_class = max([event_counts_per_class[cls][event] for cls in event_counts_per_class])\n",
    "    h_in_all_classes = total_event_counts[event]\n",
    "    relevance_metric[event] = max_h_in_class / h_in_all_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can define a threshold and keep the events equal and over the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events selected with r >= 0.5: 635\n"
     ]
    }
   ],
   "source": [
    "# Set initial threshold\n",
    "tr = 0.5\n",
    "\n",
    "selected_events = [event for event, r in relevance_metric.items() if r >= tr]\n",
    "\n",
    "print(f\"Number of events selected with r >= {tr}: {len(selected_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we separate the events in those that were not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events not selected\n",
    "remaining_events = [event for event in total_event_counts if event not in selected_events]\n",
    "\n",
    "# Placeholder for events that pass the OaT procedure\n",
    "additional_events = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is made to calculate the f1 score for a specific subset of the total events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(events_subset):\n",
    "    # Prepare the data\n",
    "    df['filtered_events'] = df['events_sequence'].apply(lambda x: [e for e in x if e in events_subset])\n",
    "    \n",
    "    # Convert event lists to strings for vectorization\n",
    "    df['events_str'] = df['filtered_events'].apply(lambda x: ' '.join(map(str, x)))\n",
    "    \n",
    "    # Vectorize the events\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['events_str'])\n",
    "    y = df['incident_type']\n",
    "    \n",
    "    # Perform stratified 4-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    return avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_events = selected_events.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over all events that were filtered out, find the ones that when included , lead to an average f1 score of 0.6 or greater and include them in the `current_events` which are used to make the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial F1-score with selected events: 0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OaT Procedure:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                        | 108/282 [07:44<12:28,  4.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m tqdm(remaining_events, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOaT Procedure\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     10\u001b[0m     temp_events \u001b[38;5;241m=\u001b[39m current_events \u001b[38;5;241m+\u001b[39m [event]\n\u001b[1;32m---> 11\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m evaluate_classifier(temp_events)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f1 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m:\n\u001b[0;32m     13\u001b[0m         current_events\u001b[38;5;241m.\u001b[39mappend(event)\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mevaluate_classifier\u001b[1;34m(events_subset)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_classifier\u001b[39m(events_subset):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Prepare the data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_events\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_sequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m events_subset])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert event lists to strings for vectorization\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_str\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_events\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, x)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mevaluate_classifier.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_classifier\u001b[39m(events_subset):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Prepare the data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_events\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_sequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m events_subset])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert event lists to strings for vectorization\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_str\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_events\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, x)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Current set of events\n",
    "current_events = selected_events.copy()\n",
    "\n",
    "# Evaluate classifier with current events\n",
    "current_f1_score = evaluate_classifier(current_events)\n",
    "print(f\"Initial F1-score with selected events: {current_f1_score:.4f}\")\n",
    "\n",
    "# Iterate over remaining events\n",
    "for event in tqdm(remaining_events, desc='OaT Procedure'):\n",
    "    temp_events = current_events + [event]\n",
    "    f1 = evaluate_classifier(temp_events)\n",
    "    if f1 >= 0.6:\n",
    "        current_events.append(event)\n",
    "        additional_events.append(event)\n",
    "        current_f1_score = f1  # Update the current F1-score\n",
    "\n",
    "print(f\"Final F1-score after OaT: {current_f1_score:.4f}\")\n",
    "print(f\"Number of additional events added: {len(additional_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count total event frequencies and filter out extremely rare events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count event frequencies\n",
    "event_counts = Counter([event for seq in df['events_sequence'] for event in seq])\n",
    "\n",
    "# Define a minimum frequency threshold\n",
    "min_event_frequency = 10  # Adjust based on dataset\n",
    "\n",
    "# Filter out rare events\n",
    "frequent_events = set([event for event, count in event_counts.items() if count >= min_event_frequency])\n",
    "\n",
    "# Update events_sequence by keeping only frequent events\n",
    "df['filtered_events_sequence'] = df['events_sequence'].apply(lambda seq: [event for event in seq if event in frequent_events])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for frequent itemset mining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df['filtered_events_sequence'].tolist()\n",
    "\n",
    "# Remove empty transactions\n",
    "transactions = [t for t in transactions if t]\n",
    "\n",
    "# Use TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_te = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the most frequent sequences using fpgrothw algorithm. However, due to huge cost and processing times, `max_length` is set to 2.\n",
    "Of course, the results will not be optimal, however, it is possible to run the notebook in our laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent itemsets found: 5380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993076</td>\n",
       "      <td>(2708)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985163</td>\n",
       "      <td>(4026)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941642</td>\n",
       "      <td>(4066)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934718</td>\n",
       "      <td>(4068)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907023</td>\n",
       "      <td>(4148)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support itemsets\n",
       "0  0.993076   (2708)\n",
       "1  0.985163   (4026)\n",
       "2  0.941642   (4066)\n",
       "3  0.934718   (4068)\n",
       "4  0.907023   (4148)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the FP-Growth algorithm to find frequent itemsets\n",
    "min_support = 0.05  # Adjust as needed based on dataset size\n",
    "\n",
    "frequent_itemsets = fpgrowth(df_te, min_support=min_support, use_colnames=True, max_len=2)\n",
    "\n",
    "print(f\"Number of frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "frequent_itemsets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the columns corresponding to each frequent sequence, checking if in a particular row the frequent sequence appers at least once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>vehicles_sequence</th>\n",
       "      <th>events_sequence</th>\n",
       "      <th>seconds_to_incident_sequence</th>\n",
       "      <th>approx_lat</th>\n",
       "      <th>approx_lon</th>\n",
       "      <th>train_kph_sequence</th>\n",
       "      <th>dj_ac_state_sequence</th>\n",
       "      <th>dj_dc_state_sequence</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>...</th>\n",
       "      <th>itemset_5370</th>\n",
       "      <th>itemset_5371</th>\n",
       "      <th>itemset_5372</th>\n",
       "      <th>itemset_5373</th>\n",
       "      <th>itemset_5374</th>\n",
       "      <th>itemset_5375</th>\n",
       "      <th>itemset_5376</th>\n",
       "      <th>itemset_5377</th>\n",
       "      <th>itemset_5378</th>\n",
       "      <th>itemset_5379</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4432881</td>\n",
       "      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n",
       "      <td>[2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...</td>\n",
       "      <td>[-5510, -5510, -5507, -5507, -5506, -5506, -55...</td>\n",
       "      <td>50.876601</td>\n",
       "      <td>4.718143</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4432943</td>\n",
       "      <td>[526, 526, 526, 526, 526, 526, 526, 526, 526, ...</td>\n",
       "      <td>[2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...</td>\n",
       "      <td>[-8573, -8573, -8032, -8032, -8032, -7859, -61...</td>\n",
       "      <td>51.037435</td>\n",
       "      <td>4.431218</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4432955</td>\n",
       "      <td>[592, 592, 592, 592, 592, 592, 592, 592, 592, ...</td>\n",
       "      <td>[4394, 1566, 1570, 4114, 4168, 4168, 4156, 406...</td>\n",
       "      <td>[-12291, -12291, -12291, -10932, -10932, -1091...</td>\n",
       "      <td>50.864083</td>\n",
       "      <td>4.162115</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, True, True, False, True, Tr...</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4433021</td>\n",
       "      <td>[576, 576, 576, 576, 576, 576, 576, 576, 576, ...</td>\n",
       "      <td>[4066, 4066, 4066, 4066, 4068, 2742, 4026, 270...</td>\n",
       "      <td>[-14351, -14204, -13890, -13383, -12739, -1243...</td>\n",
       "      <td>51.183220</td>\n",
       "      <td>4.276025</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433129</td>\n",
       "      <td>[634, 634, 634, 634, 634, 634, 634, 634, 634, ...</td>\n",
       "      <td>[4002, 4032, 4028, 2852, 4026, 4110, 2742, 285...</td>\n",
       "      <td>[-224, -224, -223, -222, -222, -222, -220, -22...</td>\n",
       "      <td>50.818727</td>\n",
       "      <td>3.253601</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id                                  vehicles_sequence  \\\n",
       "0      4432881  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n",
       "1      4432943  [526, 526, 526, 526, 526, 526, 526, 526, 526, ...   \n",
       "2      4432955  [592, 592, 592, 592, 592, 592, 592, 592, 592, ...   \n",
       "3      4433021  [576, 576, 576, 576, 576, 576, 576, 576, 576, ...   \n",
       "4      4433129  [634, 634, 634, 634, 634, 634, 634, 634, 634, ...   \n",
       "\n",
       "                                     events_sequence  \\\n",
       "0  [2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...   \n",
       "1  [2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...   \n",
       "2  [4394, 1566, 1570, 4114, 4168, 4168, 4156, 406...   \n",
       "3  [4066, 4066, 4066, 4066, 4068, 2742, 4026, 270...   \n",
       "4  [4002, 4032, 4028, 2852, 4026, 4110, 2742, 285...   \n",
       "\n",
       "                        seconds_to_incident_sequence  approx_lat  approx_lon  \\\n",
       "0  [-5510, -5510, -5507, -5507, -5506, -5506, -55...   50.876601    4.718143   \n",
       "1  [-8573, -8573, -8032, -8032, -8032, -7859, -61...   51.037435    4.431218   \n",
       "2  [-12291, -12291, -12291, -10932, -10932, -1091...   50.864083    4.162115   \n",
       "3  [-14351, -14204, -13890, -13383, -12739, -1243...   51.183220    4.276025   \n",
       "4  [-224, -224, -223, -222, -222, -222, -220, -22...   50.818727    3.253601   \n",
       "\n",
       "                                  train_kph_sequence  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                dj_ac_state_sequence  \\\n",
       "0  [False, False, False, False, False, False, Fal...   \n",
       "1  [False, False, False, False, False, False, Fal...   \n",
       "2  [False, False, False, False, False, False, Fal...   \n",
       "3  [False, False, False, False, False, False, Fal...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                dj_dc_state_sequence  incident_type  ...  \\\n",
       "0  [False, False, False, False, False, False, Fal...              4  ...   \n",
       "1  [True, True, True, True, True, True, True, Tru...             13  ...   \n",
       "2  [True, True, True, True, True, False, True, Tr...             14  ...   \n",
       "3  [True, True, True, True, True, True, True, Tru...              2  ...   \n",
       "4  [False, False, False, False, False, False, Fal...             14  ...   \n",
       "\n",
       "  itemset_5370  itemset_5371  itemset_5372  itemset_5373  itemset_5374  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            0             0             0             0             0   \n",
       "3            0             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   itemset_5375  itemset_5376  itemset_5377  itemset_5378  itemset_5379  \n",
       "0             0             0             0             0             0  \n",
       "1             0             0             0             0             0  \n",
       "2             0             0             0             0             0  \n",
       "3             0             0             0             0             0  \n",
       "4             0             0             0             0             0  \n",
       "\n",
       "[5 rows x 5391 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert frequent itemsets into a list of tuples\n",
    "frequent_sets = [tuple(tup) for tup in frequent_itemsets['itemsets']]\n",
    "\n",
    "# Function that checks if the exact sequence of events from the tuple is found in the list\n",
    "def is_tuple_in_list(seq, lst):\n",
    "    # Convert the tuple to a list to make it easier to check for a subsequence\n",
    "    seq_list = list(seq)\n",
    "    # Iterate through the list and check if the subsequence appears\n",
    "    for i in range(len(lst) - len(seq_list) + 1):\n",
    "        if lst[i:i+len(seq_list)] == seq_list:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Create new features for each frequent itemset in one batch\n",
    "new_columns = {\n",
    "    f'itemset_{idx}': df['events_sequence'].apply(lambda x: int(is_tuple_in_list(itemset, x)))\n",
    "    for idx, itemset in enumerate(frequent_sets)\n",
    "}\n",
    "\n",
    "# Add all new features to the DataFrame at once\n",
    "df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "Now we can evaluate the model on the f1 metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom scoring function with zero_division parameter\n",
    "def custom_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Wrap the custom scoring function using make_scorer\n",
    "f1_scorer = make_scorer(custom_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset_0</th>\n",
       "      <th>itemset_1</th>\n",
       "      <th>itemset_2</th>\n",
       "      <th>itemset_3</th>\n",
       "      <th>itemset_4</th>\n",
       "      <th>itemset_5</th>\n",
       "      <th>itemset_6</th>\n",
       "      <th>itemset_7</th>\n",
       "      <th>itemset_8</th>\n",
       "      <th>itemset_9</th>\n",
       "      <th>...</th>\n",
       "      <th>itemset_5370</th>\n",
       "      <th>itemset_5371</th>\n",
       "      <th>itemset_5372</th>\n",
       "      <th>itemset_5373</th>\n",
       "      <th>itemset_5374</th>\n",
       "      <th>itemset_5375</th>\n",
       "      <th>itemset_5376</th>\n",
       "      <th>itemset_5377</th>\n",
       "      <th>itemset_5378</th>\n",
       "      <th>itemset_5379</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 5380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemset_0  itemset_1  itemset_2  itemset_3  itemset_4  itemset_5  \\\n",
       "0          1          1          1          1          1          1   \n",
       "1          1          1          1          1          1          1   \n",
       "\n",
       "   itemset_6  itemset_7  itemset_8  itemset_9  ...  itemset_5370  \\\n",
       "0          1          1          1          1  ...             0   \n",
       "1          1          1          1          0  ...             0   \n",
       "\n",
       "   itemset_5371  itemset_5372  itemset_5373  itemset_5374  itemset_5375  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "\n",
       "   itemset_5376  itemset_5377  itemset_5378  itemset_5379  \n",
       "0             0             0             0             0  \n",
       "1             0             0             0             0  \n",
       "\n",
       "[2 rows x 5380 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.incident_type.copy()\n",
    "class_counts = target.value_counts()\n",
    "max_class_count = max(class_counts.values)\n",
    "sampling_strategy_cross_val = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
    "                     for i in range(len(class_counts.index)) if class_counts.values[i] < max_class_count}\n",
    "train_data = df.drop(columns=['incident_id', 'vehicles_sequence', 'events_sequence',\n",
    "       'seconds_to_incident_sequence', 'approx_lat', 'approx_lon',\n",
    "       'train_kph_sequence', 'dj_ac_state_sequence', 'dj_dc_state_sequence',\n",
    "       'incident_type','filtered_events_sequence']).copy()\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51069358 0.56184167 0.50612084 0.5055799 ]\n",
      "0.5210589972442037\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(MultinomialNB(alpha=1e-1, fit_prior=False),\n",
    "                         train_data, target,\n",
    "                        cv=4, scoring=f1_scorer,n_jobs = -1)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with dummy model\n",
    "Next we create dummy classifier to see if our model brings some value. With parameter `stratified`, the classifier generates predictions by randomly sampling the classes in a way that respects the class distribution. For example, if the training set contains 70% of samples labeled as `0` and 30% labeled as `1`, the classifier will predict 0 approximately 70% of the time and 1 approximately 30% of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "C:\\Users\\stef4\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20793466 0.16601656 0.18343041 0.18821455]\n",
      "0.18639904722815026\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(DummyClassifier(strategy=\"stratified\"),\n",
    "                         train_data, target,\n",
    "                        cv=4, scoring=f1_scorer,n_jobs = -1)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
