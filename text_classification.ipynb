{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee",
      "metadata": {
        "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee"
      },
      "source": [
        "# Text classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58",
      "metadata": {
        "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58"
      },
      "source": [
        "Manually remove the first ';' from the first row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "9a3763ac-3a33-41fc-d0c7-98a8803dd5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "224      4443537  [673, 673, 673, 673, 673, 673, 673, 673, 673, ...   \n",
              "922      4607225  [1066, 1066, 1066, 1066, 1066, 1066, 1066, 106...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "224  [2742, 3632, 4120, 2682, 4070, 2956, 2956, 295...   \n",
              "922  [2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "224  [-11919, -11911, -11901, -11900, -11879, -1186...   50.875503   \n",
              "922  [-14347, -14344, -14333, -14328, -14319, -1430...   50.624433   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "224    4.561848  [0.0, 0.0, 0.0, 0.0, 18.5, 19.6, 18.5, 22.5, 2...   \n",
              "922    4.608428  [40.2, 44.6, 68.5, 75.5, 79.2, 81.1, 81.6, 81....   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "224  [False, False, False, False, False, False, Fal...   \n",
              "922  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "224  [True, True, True, True, True, True, True, Tru...              2  \n",
              "922  [True, True, True, True, True, True, True, Tru...              9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e38eef49-30e9-429d-a7f8-7facc0f436ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>4443537</td>\n",
              "      <td>[673, 673, 673, 673, 673, 673, 673, 673, 673, ...</td>\n",
              "      <td>[2742, 3632, 4120, 2682, 4070, 2956, 2956, 295...</td>\n",
              "      <td>[-11919, -11911, -11901, -11900, -11879, -1186...</td>\n",
              "      <td>50.875503</td>\n",
              "      <td>4.561848</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 18.5, 19.6, 18.5, 22.5, 2...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>4607225</td>\n",
              "      <td>[1066, 1066, 1066, 1066, 1066, 1066, 1066, 106...</td>\n",
              "      <td>[2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14347, -14344, -14333, -14328, -14319, -1430...</td>\n",
              "      <td>50.624433</td>\n",
              "      <td>4.608428</td>\n",
              "      <td>[40.2, 44.6, 68.5, 75.5, 79.2, 81.1, 81.6, 81....</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e38eef49-30e9-429d-a7f8-7facc0f436ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e38eef49-30e9-429d-a7f8-7facc0f436ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e38eef49-30e9-429d-a7f8-7facc0f436ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0b81cbc-493f-4c1d-87ed-0b128cc9489c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0b81cbc-493f-4c1d-87ed-0b128cc9489c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0b81cbc-493f-4c1d-87ed-0b128cc9489c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115744,\n        \"min\": 4443537,\n        \"max\": 4607225,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4607225,\n          4443537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089, 1089]\",\n          \"[673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 673, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 4394, 152, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3234, 2708, 4026, 4016, 4026, 4020, 3256, 3354, 2564, 4168, 4168, 4156, 4066, 4066, 4066, 4066, 4066, 4066, 3658, 4068, 4066, 4066, 4066, 4068, 4068, 4066, 4066, 4066, 4066, 3354, 4066, 3658, 4066, 3658, 4066, 4068, 4066, 2742, 4148, 2708, 4026, 4020, 4066, 4120, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 148, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3632, 4066, 4070, 2708, 2742, 4148, 3632, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 148, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4066, 4066, 4066, 4066, 2742, 4148, 4026, 4026, 2708, 4020, 3256, 3254, 3254, 3354, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2564, 690, 2554, 4168, 2956, 2956, 4168, 4156, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2682, 2956, 2956, 2956, 2956, 4180, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4180, 2956, 2682, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4180, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 3224, 4068, 3636, 3658, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 3008, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 3364, 3354, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2708, 3234, 4016, 4026, 4026, 4020, 4068, 4068, 3658, 4066, 3658, 4066, 4066, 4068, 3658, 4068, 4068, 4016, 4068, 4068, 4068, 4066, 4068, 4066, 4066, 4066, 4066, 4066, 4068, 4068, 4068, 4068, 4068, 4026, 4016, 4026, 4020, 3256, 3364, 3354, 3658, 2564, 690, 4168, 4168, 4156, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 4068, 4066, 4066, 4066, 4068, 4068, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 3354, 4066, 4066, 4066, 3658, 4068, 3658, 4066, 4026, 4016, 4026, 4020, 4066, 3658, 4066, 4068, 4068, 3658, 4068, 3658, 4066, 4066, 4066, 4016, 4066, 4066, 4066, 4068, 4066, 4068, 4068, 4068, 4068, 4068, 3658]\",\n          \"[2742, 3632, 4120, 2682, 4070, 2956, 2956, 2956, 2956, 2956, 4120, 2956, 2956, 2956, 2956, 4068, 2708, 4026, 4016, 4020, 4066, 4068, 2742, 4026, 2708, 4020, 4026, 3632, 4120, 2956, 4066, 2708, 4016, 4026, 4020, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4020, 4068, 3530, 4394, 4016, 4016, 4066, 2742, 4026, 4148, 2708, 4020, 3632, 4120, 4120, 4120, 4066, 4068, 2708, 4070, 3234, 4026, 4016, 4026, 4020, 4068, 2742, 4026, 2708, 4026, 4020, 4120, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 374, 4394, 4066, 3636, 3658, 4066, 3636, 3658, 2708, 3548, 4026, 4032, 2740, 4054, 3548, 4394, 3534, 374, 4030, 4394, 4026, 4020, 4120, 4066, 3636, 3658, 4068, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 4066, 2708, 4024, 3506, 3506, 3506, 3506, 3506, 3506, 3506, 3506, 3506, 4024, 2742, 4024, 3506, 3506, 3636, 3658, 2742]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-14347, -14344, -14333, -14328, -14319, -14300, -14296, -14294, -14283, -14259, -14230, -14230, -14192, -14169, -14162, -14157, -14142, -14131, -14116, -14091, -14075, -14067, -14021, -13980, -13958, -13942, -13918, -13894, -13872, -13869, -13867, -13857, -13849, -13829, -13817, -13814, -13788, -13788, -13784, -13772, -13757, -13742, -13735, -13705, -13694, -13694, -13655, -13621, -13605, -13588, -13580, -13504, -13492, -13492, -13448, -13395, -13383, -13369, -13346, -13335, -13321, -13307, -13293, -13286, -13276, -13248, -13235, -13235, -13168, -13151, -13132, -13121, -13118, -13106, -13091, -13072, -13053, -13048, -13043, -13006, -13004, -12964, -12962, -12947, -12920, -12870, -12844, -12810, -12802, -12788, -12780, -12747, -12734, -12727, -12726, -11595, -11594, -11594, -11592, -11578, -11430, -10948, -10938, -10905, -10902, -10632, -10354, -10138, -9536, -9267, -8243, -8220, -7520, -7012, -6848, -6674, -6523, -6180, -6017, -5790, -5660, -5507, -5326, -5233, -5167, -5041, -5006, -4570, -4200, -3924, -2996, -2996, -2994, -2994, -2993, -2857, -1823, -1818, -1766, -1762, -1735, -1732, -1728, -1710, -1704, -1702, -1695, -1672, -1667, -1663, -1641, -1634, -1629, -1582, -1573, -1515, -1489, -1455, -1449, -1428, -1425, -1412, -1409, -1392, -1389, -1385, -1371, -1367, -1304, -1290, -1262, -1231, -1183, -1168, -1147, -1145, -1123, -1121, -1117, -1086, -1079, -1064, -1059, -1017, -1012, -1007, -989, -973, -968, -960, -947, -940, -937, -927, -924, -916, -898, -888, -886, -882, -877, -830, -799, -793, -789, -744, -684, -630, -584, -541, -506, -447, -390, -362, -358, -333, -296, -206, -165, -125, -89, -82, -75, -68, -27, 14, 109, 120, 178, 350, 359, 359, 618, 670, 714, 714, 732, 750, 799, 854, 879, 891, 908, 908, 955, 958, 971, 1010, 1017, 1060, 1062, 1111, 1132, 1132, 1211, 1213, 1227, 1257, 1272, 1272, 1338, 1345, 1351, 1358, 1393, 1397, 1405, 1409, 1422, 1461, 1490, 1490, 1548, 1558, 1612, 1630, 1630, 1658, 1683, 1715, 1725, 1727, 1756, 1774, 1774, 1831, 1851, 1863, 1912, 1932, 1932, 1974, 1977, 1993, 2001, 2007, 2008, 2044, 2061, 2072, 2077, 2163, 2167, 2181, 2194, 2214, 2216, 2264, 2264, 2333, 2410, 2421, 2435, 2458, 2460, 2471, 2493, 2496, 2497, 2507, 2512, 2540, 2558, 2590, 2608, 2610, 2628, 2654, 2672, 2707, 2717, 2719, 2731, 2762, 2771, 2782, 2804, 2813, 2832, 2849, 2858, 2879, 2891, 2899, 2909, 2943, 2951, 2965, 2980, 3014, 3055, 3083, 3094, 3105, 3116, 3156, 3164, 3200, 3208, 3209, 3245, 3254, 3259, 3308, 3310, 3312, 3377, 3386, 3404, 3446, 3453, 3464, 3472, 3525, 3543, 3565, 3571, 3572, -14262, -13709, -13508, -13252, -12738, -11600, -11600, -11599, -11598, -11597, -11597, -11582, -11496, -11495, -11435, -11133, -11077, -11028, -11014, -11007, -10983, -10962, -10951, -10951, -10942, -10942, -10941, -10922, -10909, -10907, -10900, -10865, -10859, -10845, -10818, -10781, -10754, -10718, -10706, -10693, -10681, -10669, -10636, -10614, -10568, -10555, -10542, -10537, -10524, -10523, -10512, -10498, -10486, -10463, -10447, -10437, -10410, -10397, -10388, -10357, -10338, -10255, -10241, -10211, -10169, -10142, -10125, -10061, -10034, -10023, -10021, -10011, -9982, -9974, -9944, -9934, -9926, -9891, -9880, -9843, -9829, -9823, -9786, -9776, -9740, -9738, -9719, -9684, -9646, -9601, -9599, -9598, -9571, -9563, -9540, -9521, -9467, -9464, -9459, -9440, -9432, -9427, -9417, -9410, -9363, -9342, -9320, -9312, -9303, -9271, -9047, -8992, -8974, -8937, -8918, -8894, -8881, -8866, -8864, -8815, -8812, -8768, -8766, -8759, -8723, -8704, -8682, -8663, -8654, -8634, -8597, -8578, -8569, -8512, -8505, -8502, -8501, -8461, -8454, -8449, -8415, -8406, -8404, -8360, -8352, -8312, -8303, -8295, -8290, -8272, -8247, -8223, -8194, -8187, -8171, -8149, -8139, -8131, -8127, -8119, -8098, -8081, -8071, -8049, -8025, -8016, -8005, -7967, -7956, -7954, -7909, -7889, -7866, -7847, -7843, -7824, -7795, -7778, -7750, -7744, -7733, -7731, -7727, -7706, -7701, -7689, -7686, -7650, -7644, -7615, -7600, -7558, -7552, -7523, -7302, -7302, -7258, -7242, -7233, -7141, -7137, -7126, -7109, -7083, -7082, -7076, -7069, -7062, -7049, -7016, -6997, -6997, -6928, -6910, -6901, -6852, -6818, -6818, -6768, -6764, -6732, -6724, -6710, -6704, -6678, -6654, -6654, -6584, -6575, -6572, -6527, -6483, -6483, -6433, -6398, -6384, -6353, -6285, -6245, -6239, -6235, -6230, -6184, -6168, -6168, -6102, -6086, -6083, -6021, -5996, -5929, -5926, -5880, -5872, -5839, -5830, -5828, -5818, -5794, -5772, -5735, -5705, -5690, -5664, -5647, -5605, -5577, -5571, -5565, -5559, -5541, -5511, -5436, -5372, -5351, -5338, -5336, -5330, -5329, -5317, -5273, -5237, -5171, -5125, -5085, -5080, -5045, -5010, -4965, -4957, -4889, -4886, -4883, -4874, -4870, -4860, -4856, -4854, -4846, -4840, -4833, -4817, -4810, -4804, -4790, -4777, -4774, -4771, -4740, -4734, -4720, -4713, -4688, -4686, -4671, -4665, -4636, -4627, -4597, -4574, -4477, -4390, -4341, -4337, -4320, -4318, -4316, -4298, -4294, -4275, -4271, -4268, -4255, -4252, -4204, -4171, -4112, -4107, -4091, -4087, -4077, -4074, -4060, -4055, -4052, -4037, -4032, -4010, -4006, -4002, -3980, -3977, -3973, -3937, -3928, -3594, -3594, -3507, -3505, -2999, -2999, -2998, -2997, -2861, -1519, -1493, -1266, -1235, -748, -545, -210, -169, 10, 116, 356, 666, 888, 1107, 1253, 1457, 1608, 1752, 1908, 2210, 2976, -14259, -13706, -13505, -13249, -12735, -11596, -11595, -11594, -11593, -11579, -11432, -11431, -11130, -10948, -10948, -10939, -10905, -10903, -10633, -10611, -10354, -10335, -10139, -10122, -9537, -9519, -9268, -9044, -8244, -7520, -7013, -6849, -6675, -6524, -6180, -6018, -5993, -5790, -5769, -5660, -5644, -5508, -5433, -5326, -5234, -5042, -4571, -4474, -4201, -4168, -3925, -2996, -2995, -2995, -2993, -2857, -1819, -1516, -1263, -744, -685, -542, -507, -207, 13, 119, 359, 669, 891, 1110, 1256, 1461, 1611, 1755, 1912, 2213, 2979, 3013]\",\n          \"[-11919, -11911, -11901, -11900, -11879, -11862, -11854, -11843, -11776, -11771, -11238, -11229, -11218, -11181, -11169, -11127, -11123, -10961, -10960, -10959, -10339, -10339, -4158, -4158, -4156, -4156, -4156, -2991, -2987, -2240, -2187, -2175, -1982, -1981, -1980, -1301, -1086, -870, -660, -454, -257, -3, 455, 1317, 3324, 3324, 3394, -11915, -11125, -10959, -10959, -10959, -10958, -10957, -10945, -10933, -10728, -10495, -10337, -10336, -10327, -10323, -10320, -4156, -4155, -4154, -4153, -2185, -1981, -1981, -1979, -1979, -1978, -1796, -1628, -1628, -1299, -1265, -1265, -1084, -1067, -1067, -868, -843, -843, -658, -626, -626, -452, -429, -429, -351, -351, -255, -211, -211, -1, 21, 21, 258, 361, 362, 362, 363, 367, 371, 371, 376, 456, 456, 456, 457, 458, 1023, 1319, 1347, 1347, 1596, 1618, 1618, 1882, 1912, 1912, 2452, 2474, 2474, 2840, 2931, 3060, 3064, 3074, 3084, 3090, 3091, 3096, 3124, 3133, 3135, 3140, 3192, 3207, 3218, 3220, 3390, 3390, 3395]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1775328214270104,\n        \"min\": 50.62443346932224,\n        \"max\": 50.87550279315068,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.62443346932224,\n          50.87550279315068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03293690109668978,\n        \"min\": 4.56184809109589,\n        \"max\": 4.60842790332937,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.60842790332937,\n          4.56184809109589\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[40.2, 44.6, 68.5, 75.5, 79.2, 81.1, 81.6, 81.7, 68.0, 0.0, 0.0, 0.0, 39.2, 82.3, 89.3, 89.8, 87.6, 85.7, 83.5, 80.2, 77.8, 77.6, 80.5, 79.9, 77.8, 78.5, 88.9, 87.2, 85.0, 85.0, 84.8, 84.3, 84.1, 83.2, 81.0, 80.6, 84.4, 84.6, 82.4, 78.2, 64.2, 58.9, 48.4, 0.0, 0.0, 0.0, 48.4, 89.4, 88.3, 86.7, 82.2, 0.0, 0.0, 0.0, 33.7, 92.3, 92.3, 92.5, 87.9, 86.1, 79.9, 75.1, 72.7, 67.2, 57.7, 0.0, 0.0, 0.0, 42.9, 42.9, 70.5, 83.7, 86.5, 85.8, 85.8, 86.8, 90.6, 90.6, 90.1, 85.4, 84.5, 78.3, 77.7, 75.7, 72.2, 43.2, 39.1, 31.8, 31.7, 31.5, 33.8, 16.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 52.2, 53.9, 55.0, 54.9, 0.0, 0.0, 0.1, 0.1, 0.0, 0.2, 0.0, 0.1, 0.1, 0.0, 0.2, 0.2, 0.1, 0.0, 0.0, 0.2, 0.1, 56.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 26.2, 28.9, 28.8, 30.4, 33.4, 33.5, 33.5, 33.9, 38.3, 38.8, 38.9, 25.9, 20.0, 15.2, 16.7, 16.9, 0.1, 0.0, 17.0, 30.5, 48.7, 48.4, 47.7, 47.8, 47.3, 46.5, 43.5, 34.0, 32.9, 32.1, 31.6, 0.1, 0.0, 15.1, 38.8, 40.9, 41.0, 41.0, 40.9, 41.2, 44.5, 45.9, 52.2, 52.3, 36.5, 38.5, 41.7, 55.9, 74.1, 79.6, 86.3, 89.5, 87.2, 86.3, 80.9, 77.0, 66.1, 42.6, 38.0, 37.1, 35.8, 34.8, 35.1, 33.5, 32.9, 31.6, 0.0, 0.0, 30.5, 34.5, 0.0, 0.0, 13.4, 35.9, 37.8, 38.0, 39.5, 64.1, 0.3, 0.0, 20.9, 73.6, 75.3, 74.5, 65.9, 27.2, 1.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 35.3, 53.7, 28.4, 1.0, 0.0, 0.0, 66.9, 73.6, 92.9, 123.9, 129.0, 109.3, 105.1, 1.6, 0.0, 0.0, 96.6, 93.7, 64.3, 1.1, 0.0, 0.0, 81.6, 84.6, 85.6, 87.8, 88.8, 89.7, 89.9, 90.0, 91.7, 0.5, 0.0, 0.0, 99.5, 115.6, 0.8, 0.0, 0.0, 17.5, 84.1, 98.3, 76.0, 70.8, 0.2, 0.0, 0.0, 79.3, 97.0, 90.8, 0.1, 0.0, 0.0, 69.8, 75.8, 102.2, 96.5, 87.2, 84.8, 39.6, 36.2, 40.2, 38.6, 36.8, 37.1, 37.2, 24.5, 0.2, 0.0, 0.0, 0.0, 35.4, 38.4, 35.9, 61.0, 88.9, 90.8, 100.7, 114.0, 115.9, 116.5, 109.1, 102.4, 58.5, 56.6, 55.3, 54.7, 55.8, 55.2, 57.7, 60.1, 102.8, 110.7, 111.8, 119.0, 128.2, 126.6, 125.7, 127.0, 123.8, 126.0, 127.1, 127.8, 127.5, 126.3, 118.1, 102.4, 66.4, 56.4, 32.6, 0.6, 0.0, 28.0, 82.0, 94.5, 101.2, 106.5, 130.0, 128.9, 129.4, 127.1, 126.8, 117.8, 116.5, 116.4, 123.8, 122.7, 121.5, 57.4, 57.1, 58.7, 60.2, 57.8, 56.3, 55.9, 54.9, 75.7, 114.5, 121.9, 122.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.2, 38.4, 38.0, 40.1, 42.0, 54.5, 54.5, 53.9, 53.9, 54.1, 54.7, 55.0, 54.9, 54.9, 88.5, 89.1, 90.1, 89.3, 87.3, 84.1, 90.6, 90.0, 89.9, 88.2, 70.0, 0.0, 0.0, 0.0, 19.6, 61.4, 71.5, 93.5, 94.8, 86.7, 85.3, 85.8, 85.0, 85.6, 83.8, 83.9, 71.8, 65.7, 0.0, 0.0, 86.8, 86.2, 86.9, 84.1, 0.1, 0.0, 16.0, 71.1, 80.8, 83.0, 90.4, 88.1, 87.8, 87.0, 87.2, 87.5, 88.2, 88.2, 85.8, 86.8, 87.0, 89.3, 88.8, 86.6, 86.7, 86.4, 83.9, 37.6, 21.8, 22.1, 22.1, 73.5, 74.1, 0.1, 0.0, 58.2, 62.9, 70.6, 83.9, 77.6, 75.7, 73.9, 73.2, 37.3, 38.2, 31.3, 26.4, 22.4, 0.0, 0.0, 0.0, 6.1, 32.5, 51.8, 58.2, 60.6, 73.9, 76.4, 100.6, 101.1, 117.2, 116.3, 111.1, 59.8, 56.7, 58.5, 52.9, 52.1, 53.7, 56.3, 58.5, 56.5, 108.9, 113.3, 114.1, 115.8, 129.0, 130.3, 130.4, 119.3, 120.6, 120.6, 128.7, 125.8, 122.2, 127.8, 125.2, 120.8, 92.1, 0.1, 0.0, 6.2, 32.3, 77.9, 109.4, 118.4, 126.7, 130.0, 130.2, 127.7, 115.9, 111.5, 111.0, 121.7, 124.7, 130.2, 129.4, 120.2, 117.6, 57.9, 49.3, 54.8, 56.8, 56.3, 56.2, 60.9, 61.4, 94.5, 97.4, 94.4, 92.5, 89.4, 86.9, 87.5, 87.5, 87.6, 44.2, 35.7, 38.1, 39.8, 33.9, 34.7, 0.0, 0.0, 0.0, 0.0, 19.4, 33.8, 36.0, 35.4, 36.8, 43.9, 99.8, 100.9, 101.4, 100.2, 92.0, 76.0, 0.0, 0.0, 0.0, 88.6, 113.0, 112.7, 0.0, 0.0, 0.0, 35.5, 51.0, 125.6, 125.9, 75.8, 47.6, 0.1, 0.0, 0.0, 102.4, 112.8, 113.4, 0.1, 0.0, 0.0, 61.3, 28.3, 20.7, 13.8, 31.8, 107.5, 112.4, 116.2, 121.2, 0.1, 0.0, 0.0, 40.6, 84.2, 89.6, 0.0, 0.0, 85.8, 88.8, 127.0, 126.7, 124.7, 120.9, 120.2, 83.2, 0.0, 0.0, 41.3, 103.5, 90.0, 0.1, 0.0, 17.0, 79.8, 86.0, 89.9, 93.5, 76.7, 0.1, 0.0, 90.1, 88.6, 63.4, 60.0, 56.1, 55.9, 46.5, 34.7, 0.0, 0.0, 32.8, 39.1, 38.6, 0.0, 0.0, 15.0, 27.4, 51.2, 51.9, 52.7, 54.6, 60.5, 72.3, 76.8, 79.1, 86.0, 89.7, 90.1, 86.0, 85.0, 80.0, 71.0, 61.2, 61.0, 59.6, 56.9, 55.7, 45.7, 46.6, 52.5, 53.7, 51.2, 48.2, 38.5, 35.8, 14.6, 0.0, 0.0, 16.1, 38.3, 39.4, 40.5, 40.3, 40.3, 42.8, 43.3, 46.6, 46.6, 46.3, 44.7, 44.2, 0.0, 0.0, 25.2, 40.1, 48.8, 48.4, 48.4, 47.9, 34.6, 34.9, 34.0, 35.3, 36.5, 34.5, 33.6, 33.1, 36.9, 37.4, 37.3, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.4, 0.0, 0.0, 0.1, 0.8, 0.0, 1.5, 0.0, 0.0, 0.0, 1.5, 2.7, 1.8, 1.1, 1.4, 0.4, 0.5, 0.8, 1.3, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.3, 54.0, 53.9, 55.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 56.1, 0.1, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.0, 0.0, 0.1, 0.0, 0.8, 1.4, 0.0, 0.0, 0.0, 1.5, 2.2, 1.8, 0.8, 1.8, 0.4, 0.3, 0.5, 0.9, 0.0]\",\n          \"[0.0, 0.0, 0.0, 0.0, 18.5, 19.6, 18.5, 22.5, 24.8, 25.1, 0.0, 2.9, 16.4, 28.5, 28.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.0, 0.0, 108.265625, 108.34375, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.\n",
        "                                 size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            # Collect probability predictions for multiclass\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        # Convert predictions to a 3D array: (num_samples, num_classes, num_models)\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        # Define fitness function for genetic algorithm\n",
        "        def fitness(weights):\n",
        "            # Apply weights to model predictions\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            # Get the predicted class with the highest weighted probability\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            # Return negative weighted F1 score for optimization\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        # Genetic algorithm for weight optimization\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        # Store optimized weights\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        # Generate predictions for the input data\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)  # Transforming string into actual list\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            # Step 2: Sort events by frequency and calculate percentages\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)  # Ensure event_type is string\n",
        "\n",
        "            # Step 3: Filter events with percentage <= 85%\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            # Step 4: Clean the 'events_sequence' column\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)  # Convert string to list\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])  # Filter low-frequency events\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)  # Remove brackets and commas\n",
        "            )\n",
        "\n",
        "            # Step 5: Extract the target column\n",
        "            self.y = df['incident_type'].copy()  # Separate target column\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n",
        "\n",
        "  def representation_b(self, df):\n",
        "\n",
        "    before_incident = []\n",
        "    after_incident = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Convertir las cadenas a listas\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        # Filtrar eventos antes del incidente (t <= 0)\n",
        "        before_events = \" \".join([str(event) for event, time in zip(events, seconds) if time <= 0])\n",
        "        if before_events:\n",
        "            before_incident.append({\n",
        "                \"events_sequence\": before_events,\n",
        "                \"class\": incident_type\n",
        "            })\n",
        "\n",
        "        # Filtrar eventos después del incidente (t > 0)\n",
        "        after_events = \" \".join([str(event) for event, time in zip(events, seconds) if time > 0])\n",
        "        if after_events:\n",
        "            after_incident.append({\n",
        "                \"events_sequence\": after_events,\n",
        "                \"class\": 100\n",
        "            })\n",
        "\n",
        "    # Convertir listas a DataFrames\n",
        "    before_df = pd.DataFrame(before_incident)\n",
        "    after_df = pd.DataFrame(after_incident)\n",
        "\n",
        "    return before_df, after_df\n",
        "\n",
        "\n",
        "  def representation_c(df, sequence_length=30):\n",
        "\n",
        "    overlapping_sequences = []\n",
        "    step = sequence_length // 2  # Paso entre ventanas solapadas\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Convertir eventos y tiempos en listas\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        # Generar cadenas antes del incidente\n",
        "        for i in range(0, len(events) - sequence_length + 1, step):\n",
        "            sequence = events[i:i + sequence_length]\n",
        "            seconds_slice = seconds[i:i + sequence_length]\n",
        "\n",
        "            # Verificar si la mayoría de los tiempos son antes o después del incidente\n",
        "            if all(sec <= 0 for sec in seconds_slice):\n",
        "                sequence_class = incident_type\n",
        "            elif all(sec > 0 for sec in seconds_slice):\n",
        "                sequence_class = 100\n",
        "            else:\n",
        "                # Mezcla de antes y después del incidente, no considerar esta secuencia\n",
        "                continue\n",
        "\n",
        "            overlapping_sequences.append({\"sequence\": sequence, \"class\": sequence_class})\n",
        "\n",
        "    # Crear un nuevo DataFrame con las secuencias generadas\n",
        "    sequences_df = pd.DataFrame(overlapping_sequences)\n",
        "    return sequences_df\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.le = LabelEncoder().fit(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
        "        self.y_train = self.le.transform(self.y_train)\n",
        "        self.y_test = self.le.transform(self.y_test)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            #\"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            #\"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            #\"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1)\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False),\n",
        "        }\n",
        "\n",
        "\n",
        "    def drop_small_classes(self, X, y, min_instances=25):\n",
        "\n",
        "        class_counts = y.value_counts()\n",
        "\n",
        "        valid_classes = class_counts[class_counts >= min_instances].index\n",
        "\n",
        "        mask = y.isin(valid_classes)\n",
        "        X_filtered = X[mask]\n",
        "        y_filtered = y[mask]\n",
        "\n",
        "        X_filtered.reset_index(drop=True, inplace=True)\n",
        "        y_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_filtered, y_filtered\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        \"\"\"Test a model with Stratified K-Fold and return an array with metric results.\"\"\"\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "        X, y = self.drop_small_classes(self.X, self.y)\n",
        "\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = self.le.transform((y[train_index])), self.le.transform(y[test_index])\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for each fold\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "            precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "            f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "        # Return average metrics as a result array\n",
        "        return [\n",
        "            model_name, vectorizer_name, sampler_name,\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        progress_bar = tqdm(total = len(self.vectorizers.keys()) * len(self.sampling_strategies.keys()) * len(self.classifiers.keys()))\n",
        "        # Iterate over vectorizers, samplers, and classifiers\n",
        "        for vect_name, ovectorizer in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(ovectorizer)\n",
        "            for samp_name, osampler in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(osampler)\n",
        "                for clf_name, omodel in self.classifiers.items():\n",
        "                    model = deepcopy(omodel)\n",
        "\n",
        "                    result = self.test(\n",
        "                        model=model,\n",
        "                        model_name=clf_name,\n",
        "                        vectorizer=vectorizer,\n",
        "                        vectorizer_name=vect_name,\n",
        "                        sampler=sampler,\n",
        "                        sampler_name=samp_name\n",
        "                    )\n",
        "                    # Store the trained model and add result to the results list\n",
        "                    results.append(result)\n",
        "\n",
        "                    vectorizer = deepcopy(ovectorizer)\n",
        "                    sampler = deepcopy(osampler)\n",
        "                    model = deepcopy(omodel)\n",
        "                    vectorizer.fit(self.X_train)\n",
        "                    X_train = vectorizer.transform(self.X_train).toarray()\n",
        "                    X_resampled, y_resampled = sampler.fit_resample(X_train, self.y_train)\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    self.trained_models[(vect_name, samp_name, clf_name)] = model\n",
        "                    self.trained_vectorizers[vect_name] = vectorizer\n",
        "                    self.trainer_samplers[(vect_name, samp_name)] = sampler\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "        # Convert results to a DataFrame for better readability\n",
        "        columns = [\n",
        "            'Model', 'Vectorizer', 'Sampler',\n",
        "            'Accuracy Mean', 'Accuracy Std',\n",
        "            'Recall Mean', 'Recall Std',\n",
        "            'Precision Mean', 'Precision Std',\n",
        "            'F1 Mean', 'F1 Std'\n",
        "        ]\n",
        "        results_df = pd.DataFrame(results, columns=columns)\n",
        "        self.results = results_df\n",
        "        return results_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.events_sequence, df.incident_type\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWMj2hzMHL9L",
        "outputId": "742d6875-7499-48f3-c443-bff5a86f9eeb"
      },
      "id": "XWMj2hzMHL9L",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:10<01:36, 10.71s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:15<00:57,  7.13s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:23<00:52,  7.53s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:34<00:53,  8.96s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [03:52<06:25, 77.05s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [04:02<03:37, 54.44s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [04:06<01:53, 37.95s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [04:10<00:53, 26.91s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [05:24<00:41, 41.91s/it]\u001b[A\n",
            "100%|██████████| 10/10 [06:07<00:00, 36.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.83      0.71        24\n",
            "           1       0.58      0.44      0.50        16\n",
            "           2       0.85      0.74      0.79        23\n",
            "           3       0.50      0.60      0.55         5\n",
            "           4       0.85      0.86      0.85        64\n",
            "           5       0.67      0.73      0.70        30\n",
            "           6       0.72      0.60      0.66        35\n",
            "\n",
            "    accuracy                           0.74       197\n",
            "   macro avg       0.69      0.69      0.68       197\n",
            "weighted avg       0.74      0.74      0.73       197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5BnuWhimN5ri",
        "outputId": "898c2aec-0cd3-49b4-a3b1-1e03425c143a"
      },
      "id": "5BnuWhimN5ri",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Vectorizer Sampler  Accuracy Mean  Accuracy Std  \\\n",
              "0          LogisticRegression      Count   SMOTE       0.471486      0.017767   \n",
              "1                DecisionTree      Count   SMOTE       0.459303      0.032458   \n",
              "2                RandomForest      Count   SMOTE       0.640542      0.031054   \n",
              "3        ExtraTreesClassifier      Count   SMOTE       0.679255      0.037355   \n",
              "4  GradientBoostingClassifier      Count   SMOTE       0.705687      0.006607   \n",
              "5          AdaBoostClassifier      Count   SMOTE       0.481773      0.055515   \n",
              "6                  GaussianNB      Count   SMOTE       0.513224      0.022765   \n",
              "7                         KNN      Count   SMOTE       0.290267      0.021185   \n",
              "8                         SVM      Count   SMOTE       0.311629      0.039142   \n",
              "9                     XGBoost      Count   SMOTE       0.696540      0.016580   \n",
              "\n",
              "   Recall Mean  Recall Std  Precision Mean  Precision Std   F1 Mean    F1 Std  \n",
              "0     0.471486    0.017767        0.512338       0.008860  0.469512  0.015478  \n",
              "1     0.459303    0.032458        0.471232       0.032722  0.460248  0.032103  \n",
              "2     0.640542    0.031054        0.648740       0.037938  0.632973  0.032436  \n",
              "3     0.679255    0.037355        0.683635       0.048037  0.670914  0.042893  \n",
              "4     0.705687    0.006607        0.714770       0.008536  0.703078  0.007395  \n",
              "5     0.481773    0.055515        0.548591       0.051530  0.493769  0.054542  \n",
              "6     0.513224    0.022765        0.575248       0.017215  0.515439  0.016750  \n",
              "7     0.290267    0.021185        0.332371       0.022227  0.286779  0.021274  \n",
              "8     0.311629    0.039142        0.372378       0.042770  0.303558  0.036071  \n",
              "9     0.696540    0.016580        0.704206       0.027843  0.693191  0.017171  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94382e7c-fd92-4a02-acdb-019dc1b79af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.471486</td>\n",
              "      <td>0.017767</td>\n",
              "      <td>0.471486</td>\n",
              "      <td>0.017767</td>\n",
              "      <td>0.512338</td>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.469512</td>\n",
              "      <td>0.015478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.459303</td>\n",
              "      <td>0.032458</td>\n",
              "      <td>0.459303</td>\n",
              "      <td>0.032458</td>\n",
              "      <td>0.471232</td>\n",
              "      <td>0.032722</td>\n",
              "      <td>0.460248</td>\n",
              "      <td>0.032103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.640542</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>0.640542</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>0.648740</td>\n",
              "      <td>0.037938</td>\n",
              "      <td>0.632973</td>\n",
              "      <td>0.032436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.679255</td>\n",
              "      <td>0.037355</td>\n",
              "      <td>0.679255</td>\n",
              "      <td>0.037355</td>\n",
              "      <td>0.683635</td>\n",
              "      <td>0.048037</td>\n",
              "      <td>0.670914</td>\n",
              "      <td>0.042893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.705687</td>\n",
              "      <td>0.006607</td>\n",
              "      <td>0.705687</td>\n",
              "      <td>0.006607</td>\n",
              "      <td>0.714770</td>\n",
              "      <td>0.008536</td>\n",
              "      <td>0.703078</td>\n",
              "      <td>0.007395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.481773</td>\n",
              "      <td>0.055515</td>\n",
              "      <td>0.481773</td>\n",
              "      <td>0.055515</td>\n",
              "      <td>0.548591</td>\n",
              "      <td>0.051530</td>\n",
              "      <td>0.493769</td>\n",
              "      <td>0.054542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.513224</td>\n",
              "      <td>0.022765</td>\n",
              "      <td>0.513224</td>\n",
              "      <td>0.022765</td>\n",
              "      <td>0.575248</td>\n",
              "      <td>0.017215</td>\n",
              "      <td>0.515439</td>\n",
              "      <td>0.016750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.290267</td>\n",
              "      <td>0.021185</td>\n",
              "      <td>0.290267</td>\n",
              "      <td>0.021185</td>\n",
              "      <td>0.332371</td>\n",
              "      <td>0.022227</td>\n",
              "      <td>0.286779</td>\n",
              "      <td>0.021274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.311629</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.311629</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.372378</td>\n",
              "      <td>0.042770</td>\n",
              "      <td>0.303558</td>\n",
              "      <td>0.036071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.696540</td>\n",
              "      <td>0.016580</td>\n",
              "      <td>0.696540</td>\n",
              "      <td>0.016580</td>\n",
              "      <td>0.704206</td>\n",
              "      <td>0.027843</td>\n",
              "      <td>0.693191</td>\n",
              "      <td>0.017171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94382e7c-fd92-4a02-acdb-019dc1b79af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94382e7c-fd92-4a02-acdb-019dc1b79af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94382e7c-fd92-4a02-acdb-019dc1b79af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96c11d16-e69a-4a6e-98f5-7cc68d497b58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96c11d16-e69a-4a6e-98f5-7cc68d497b58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96c11d16-e69a-4a6e-98f5-7cc68d497b58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_05aedcd2-fe1b-46f1-9afd-9d124899679c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_05aedcd2-fe1b-46f1-9afd-9d124899679c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SVM\",\n          \"DecisionTree\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1524002320259485,\n        \"min\": 0.29026727442245936,\n        \"max\": 0.705687351082565,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.311628509271729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014002205221427363,\n        \"min\": 0.00660709904069551,\n        \"max\": 0.0555148780985835,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.03914198530559259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1524002320259485,\n        \"min\": 0.29026727442245936,\n        \"max\": 0.705687351082565,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.311628509271729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014002205221427363,\n        \"min\": 0.00660709904069551,\n        \"max\": 0.0555148780985835,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.03914198530559259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13552677103497912,\n        \"min\": 0.33237089377815876,\n        \"max\": 0.7147699843912887,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3723777786972883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015484528982873887,\n        \"min\": 0.00853622834879934,\n        \"max\": 0.05153011304298673,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04277037008554203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15166895469109204,\n        \"min\": 0.2867785729744833,\n        \"max\": 0.7030777419702039,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.30355799618980644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014517456475804751,\n        \"min\": 0.00739548066817252,\n        \"max\": 0.05454181546113614,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.036070545229701774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aqzrdn9ukm_",
        "outputId": "cfe6ef9c-1924-49fd-9df1-3faca8f566e5"
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:07<01:10,  7.84s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:10<00:36,  4.59s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:16<00:38,  5.54s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:25<00:39,  6.65s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [03:41<06:15, 75.13s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [03:49<03:29, 52.31s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [03:51<01:47, 35.82s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [03:52<00:49, 24.85s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [04:41<00:32, 32.40s/it]\u001b[A\n",
            "100%|██████████| 10/10 [05:28<00:00, 32.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.83      0.70        24\n",
            "           1       0.61      0.69      0.65        16\n",
            "           2       0.71      0.74      0.72        23\n",
            "           3       0.43      0.60      0.50         5\n",
            "           4       0.90      0.88      0.89        64\n",
            "           5       0.73      0.73      0.73        30\n",
            "           6       0.83      0.54      0.66        35\n",
            "\n",
            "    accuracy                           0.75       197\n",
            "   macro avg       0.69      0.72      0.69       197\n",
            "weighted avg       0.77      0.75      0.75       197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3_juRB6oN_xb",
        "outputId": "a4d8dbbe-ec5b-437a-d1ef-aecf281df642"
      },
      "id": "3_juRB6oN_xb",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Vectorizer Sampler  Accuracy Mean  Accuracy Std  \\\n",
              "0          LogisticRegression      Count   SMOTE       0.626277      0.043505   \n",
              "1                DecisionTree      Count   SMOTE       0.503087      0.022870   \n",
              "2                RandomForest      Count   SMOTE       0.639527      0.032466   \n",
              "3        ExtraTreesClassifier      Count   SMOTE       0.657868      0.028028   \n",
              "4  GradientBoostingClassifier      Count   SMOTE       0.709764      0.017843   \n",
              "5          AdaBoostClassifier      Count   SMOTE       0.495882      0.076081   \n",
              "6                  GaussianNB      Count   SMOTE       0.491837      0.016405   \n",
              "7                         KNN      Count   SMOTE       0.400186      0.020440   \n",
              "8                         SVM      Count   SMOTE       0.484730      0.014635   \n",
              "9                     XGBoost      Count   SMOTE       0.675168      0.028482   \n",
              "\n",
              "   Recall Mean  Recall Std  Precision Mean  Precision Std   F1 Mean    F1 Std  \n",
              "0     0.626277    0.043505        0.635346       0.042035  0.626121  0.041839  \n",
              "1     0.503087    0.022870        0.525175       0.031072  0.507673  0.022681  \n",
              "2     0.639527    0.032466        0.638117       0.038609  0.629648  0.033773  \n",
              "3     0.657868    0.028028        0.664988       0.031401  0.648764  0.028840  \n",
              "4     0.709764    0.017843        0.718387       0.016190  0.707514  0.019191  \n",
              "5     0.495882    0.076081        0.528046       0.066722  0.496413  0.078922  \n",
              "6     0.491837    0.016405        0.565589       0.023900  0.494206  0.013334  \n",
              "7     0.400186    0.020440        0.469941       0.022513  0.408985  0.021411  \n",
              "8     0.484730    0.014635        0.560749       0.011080  0.483875  0.018098  \n",
              "9     0.675168    0.028482        0.677742       0.033846  0.668889  0.028916  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.626277</td>\n",
              "      <td>0.043505</td>\n",
              "      <td>0.626277</td>\n",
              "      <td>0.043505</td>\n",
              "      <td>0.635346</td>\n",
              "      <td>0.042035</td>\n",
              "      <td>0.626121</td>\n",
              "      <td>0.041839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.503087</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>0.503087</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>0.525175</td>\n",
              "      <td>0.031072</td>\n",
              "      <td>0.507673</td>\n",
              "      <td>0.022681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.639527</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>0.639527</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>0.638117</td>\n",
              "      <td>0.038609</td>\n",
              "      <td>0.629648</td>\n",
              "      <td>0.033773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.657868</td>\n",
              "      <td>0.028028</td>\n",
              "      <td>0.657868</td>\n",
              "      <td>0.028028</td>\n",
              "      <td>0.664988</td>\n",
              "      <td>0.031401</td>\n",
              "      <td>0.648764</td>\n",
              "      <td>0.028840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.709764</td>\n",
              "      <td>0.017843</td>\n",
              "      <td>0.709764</td>\n",
              "      <td>0.017843</td>\n",
              "      <td>0.718387</td>\n",
              "      <td>0.016190</td>\n",
              "      <td>0.707514</td>\n",
              "      <td>0.019191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.495882</td>\n",
              "      <td>0.076081</td>\n",
              "      <td>0.495882</td>\n",
              "      <td>0.076081</td>\n",
              "      <td>0.528046</td>\n",
              "      <td>0.066722</td>\n",
              "      <td>0.496413</td>\n",
              "      <td>0.078922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.491837</td>\n",
              "      <td>0.016405</td>\n",
              "      <td>0.491837</td>\n",
              "      <td>0.016405</td>\n",
              "      <td>0.565589</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.494206</td>\n",
              "      <td>0.013334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.400186</td>\n",
              "      <td>0.020440</td>\n",
              "      <td>0.400186</td>\n",
              "      <td>0.020440</td>\n",
              "      <td>0.469941</td>\n",
              "      <td>0.022513</td>\n",
              "      <td>0.408985</td>\n",
              "      <td>0.021411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.484730</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.484730</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.560749</td>\n",
              "      <td>0.011080</td>\n",
              "      <td>0.483875</td>\n",
              "      <td>0.018098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.675168</td>\n",
              "      <td>0.028482</td>\n",
              "      <td>0.675168</td>\n",
              "      <td>0.028482</td>\n",
              "      <td>0.677742</td>\n",
              "      <td>0.033846</td>\n",
              "      <td>0.668889</td>\n",
              "      <td>0.028916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2575f4e-9757-455a-9478-69251b0f317f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2575f4e-9757-455a-9478-69251b0f317f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2575f4e-9757-455a-9478-69251b0f317f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c9c7b802-e14b-4d8d-933e-ed93624e4f1b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c9c7b802-e14b-4d8d-933e-ed93624e4f1b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SVM\",\n          \"DecisionTree\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10460477008068274,\n        \"min\": 0.40018647052729717,\n        \"max\": 0.7097638039987568,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48473013570910606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018345361577286654,\n        \"min\": 0.01463508597700476,\n        \"max\": 0.0760807361541652,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01463508597700476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10460477008068274,\n        \"min\": 0.40018647052729717,\n        \"max\": 0.7097638039987568,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48473013570910606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018345361577286654,\n        \"min\": 0.01463508597700476,\n        \"max\": 0.0760807361541652,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01463508597700476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07984414061308821,\n        \"min\": 0.46994128352857956,\n        \"max\": 0.7183869128095757,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5607489349836725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015624627155135084,\n        \"min\": 0.01107966133204304,\n        \"max\": 0.06672168794063564,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01107966133204304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09995007657646919,\n        \"min\": 0.4089852202407232,\n        \"max\": 0.7075139643123525,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48387475469993924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01888244647301909,\n        \"min\": 0.013334167290706925,\n        \"max\": 0.07892160591071905,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01809783348065855\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_before, df_after = Representations(df).representation_b(df)\n",
        "X, y = df_before.events_sequence, df_before['class']\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "razuBz2VOucS",
        "outputId": "9b665267-886f-4003-a7f1-30c28b7b7ec3"
      },
      "id": "razuBz2VOucS",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [05:33<?, ?it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 3, n_samples = 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-39755b4ecd0f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_before\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_before\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnsembleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_vectorizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-dce5d7368f8e>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    391\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0minequality_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"n_neighbors <= n_samples_fit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;34mf\"Expected {inequality_str}, but \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;34mf\"n_neighbors = {n_neighbors}, n_samples_fit = {n_samples_fit}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 3, n_samples = 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df_after.events_sequence, df_before['class']\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "id": "Dc3-xLClSvjn"
      },
      "id": "Dc3-xLClSvjn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}