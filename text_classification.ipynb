{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Importation"
      ],
      "metadata": {
        "id": "vXgvhkss9klA"
      },
      "id": "vXgvhkss9klA"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "import pickle\n",
        "from joblib import Parallel, delayed\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import parallel_backend\n",
        "import threading\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Experiment`\n",
        "\n",
        "This class is a pipeline that automates the process of training and testing using cross-validation and prepares the system for ensemble evaluations. This class was developed as pipeline to do experiments more easily, since we want to test all possible model, sampling strategies and vectorizers available.\n",
        "\n",
        "One main limitation is the business knowledge we have, since we don not really understand at a very specific level this dataset, like what exactly each incident is, or what does each event in the events sequence represent, we didn't take any apriori assumtios of the data, and we decided to find by bute force what is the best vectorizer, sampling strategy and model for the given dataset. Additionally, we also tested different representations of the sequences in an attempt of removing any noise we were not aware of. These kinds of knowledge limitations impacted on the results we presented since we are treating the dataset as a black box in certain aspects.\n",
        "\n",
        "For the experiments, we are trateing the sequences of events as if they were words in a text. Therefore, we treated this problem as text classification and defined the pipeline as such. Therefore, we will test the **TFIDF Vectorier, Count Vectorizer and Word2Vec** to understand whichone can infere the best embedding space for the provided event sequences.\n",
        "\n",
        "Since we are dealing with a very small data sample (around 1k observations) we wanted to train our models in oversampled data using different sampling methods and find our which can improve the models performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`__init__(self, X, y)`**\n",
        "\n",
        "This class is initialized with the training data and the target column. Whithin this method it:\n",
        "  - Splits `X` (features) and `y` (labels) into training and test sets using **stratified sampling** to ensure class balance.\n",
        "  - Encodes categorical labels (`y`) into numerical values using `LabelEncoder`.\n",
        "\n",
        "We also initialize the following attributes to be accessible in all parts of the pipeline:\n",
        "  - **`self.X_train`, `self.X_test`, `self.y_train`, `self.y_test`:** Prepared splits for training and testing.\n",
        "  - **`self.trai`ed_models` and `self.trained_vectorizers`:** Empty dictionaries to store trained models and vectorizers.\n",
        "  - **`self.results`:** Stores evaluation results for comparison.\n",
        "  - **`sampling_strategies`:** A dictionary of techniques to handle class imbalance, we are using `SMOTE`, `Borderline-SMOTE`, `ADASYN`, `RandomOversampler`, `SMOTE-ENN`, `SMOTE-Tomek`.\n",
        "  - **`vectorizers`:** A dictionary of methods for text representation, we are using `TFIDF`, `Count`,`Word2Vec`\n",
        "  - **`classifiers`:** A set of preconfigured machine learning models, such as `LogisticRegression`,`DecisionTree`,`RandomForest`,`ExtraTreesClassifier`,`GradientBoostingClassifier`,`AdaBoostClassifier`,`GaussianNB`,`KNN`,`SVM`,`XGBoost`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`duplicate_minor_classes(self, X, y, min_instances=5)`**\n",
        "\n",
        "Balances the dataset by duplicating underrepresented classes until they meet the minimum instance threshold.\n",
        "\n",
        "1. Identifies **minor classes** with fewer samples than `min_instances`.\n",
        "2. Duplicates rows corresponding to these classes.\n",
        "3. Merges the duplicated data back with the original dataset.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name)`**\n",
        "\n",
        "Using cross-validation it evaluates a single combination of **Model**, **Vectorizer** and **Sampler**. It returns a list of evaluation metrics (mean and standard deviation) for the specified combination.\n",
        "\n",
        "1. Splits `X` and `y` into 5 folds using **StratifiedKFold**.\n",
        "2. For each fold:\n",
        "   - Transforms the data with the given vectorizer.\n",
        "   - Balances the data using the sampler.\n",
        "   - Trains the model on the resampled training data.\n",
        "   - Predicts on the validation data.\n",
        "3. Calculates metrics:\n",
        "   - Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1 Score\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **`training(self)`**\n",
        "\n",
        "Runs experiments for all combinations of **Model**, **Vectorizer** and **Sampler**.\n",
        "\n",
        "1. Balances the training data using `duplicate_minor_classes`.\n",
        "2. Constructs a task list of all vectorizer-sampler-model combinations.\n",
        "3. Uses parallel processing to execute each task:\n",
        "   - For each combination, calls `test()` to evaluate.\n",
        "4. Aggregates results into a DataFrame for easy comparison.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_task(self, task, progress_bar)`**\n",
        "\n",
        "Handles a single task from the `training()` pipeline to run it in parallel. Returns evaluation metrics for the task.\n",
        "\n",
        "1. Unpacks the task (vectorizer, sampler, model).\n",
        "2. Executes `test()` for the task.\n",
        "3. Updates the progress bar.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test_ensemble(self)`**\n",
        "\n",
        "Evaluates the performance of an ensemble model across multiple folds. Returns evaluation metrics for the ensemble model.\n",
        "\n",
        "1. Splits the data using `StratifiedKFold`.\n",
        "2. For each fold:\n",
        "   - Trains all models, vectorizers, and samplers on the training data.\n",
        "   - Constructs an ensemble model using `EnsembleModel`.\n",
        "   - Tests the ensemble on the validation set.\n",
        "3. Calculates metrics for the ensembleâ€™s performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_fold(self, X_train, X_test, y_train, y_test)`**\n",
        "\n",
        "Handles training and evaluation for a single fold in `test_ensemble` to be executed in parallel along all other folds. Returns evaluation metrics for the ensemble model for that fold.\n",
        "\n",
        "1. Trains all vectorizers and models on the training data.\n",
        "2. Stores trained models and vectorizers for the fold.\n",
        "3. Fits an ensemble model on the predictions.\n",
        "4. Evaluates the ensemble on the validation set.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fr_q4Q0M63DE"
      },
      "id": "Fr_q4Q0M63DE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Word2VecVectorizer`\n",
        "This class converts sentences into numerical vectors using Word2Vec, which captures the semantic meaning of words. This class was defined to provide an interface similar to Scikit-Learn interface and avoid syntaxis issues later on in the `Experiment` class.\n",
        "\n",
        " - `__init__`: Lets you configure how the Word2Vec model works:\n",
        "   - `size` is the number of dimensions for word vectors (e.g., 100-dimensional space).\n",
        "   - `window` is the maximum distance between the current and predicted words.\n",
        "   - `min_count` is the minimum number of times a word must appear to be included in the model.\n",
        "   - `workers` determines how many CPU threads to use for training (faster with more workers).\n",
        " - `fit`: Takes a list of sentences, splits them into words, and trains a Word2Vec model to learn relationships between words.\n",
        " - `transform`: Takes sentences and converts them into vectors. It does this by averaging the vectors of all words in a sentence. If a word isn't in the Word2Vec model, it is ignored, and zeros are used instead.\n",
        " - `fit_transform`: A convenience method that combines the `fit` (training) and `transform` (vectorizing) steps.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SgzoRMgu6W0K"
      },
      "id": "SgzoRMgu6W0K"
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.\n",
        "                                 size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoVectorier(TransformerMixin):\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "B4W8MlJVFVf-"
      },
      "id": "B4W8MlJVFVf-",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.le = LabelEncoder()\n",
        "        self.y = self.le.fit_transform(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "        self.y_train = self.le.transform(self.y_train)\n",
        "        self.y_test = self.le.transform(self.y_test)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            \"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            \"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            \"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1),\n",
        "            \"NoVec\": NoVectorier()\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False, n_jobs = 2),\n",
        "        }\n",
        "\n",
        "\n",
        "    def duplicate_minor_classes(self, X, y, min_instances=5):\n",
        "        X = X.reset_index(drop=True)\n",
        "        y  = y.reset_index(drop=True)\n",
        "        class_counts = y.value_counts()\n",
        "\n",
        "        minor_classes = class_counts[class_counts < min_instances].index\n",
        "\n",
        "        minor_class_rows = X.loc[y.isin(minor_classes)]\n",
        "        minor_class_labels = y.loc[y.isin(minor_classes)]\n",
        "\n",
        "        duplicated_X = pd.concat([minor_class_rows] * 2, ignore_index=True)\n",
        "        duplicated_y = pd.concat([minor_class_labels] * 2, ignore_index=True)\n",
        "\n",
        "        X_balanced = pd.concat([X, duplicated_X], ignore_index=True)\n",
        "        y_balanced = pd.concat([y, duplicated_y], ignore_index=True)\n",
        "\n",
        "        X_balanced.reset_index(drop=True, inplace=True)\n",
        "        y_balanced.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_balanced, y_balanced\n",
        "\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average=\"weighted\"))\n",
        "            precisions.append(precision_score(y_test, y_pred, average=\"weighted\"))\n",
        "            f1s.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "        return [\n",
        "            model_name,\n",
        "            vectorizer_name,\n",
        "            sampler_name,\n",
        "            np.mean(accuracies),\n",
        "            np.std(accuracies),\n",
        "            np.mean(recalls),\n",
        "            np.std(recalls),\n",
        "            np.mean(precisions),\n",
        "            np.std(precisions),\n",
        "            np.mean(f1s),\n",
        "            np.std(f1s),\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        self.X_train, self.y_train = self.duplicate_minor_classes(\n",
        "            self.X_train, pd.Series(self.y_train)\n",
        "        )\n",
        "        task_list = []\n",
        "\n",
        "        for vect_name, vectorizer in self.vectorizers.items():\n",
        "            for samp_name, sampler in self.sampling_strategies.items():\n",
        "                for clf_name, model in self.classifiers.items():\n",
        "                    task_list.append(\n",
        "                        (clf_name, vect_name, samp_name, deepcopy(model), deepcopy(vectorizer), deepcopy(sampler))\n",
        "                    )\n",
        "\n",
        "        progress_bar = tqdm(total=len(task_list))\n",
        "        with parallel_backend(\"threading\"):\n",
        "            parallel_results = Parallel(n_jobs=-1)(\n",
        "                delayed(self._process_task)(task, progress_bar) for task in task_list\n",
        "            )\n",
        "\n",
        "        results.extend(parallel_results)\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Save results and models\n",
        "        self.results = pd.DataFrame(\n",
        "            results,\n",
        "            columns=[\n",
        "                \"Model\",\n",
        "                \"Vectorizer\",\n",
        "                \"Sampler\",\n",
        "                \"Accuracy Mean\",\n",
        "                \"Accuracy Std\",\n",
        "                \"Recall Mean\",\n",
        "                \"Recall Std\",\n",
        "                \"Precision Mean\",\n",
        "                \"Precision Std\",\n",
        "                \"F1 Mean\",\n",
        "                \"F1 Std\",\n",
        "            ],\n",
        "        )\n",
        "        return self.results\n",
        "\n",
        "    def _process_task(self, task, progress_bar):\n",
        "        clf_name, vect_name, samp_name, model, vectorizer, sampler = task\n",
        "        result = self.test(\n",
        "            model=model,\n",
        "            model_name=clf_name,\n",
        "            vectorizer=vectorizer,\n",
        "            vectorizer_name=vect_name,\n",
        "            sampler=sampler,\n",
        "            sampler_name=samp_name,\n",
        "        )\n",
        "        progress_bar.update(1)\n",
        "        return result\n",
        "\n",
        "    def test_ensemble(self):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        tasks = []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "            tasks.append((X_train, X_test, y_train, y_test))\n",
        "\n",
        "        total_tasks = len(tasks)\n",
        "        progress_bar = tqdm(total=total_tasks, desc=\"Processing folds\")\n",
        "        lock = threading.Lock()  # Lock to manage updates safely across threads\n",
        "\n",
        "        def process_with_progress(*args):\n",
        "            result = self._process_fold(*args)\n",
        "            with lock:\n",
        "                progress_bar.update(1)\n",
        "            return result\n",
        "\n",
        "        with parallel_backend(\"threading\"):\n",
        "            results = Parallel(n_jobs=-1)(\n",
        "                delayed(process_with_progress)(X_train, X_test, y_train, y_test)\n",
        "                for X_train, X_test, y_train, y_test in tasks\n",
        "            )\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        accuracies, recalls, precisions, f1s = zip(*results)\n",
        "\n",
        "        return [\n",
        "            \"Ensemble\", \"Multiple\", \"Multiple\",\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def _process_fold(self, X_train, X_test, y_train, y_test):\n",
        "        fold_trained_models = {}\n",
        "        fold_trained_vectorizers = {}\n",
        "\n",
        "        for vectorizer_name, vectorizer_i in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(vectorizer_i)\n",
        "            X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test_vect = vectorizer.transform(X_test).toarray()\n",
        "            fold_trained_vectorizers[vectorizer_name] = vectorizer\n",
        "\n",
        "            for sampler_name, sampler_i in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(sampler_i)\n",
        "                X_resampled, y_resampled = sampler.fit_resample(X_train_vect, y_train)\n",
        "\n",
        "                for model_name, model in self.classifiers.items():\n",
        "                    trained_model = deepcopy(model)\n",
        "                    trained_model.fit(X_resampled, y_resampled)\n",
        "                    fold_trained_models[(vectorizer_name, sampler_name, model_name)] = trained_model\n",
        "\n",
        "        ensemble = EnsembleModel(fold_trained_models, fold_trained_vectorizers)\n",
        "        ensemble.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = ensemble.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "        return accuracy, recall, precision, f1\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`EnsembleModel`\n",
        "\n",
        "This class combines predictions from multiple models to make a more accurate \"group decision.\"\n",
        " - `__init__`: Takes two things:\n",
        "   - A dictionary of trained models.\n",
        "   - A dictionary of vectorizers (tools that convert text into numbers).\n",
        "   It stores these for use during prediction and training.\n",
        " - `_generate_prediction_matrix`: This creates a matrix where:\n",
        "   - Each row corresponds to an input sample.\n",
        "   - Each column is a model's prediction probabilities for each class.\n",
        " - `fit`: Uses an optimization algorithm (`differential_evolution`) to find the best set of weights for combining the model predictions. The goal is to maximize prediction performance (e.g., F1-score).\n",
        " - `predict`: Uses the optimized weights to combine predictions from all models and makes the final decision by selecting the class with the highest combined probability."
      ],
      "metadata": {
        "id": "JmL3JegE6lTx"
      },
      "id": "JmL3JegE6lTx"
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        def fitness(weights):\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Representations`\n",
        "\n",
        "This class creates different ways to represent sequences of events for machine learning analysis.\n",
        " - `representation_a`: Focuses on filtering events:\n",
        "   - Counts the frequency of each event in all sequences.\n",
        "   - Keeps only the events that occur less than 85% of the time, filtering out common noise.\n",
        "   - Outputs a \"cleaned\" sequence of events and the labels (e.g., incident types).\n",
        " - `representation_b`: Splits event sequences into two parts:\n",
        "   - Events *before* an incident (labeled with the incident type).\n",
        "   - Events *after* an incident (labeled as \"unknown\").\n",
        " - `representation_c`: Breaks sequences into overlapping chunks:\n",
        "   - For example, if you have a sequence of 50 events, it divides them into smaller parts (e.g., chunks of 30 events with 15 overlapping).\n",
        "   - Each chunk is labeled with the incident type.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7kLLXN5Y6viF"
      },
      "id": "7kLLXN5Y6viF"
    },
    {
      "cell_type": "code",
      "source": [
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)\n",
        "\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)\n",
        "            )\n",
        "\n",
        "            self.y = df['incident_type'].copy()\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n",
        "\n",
        "  def representation_b(self, df):\n",
        "\n",
        "    before_incident = []\n",
        "    after_incident = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        before_events = \" \".join([str(event) for event, time in zip(events, seconds) if time <= 0])\n",
        "        if before_events:\n",
        "            before_incident.append({\n",
        "                \"events_sequence\": before_events,\n",
        "                \"class\": incident_type\n",
        "            })\n",
        "\n",
        "        after_events = \" \".join([str(event) for event, time in zip(events, seconds) if time > 0])\n",
        "        if after_events:\n",
        "            after_incident.append({\n",
        "                \"events_sequence\": after_events,\n",
        "                \"class\": 100\n",
        "            })\n",
        "\n",
        "    before_df = pd.DataFrame(before_incident)\n",
        "    after_df = pd.DataFrame(after_incident)\n",
        "\n",
        "    return before_df, after_df\n",
        "\n",
        "\n",
        "  def representation_c(self, df, sequence_length=30):\n",
        "\n",
        "    overlapping_sequences = []\n",
        "    step = sequence_length // 2\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        for i in range(0, len(events) - sequence_length + 1, step):\n",
        "            sequence = [str(i) for i in events[i:i + sequence_length]]\n",
        "            seconds_slice = seconds[i:i + sequence_length]\n",
        "            sequence_class = incident_type\n",
        "\n",
        "            overlapping_sequences.append({\"sequence\": \" \".join(sequence), \"class\": sequence_class})\n",
        "\n",
        "    sequences_df = pd.DataFrame(overlapping_sequences)\n",
        "    return sequences_df.sequence, sequences_df['class']\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# `duplicate_minor_classes`\n",
        "\n",
        "This standalone function ensures that all classes in the dataset are equally represented.\n",
        " - Identifies classes with fewer samples than a threshold (`min_instances`).\n",
        " - Duplicates the data for these minority classes to balance the dataset.\n",
        " - Returns the updated dataset, which is now less biased towards dominant classes.\n"
      ],
      "metadata": {
        "id": "bIlcU7c67LPc"
      },
      "id": "bIlcU7c67LPc"
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_minor_classes(X, y, min_instances=10):\n",
        "    X = X.reset_index(drop=True)\n",
        "    y  = y.reset_index(drop=True)\n",
        "    class_counts = y.value_counts()\n",
        "\n",
        "    minor_classes = class_counts[class_counts <= min_instances].index\n",
        "\n",
        "    minor_class_rows = X.loc[y.isin(minor_classes)]\n",
        "    minor_class_labels = y.loc[y.isin(minor_classes)]\n",
        "\n",
        "    duplicated_X = pd.concat([minor_class_rows] * 2, ignore_index=True)\n",
        "    duplicated_y = pd.concat([minor_class_labels] * 2, ignore_index=True)\n",
        "\n",
        "    X_balanced = pd.concat([X, duplicated_X], ignore_index=True)\n",
        "    y_balanced = pd.concat([y, duplicated_y], ignore_index=True)\n",
        "\n",
        "    X_balanced.reset_index(drop=True, inplace=True)\n",
        "    y_balanced.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return X_balanced, y_balanced"
      ],
      "metadata": {
        "id": "FEn5DGXm_hyE"
      },
      "id": "FEn5DGXm_hyE",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "ic7u7acl7qJj"
      },
      "id": "ic7u7acl7qJj"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "f2c80d06-167a-4a7a-e2f5-a7b499ed959e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "523      4457471  [601, 601, 601, 601, 601, 601, 601, 601, 601, ...   \n",
              "972      4610651  [1024, 1024, 1024, 1024, 1024, 1024, 1024, 102...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "523  [3636, 3658, 2956, 2956, 2956, 2956, 2956, 406...   \n",
              "972  [2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "523  [-14377, -14377, -14335, -14331, -14295, -1428...   50.874132   \n",
              "972  [-14366, -14349, -14339, -14312, -14305, -1430...   50.471103   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "523    4.101063  [0.0, 0.0, 59.8, 68.0, 84.9, 81.0, 47.0, 0.2, ...   \n",
              "972    5.689640  [18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84....   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "523  [False, False, False, False, False, False, Fal...   \n",
              "972  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "523  [True, True, True, True, True, True, True, Tru...             13  \n",
              "972  [True, True, True, True, True, True, True, Tru...             99  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f308711b-6908-4bb5-a67e-def43fdb5220\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>4457471</td>\n",
              "      <td>[601, 601, 601, 601, 601, 601, 601, 601, 601, ...</td>\n",
              "      <td>[3636, 3658, 2956, 2956, 2956, 2956, 2956, 406...</td>\n",
              "      <td>[-14377, -14377, -14335, -14331, -14295, -1428...</td>\n",
              "      <td>50.874132</td>\n",
              "      <td>4.101063</td>\n",
              "      <td>[0.0, 0.0, 59.8, 68.0, 84.9, 81.0, 47.0, 0.2, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>4610651</td>\n",
              "      <td>[1024, 1024, 1024, 1024, 1024, 1024, 1024, 102...</td>\n",
              "      <td>[2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14366, -14349, -14339, -14312, -14305, -1430...</td>\n",
              "      <td>50.471103</td>\n",
              "      <td>5.689640</td>\n",
              "      <td>[18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84....</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f308711b-6908-4bb5-a67e-def43fdb5220')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f308711b-6908-4bb5-a67e-def43fdb5220 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f308711b-6908-4bb5-a67e-def43fdb5220');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f76528a-52a5-45ca-ba23-d5b089ec2ecc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f76528a-52a5-45ca-ba23-d5b089ec2ecc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f76528a-52a5-45ca-ba23-d5b089ec2ecc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 108314,\n        \"min\": 4457471,\n        \"max\": 4610651,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4610651,\n          4457471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]\",\n          \"[601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601, 601]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4168, 4140, 4158, 4140, 4162, 4160, 4168, 2956, 2584, 2556, 2956, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2708, 2744, 4124, 4068, 3636, 3658, 4148, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4140, 2956, 4140, 4162, 4150, 4152, 4168, 4156, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 2956, 2956, 4068, 2686, 2708, 2742, 4158, 3760, 3768, 3636, 3658, 2886, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4168, 4140, 2956, 2956, 4140, 4162, 4160, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956]\",\n          \"[3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 2742, 4026, 3636, 3658, 4066, 3636, 3658, 4120, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4120, 3636, 3658, 2682, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 2708, 3234, 4396, 548, 2744, 4124, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 2684, 4124, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 4066, 3636, 3658, 4124, 4124, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3236, 2708, 2742, 4026, 3636, 3658, 4120, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 4396, 922, 942, 4180, 4394, 946, 920, 4080, 922, 920, 942, 922, 942, 920, 2708, 2742, 942, 920, 922, 922, 2942, 4120, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2682, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4168, 4140, 3234, 2708, 3986, 4004, 2852, 4110, 2854, 4026, 2708, 2742, 4026, 4148, 4140, 4152, 2554, 4168, 4156, 4406, 4410, 2740, 4408, 4412, 4030, 4018, 4026, 4066, 3636, 3658, 4120, 4120, 2682, 2956, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-14366, -14349, -14339, -14312, -14305, -14304, -14293, -14290, -14274, -14272, -14261, -14260, -14233, -14231, -14210, -14204, -14183, -14183, -14149, -14131, -14111, -14106, -14104, -14101, -14093, -14086, -14083, -14081, -14032, -14016, -13946, -13860, -13792, -13774, -13741, -13726, -13714, -13685, -13682, -13627, -13625, -13619, -13614, -13587, -13575, -13572, -13533, -13525, -13520, -13478, -13458, -13406, -13406, -13350, -13325, -13313, -13284, -13281, -13221, -13209, -13205, -13166, -13146, -13146, -13065, -13062, -13023, -13010, -12984, -12982, -12971, -12969, -12933, -12931, -12904, -12861, -12861, -12797, -12753, -12748, -12725, -12712, -12709, -12703, -12679, -12675, -12674, -12670, -12669, -12668, -12667, -12667, -12652, -12641, -12638, -12632, -12613, -12591, -12543, -12531, -12521, -12474, -12467, -12433, -12430, -12418, -12367, -12327, -12327, -12286, -12262, -12238, -12222, -12221, -12208, -12169, -12055, -12009, -12003, -11960, -11942, -11724, -11691, -11688, -11678, -11668, -11656, -11653, -11641, -11630, -11618, -11574, -11492, -11438, -11406, -11394, -11388, -11345, -11328, -11186, -11163, -11123, -11123, -11044, -11027, -10993, -10991, -10976, -10974, -10942, -10933, -10921, -10906, -10883, -10883, -10844, -10824, -10801, -10794, -10779, -10778, -10760, -10746, -10728, -10716, -10677, -10642, -10628, -10603, -10566, -10558, -10493, -10459, -10426, -10397, -10370, -10368, -10353, -10308, -10288, -10279, -10262, -10220, -10220, -10156, -10115, -10101, -10029, -9880, -9828, -9826, -9771, -9769, -9723, -9722, -9706, -9636, -9612, -9606, -9576, -9576, -9575, -5795, -5697, -5669, -5004, -5004, -4964, -4959, -4927, -4847, -4836, -4828, -4800, -4797, -4743, -4740, -4690, -4551, -4483, -4469, -4440, -4418, -4416, -4376, -4376, -4363, -4334, -4323, -4303, -4259, -4246, -4244, -4219, -4192, -4161, -4127, -4065, -4057, -4020, -3996, -3982, -3948, -3909, -3893, -3861, -3842, -3809, -3808, -3801, -3797, -3795, -3783, -3769, -3755, -3730, -3730, -3728, -3675, -3642, -3623, -3586, -3574, -3536, -3506, -3506, -3476, -3342, -3325, -3285, -3279, -3268, -3238, -3184, -3106, -3066, -3054, -3043, -3032, -3029, -3018, -3009, -3001, -2999, -2969, -2754, -2735, -2697, -2690, -2649, -2548, -2513, -2502, -2501, -2489, -2470, -2455, -2438, -2436, -2412, -2412, -2385, -2334, -2321, -2291, -2285, -2241, -2231, -2176, -2144, -2138, -2115, -2089, -2086, -2084, -2079, -2072, -2069, -2059, -2033, -1990, -1971, -1962, -1939, -1939, -1893, -1876, -1847, -1833, -1819, -1793, -1781, -1756, -1743, -1740, -1686, -1669, -1669, -1599, -1596, -1529, -1527, -1498, -1486, -1466, -1443, -1411, -1411, -1381, -1349, -1342, -1337, -1304, -1292, -1290, -1253, -1248, -1243, -1200, -1187, -1184, -1155, -1142, -1124, -1091, -1072, -1064, -1051, -1047, -997, -966, -938, -866, -806, -804, -791, -786, -779, -767, -752, -737, -727, -706, -695, -695, -684, -644, -641, -591, -590, -577, -560, -558, -547, -546, -540, -522, -517, -513, -510, -497, -486, -484, -479, -349, -349, -295, -295, -26, -26, 682, 889, 941, 960, 973, 1013, 1026, 1029, 1048, 1049, 1051, 1069, 1081, 1082, 1107, 1109, 1126, 1132, 1146, 1146, 1186, 1205, 1225, 1231, 1233, 1236, 1244, 1251, 1254, 1256, 1301, 1317, 1388, 1472, 1567, 1604, 1640, 1655, 1667, 1695, 1698, 1813, 1819, 1835, 1853, 1918, 1951, 1959, 2067, 2088, 2100, 2143, 2155, 2157, 2175, 2175, 2193, 2229, 2250, 2263, 2292, 2295, 2349, 2360, 2363, 2392, 2405, 2405, 2481, 2484, 2520, 2533, 2575, 2582, 2618, 2626, 2633, 2682, 2684, 2706, 2725, 2725, 2755, 2801, 2806, 2828, 2842, 2848, 2888, 2889, 2894, 2897, 2899, 2905, 2907, 2909, 2927, 2947, 2970, 3017, 3028, 3037, 3081, 3087, 3117, 3119, 3130, 3171, 3209, 3209, 3216, 3246, 3263, 3282, 3294, 3305, 3339, 3440, 3481, 3487, 3526, 3542]\",\n          \"[-14377, -14377, -14335, -14331, -14295, -14282, -14261, -14245, -14224, -14224, -14177, -14164, -14117, -14101, -14101, -14054, -14041, -14039, -13981, -13966, -13966, -13907, -13905, -13852, -13850, -13845, -13838, -13799, -13764, -13693, -13688, -13665, -13651, -13469, -13468, -11292, -11292, -11077, -10758, -10758, -10747, -10740, -10695, -10639, -10618, -10592, -10586, -10582, -10580, -10541, -10532, -10530, -10489, -10474, -10474, -10407, -10398, -10396, -10348, -10332, -10332, -10286, -10274, -10264, -10232, -10230, -10211, -10211, -10200, -10169, -10156, -10121, -10116, -10099, -10089, -10088, -10072, -10072, -10057, -10045, -10015, -10004, -9991, -9963, -9924, -9887, -9875, -9873, -9855, -9826, -9826, -9815, -9762, -9753, -9682, -9668, -9668, -9648, -9621, -9620, -9583, -9573, -9561, -9545, -9544, -9516, -9516, -9494, -9468, -9456, -9454, -9413, -9411, -9410, -9394, -9392, -9374, -9347, -9347, -9335, -9319, -9312, -9267, -9253, -9250, -9236, -9211, -9208, -9207, -9198, -9191, -9186, -9175, -9164, -9160, -9152, -9139, -9137, -9129, -9099, -9098, -9091, -9088, -9054, -9051, -9033, -9014, -9013, -8992, -8977, -8972, -8952, -8938, -8932, -8917, -8899, -8893, -8886, -8875, -8864, -8862, -8860, -8858, -8851, -8846, -8822, -8818, -8811, -8806, -8799, -8784, -8782, -8764, -8736, -8736, -8695, -8693, -8665, -8650, -8646, -8644, -8642, -8623, -8590, -8582, -8549, -8534, -8519, -8423, -8390, -8369, -8369, -8348, -8339, -8309, -8305, -8283, -8280, -8277, -8263, -8258, -8256, -8252, -8232, -8227, -8224, -8208, -8205, -8203, -8191, -8188, -8164, -8140, -8139, -8139, -8128, -8107, -8104, -8103, -8085, -8082, -8069, -8066, -8051, -8047, -8044, -8031, -8027, -7966, -7960, -7947, -7922, -7922, -7910, -7886, -7881, -7871, -7861, -7853, -7846, -7844, -7816, -7801, -7799, -7774, -7740, -7734, -7712, -7711, -7703, -7690, -7682, -7682, -7215, -6611, -6609, -6609, -6557, -6508, -6473, -6465, -6448, -6442, -6403, -6398, -6394, -6363, -6360, -6328, -6320, -6278, -6247, -6247, -6228, -6215, -6206, -6152, -6147, -6146, -6129, -6127, -6125, -6106, -6102, -6077, -6073, -6070, -6053, -6049, -6022, -5983, -5983, -5971, -5943, -5939, -5921, -5917, -5906, -5902, -5887, -5883, -5880, -5875, -5866, -5862, -5839, -5836, -5833, -5810, -5807, -5775, -5675, -5675, -5529, -5488, -5432, -5417, -5414, -5380, -5375, -5356, -5340, -5331, -5327, -5321, -5319, -5307, -5280, -5277, -5261, -5220, -5220, -5175, -5168, -5165, -5149, -5142, -5137, -5132, -5128, -5104, -5099, -5092, -5090, -5088, -5087, -5078, -5067, -5056, -5050, -5033, -5018, -5011, -4998, -4978, -4974, -4958, -4938, -4937, -4918, -4900, -4897, -4861, -4858, -4849, -4847, -4814, -4808, -4806, -4796, -4794, -4788, -4772, -4762, -4761, -4755, -4747, -4737, -4733, -4705, -4689, -4675, -4608, -4578, -4540, -4540, -4520, -4497, -4493, -4463, -4460, -4457, -4395, -4394, -4373, -4329, -4285, -4285, -4264, -4249, -4234, -4190, -4176, -4174, -4146, -4095, -4095, -4006, -3966, -3951, -3950, -3930, -3928, -3913, -3913, -3878, -3875, -3808, -3807, -3800, -3766, -3736, -3721, -3710, -3681, -3675, -3666, -3651, -3651, -3640, -3614, -3610, -3580, -3571, -3552, -3538, -3525, -3525, -3513, -3481, -3468, -3425, -3410, -3410, -3399, -3396, -3369, -3357, -3355, -3299, -3284, -3284, -3270, -3203, -3201, -3152, -3150, -3145, -3139, -3114, -3095, -3035, -3031, -3011, -3009, -3007, -2925, -2924, -467, -467, -272, -258, -219, -146, -117, -76, -67, -60, -58, -10, 1, 3, 60, 61, 72, 72, 97, 214, 256, 262, 318, 330, 330, 349, 371, 371, 376, 377, 377, 377, 379, 392, 396, 399, 411, 445, 446, 451, 465, 468, 503, 508, 508, 530, 616, 735, 776, 795, 844, 859, 859, 877, 907, 921, 958, 963, 981, 997, 1005, 1005, 1030, 1064, 1076, 1092, 1122, 1164, 1165, 1212, 1228, 1230, 1250, 1263, 1263, 1277, 1330, 1341, 1421, 1438, 1438, 1440, 1484, 1485, 1526, 1538, 1550, 1568, 1580, 1585, 1585, 1626, 1640, 1642, 1707, 1709, 1713, 1744, 1747, 1777, 1786, 1792, 1800, 1802, 1813, 2068, 2070, 2070, 2072, 2073, 2097, 2097, 2097, 2097, 2109, 2111, 2117, 2117, 2120, 2132, 2134, 2139, 2143, 2145, 2148, 2149, 2149, 2196, 2227, 2227, 2237, 2264, 2266, 2300, 2360, 2373, 2374, 2376, 2384, 2389, 2414, 2416, 2417, 2425, 2432, 2437, 2447, 2458, 2462, 2470, 2482, 2484, 2492, 2521, 2523, 2530, 2532, 2567, 2570, 2587, 2606, 2608, 2628, 2644, 2648, 2669, 2682, 2689, 2704, 2721, 2727, 2734, 2745, 2757, 2759, 2761, 2762, 2769, 2774, 2800, 2804, 2805, 2812, 2818, 2826, 2845, 2848, 2864, 2865, 2898, 2898, 2931, 2952, 2955, 2984, 2999, 3002, 3004, 3006, 3021, 3024, 3055, 3063, 3092, 3101, 3111, 3185, 3211, 3237, 3237, 3256, 3314, 3353, 3357, 3382, 3385, 3388, 3402, 3407, 3408, 3414, 3432, 3437, 3440, 3457, 3461, 3464, 3501, 3558, 3593]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2849849648957564,\n        \"min\": 50.47110252894736,\n        \"max\": 50.87413213137536,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.47110252894736,\n          50.87413213137536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.123293469925027,\n        \"min\": 4.101062902148997,\n        \"max\": 5.689639761842105,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.689639761842105,\n          4.101062902148997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84.6, 85.7, 85.3, 82.4, 82.5, 65.3, 62.2, 18.1, 1.5, 0.0, 0.0, 27.8, 68.5, 87.1, 85.7, 85.2, 85.2, 85.4, 84.4, 83.6, 82.4, 55.5, 55.5, 52.7, 51.3, 55.2, 54.0, 61.2, 80.0, 86.5, 85.0, 84.4, 80.9, 80.3, 80.3, 81.5, 81.8, 85.1, 85.9, 84.6, 83.1, 82.0, 38.1, 0.8, 0.0, 0.0, 49.3, 84.0, 87.3, 81.6, 81.3, 77.1, 72.7, 72.2, 1.0, 0.0, 0.0, 75.2, 78.0, 83.2, 84.3, 82.9, 82.8, 80.4, 80.1, 48.2, 45.6, 0.4, 0.0, 0.0, 29.2, 39.5, 38.5, 48.8, 75.0, 74.1, 73.3, 69.4, 69.0, 69.2, 69.2, 69.0, 68.9, 68.5, 68.7, 63.3, 59.6, 59.0, 56.8, 64.8, 70.0, 82.4, 79.9, 83.5, 84.9, 82.6, 86.0, 87.5, 86.5, 0.4, 0.0, 0.0, 24.3, 60.9, 66.4, 71.8, 72.8, 81.6, 83.5, 87.4, 88.3, 87.3, 85.3, 72.6, 56.4, 87.6, 86.8, 82.8, 88.1, 85.6, 85.4, 86.0, 88.7, 85.2, 86.3, 88.5, 96.0, 88.3, 89.6, 91.3, 85.7, 87.3, 44.4, 2.4, 0.0, 0.0, 58.5, 65.0, 62.5, 61.8, 56.3, 55.9, 54.2, 52.6, 40.1, 2.2, 0.0, 0.0, 18.8, 37.6, 59.1, 55.9, 54.2, 55.1, 68.9, 84.2, 88.8, 87.1, 84.9, 86.0, 80.0, 88.0, 95.5, 95.9, 88.9, 81.6, 85.1, 80.3, 61.6, 60.0, 59.5, 60.0, 42.4, 33.0, 1.9, 0.0, 0.0, 41.5, 69.6, 69.5, 83.9, 90.2, 97.2, 98.4, 95.6, 96.5, 79.1, 78.0, 56.2, 29.7, 10.4, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 12.3, 92.9, 94.9, 90.7, 91.2, 91.5, 94.8, 94.7, 94.2, 86.8, 73.8, 77.1, 69.4, 3.5, 0.1, 0.0, 0.0, 0.0, 22.1, 40.8, 56.4, 67.1, 68.3, 68.1, 87.2, 89.2, 87.9, 89.0, 95.6, 94.7, 89.7, 85.2, 86.9, 86.8, 71.9, 54.2, 52.7, 56.5, 55.4, 55.4, 57.5, 58.0, 57.8, 58.9, 49.6, 2.9, 0.0, 0.0, 0.0, 55.4, 55.5, 56.1, 79.5, 87.3, 1.7, 0.0, 0.0, 40.6, 87.8, 90.1, 97.3, 97.4, 96.4, 98.2, 85.9, 97.4, 88.4, 88.2, 87.6, 97.3, 96.4, 96.2, 97.4, 97.9, 97.3, 63.0, 65.1, 89.5, 98.1, 98.5, 95.2, 98.3, 90.3, 86.5, 86.5, 87.3, 84.6, 57.2, 2.1, 0.0, 0.0, 0.0, 0.0, 96.4, 98.2, 95.3, 93.0, 88.1, 89.1, 86.6, 77.7, 77.3, 77.7, 74.8, 74.6, 74.4, 72.1, 61.2, 60.5, 55.0, 39.5, 32.4, 28.9, 0.1, 0.0, 0.0, 32.7, 35.0, 46.9, 68.3, 85.2, 82.8, 82.5, 84.6, 82.4, 81.9, 0.2, 0.0, 0.0, 62.8, 66.8, 88.1, 87.9, 88.5, 88.1, 79.0, 0.2, 0.0, 0.0, 21.6, 88.0, 87.6, 86.6, 88.6, 88.2, 89.2, 89.4, 88.7, 88.3, 83.8, 82.9, 83.3, 83.6, 71.6, 52.7, 56.1, 55.5, 54.3, 53.3, 53.0, 57.0, 56.2, 55.1, 54.6, 82.0, 84.9, 87.7, 86.9, 86.8, 87.5, 84.8, 57.1, 43.0, 0.5, 0.0, 0.0, 0.0, 36.3, 36.3, 61.3, 62.4, 83.5, 86.3, 86.0, 83.9, 83.4, 81.7, 60.6, 50.9, 45.8, 45.5, 27.6, 2.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.6, 17.7, 21.2, 48.9, 37.5, 37.2, 59.5, 62.0, 66.4, 86.3, 83.2, 84.0, 75.1, 71.7, 24.1, 0.3, 0.0, 0.0, 23.9, 63.8, 86.9, 85.8, 85.5, 85.8, 87.2, 86.5, 86.3, 86.3, 57.1, 54.3, 55.3, 54.4, 26.2, 35.2, 58.6, 83.7, 86.9, 84.1, 81.5, 30.2, 27.7, 25.5, 29.3, 31.9, 29.9, 30.6, 26.2, 32.8, 37.2, 47.2, 4.4, 0.4, 0.0, 0.0, 0.0, 57.3, 87.7, 84.8, 85.1, 84.8, 86.6, 86.0, 85.5, 2.6, 0.0, 0.0, 87.3, 87.6, 85.1, 81.1, 25.1, 22.5, 19.7, 20.7, 28.3, 47.0, 47.0, 2.3, 0.0, 0.0, 32.4, 37.2, 37.6, 47.5, 71.6, 70.8, 65.6, 65.4, 63.3, 62.0, 61.7, 59.8, 59.1, 58.7, 53.0, 54.1, 68.5, 88.3, 86.4, 88.0, 96.0, 97.2, 97.9, 98.3, 96.0, 1.7, 0.0, 0.0, 0.0, 36.7, 79.9, 88.5, 93.1, 97.1, 96.0, 96.3, 96.8, 96.0, 96.8, 77.9]\",\n          \"[0.0, 0.0, 59.8, 68.0, 84.9, 81.0, 47.0, 0.2, 0.0, 0.0, 64.4, 81.3, 0.2, 0.0, 0.0, 72.7, 93.0, 95.3, 0.2, 0.0, 0.0, 94.0, 97.0, 102.8, 102.7, 98.4, 85.8, 34.8, 28.7, 23.4, 22.9, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.2, 41.1, 65.9, 103.2, 111.7, 117.2, 119.8, 119.9, 120.4, 118.6, 0.2, 0.0, 0.0, 101.3, 103.6, 99.3, 0.1, 0.0, 0.0, 83.6, 93.3, 93.8, 2.9, 0.1, 0.0, 0.0, 0.0, 66.3, 94.7, 57.3, 54.4, 33.1, 0.3, 0.2, 0.0, 0.0, 0.0, 29.3, 90.7, 95.9, 96.1, 115.4, 111.0, 86.1, 66.3, 61.6, 0.0, 0.0, 0.0, 0.0, 113.5, 105.1, 0.0, 0.0, 0.0, 0.0, 78.5, 81.2, 110.4, 89.3, 65.7, 1.1, 0.1, 0.0, 0.0, 0.0, 75.7, 78.6, 78.4, 68.3, 68.1, 67.8, 55.0, 49.2, 0.3, 0.0, 0.0, 0.0, 36.1, 56.1, 76.6, 77.1, 77.5, 77.0, 84.5, 84.9, 85.3, 84.8, 84.8, 85.1, 85.6, 85.3, 85.7, 85.9, 86.0, 85.9, 97.9, 123.2, 124.9, 131.3, 133.6, 155.8, 156.8, 158.8, 158.0, 158.3, 158.4, 157.6, 158.5, 158.2, 159.1, 159.4, 158.2, 158.7, 158.4, 157.9, 158.2, 157.8, 158.4, 158.1, 157.4, 152.0, 144.9, 102.5, 98.5, 98.6, 99.1, 98.7, 65.9, 57.4, 0.6, 0.0, 0.0, 54.0, 62.7, 72.1, 66.1, 64.8, 64.6, 63.6, 61.4, 66.5, 66.5, 43.6, 33.8, 29.6, 26.1, 0.0, 0.0, 0.0, 0.0, 0.0, 33.2, 38.2, 38.9, 38.5, 39.5, 41.6, 41.6, 41.6, 41.1, 44.9, 46.6, 47.5, 49.4, 49.5, 49.5, 49.4, 49.1, 0.2, 0.0, 0.0, 0.0, 0.0, 53.0, 50.2, 48.8, 49.4, 49.3, 50.2, 50.0, 50.3, 50.0, 48.2, 37.8, 36.5, 36.6, 37.4, 0.1, 0.0, 0.0, 0.0, 39.9, 41.1, 43.8, 66.3, 68.4, 69.7, 70.3, 68.3, 49.8, 45.5, 38.3, 35.4, 33.6, 2.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.5, 28.2, 37.0, 39.4, 47.2, 47.8, 30.5, 29.3, 28.5, 28.1, 29.2, 27.6, 26.3, 0.0, 0.0, 0.0, 0.0, 20.7, 26.1, 36.5, 37.5, 37.6, 38.5, 38.7, 38.7, 37.2, 36.6, 38.2, 37.7, 37.7, 37.6, 38.5, 0.0, 0.0, 0.0, 0.0, 38.2, 42.1, 45.1, 44.3, 42.2, 41.5, 40.6, 40.1, 39.4, 38.1, 37.1, 37.6, 34.8, 34.3, 33.9, 34.6, 34.6, 0.2, 0.0, 0.0, 0.0, 26.9, 43.1, 68.9, 69.9, 64.3, 63.0, 63.3, 74.4, 78.6, 88.4, 89.9, 89.5, 87.5, 67.6, 60.2, 0.2, 0.0, 0.0, 29.2, 53.0, 62.2, 91.9, 103.1, 108.4, 113.4, 117.5, 139.8, 143.3, 148.8, 149.7, 150.6, 151.3, 155.7, 159.2, 160.6, 160.5, 160.2, 159.7, 160.3, 161.7, 160.5, 161.0, 160.6, 160.3, 159.8, 160.0, 160.2, 160.3, 110.6, 107.1, 105.8, 105.4, 105.0, 104.7, 104.2, 94.2, 91.1, 78.3, 77.0, 76.6, 76.3, 76.6, 76.2, 75.6, 75.1, 76.5, 75.7, 74.0, 34.0, 0.2, 0.0, 0.0, 0.0, 20.8, 25.6, 35.4, 35.4, 35.8, 53.4, 53.4, 51.4, 0.1, 0.0, 0.0, 0.0, 37.0, 76.0, 88.0, 63.8, 63.3, 0.0, 0.0, 0.0, 102.5, 93.5, 53.5, 48.1, 3.2, 0.1, 0.0, 0.0, 0.0, 0.0, 110.0, 109.8, 110.6, 104.5, 87.5, 91.1, 91.4, 47.8, 34.7, 0.0, 0.0, 0.0, 0.0, 62.5, 72.6, 112.0, 105.3, 61.8, 0.4, 0.0, 0.0, 0.0, 63.4, 90.3, 0.2, 0.0, 0.0, 0.0, 0.0, 79.8, 99.9, 102.7, 0.0, 0.0, 0.0, 0.0, 97.5, 100.7, 113.4, 113.4, 113.7, 113.5, 69.9, 39.4, 28.7, 28.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.8, 37.1, 34.0, 68.8, 78.7, 84.8, 87.5, 100.2, 91.3, 86.7, 0.5, 0.0, 0.0, 0.0, 0.0, 22.0, 31.4, 48.3, 0.2, 0.0, 0.0, 0.0, 59.3, 59.3, 69.3, 72.5, 72.5, 72.5, 70.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.9, 54.9, 0.0, 0.0, 0.0, 0.0, 58.9, 82.2, 61.9, 53.5, 28.5, 0.2, 0.0, 0.0, 21.9, 87.7, 84.4, 89.4, 96.6, 107.0, 106.5, 65.2, 54.6, 52.1, 0.1, 0.0, 0.0, 0.0, 99.8, 90.2, 0.1, 0.0, 0.0, 0.0, 77.9, 80.5, 86.8, 78.9, 62.4, 0.3, 0.0, 0.0, 0.0, 69.6, 65.7, 61.9, 35.4, 35.0, 34.6, 29.2, 27.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 76.7, 80.3, 80.3, 80.2, 79.2, 77.9, 89.0, 89.3, 89.8, 88.9, 88.6, 89.0, 89.7, 89.2, 89.7, 89.8, 89.7, 89.8, 99.2, 124.0, 125.0, 131.8, 134.1, 155.4, 157.1, 159.2, 157.9, 158.3, 158.3, 157.4, 158.4, 158.1, 159.1, 159.1, 158.1, 158.7, 158.3, 157.9, 158.4, 158.1, 157.8, 158.2, 157.8, 148.4, 140.8, 97.8, 89.7, 87.0, 84.5, 85.5, 84.9, 51.7, 47.2, 0.3, 0.0, 0.0, 0.0, 0.0, 56.5, 58.7, 82.4, 69.1, 68.1, 68.2, 67.0, 64.1, 64.7, 71.0, 69.8, 63.8, 56.4, 41.2, 33.2, 0.2, 0.0, 0.0, 0.0, 0.0, 26.4, 32.3, 38.9, 38.6, 38.9, 42.2, 42.2, 42.3, 41.8, 45.9, 46.3, 46.5, 39.7, 32.5, 25.6, 12.4, 20.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60,\n        \"min\": 13,\n        \"max\": 99,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          99,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Raw Dataset\n",
        "We want to test the performance of the pre-defined pipeline as a baseline for future experiments. That is, the data won't have any further transformation other than those defined in the `Experiment` class."
      ],
      "metadata": {
        "id": "5JiAkAiE3qUo"
      },
      "id": "5JiAkAiE3qUo"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = duplicate_minor_classes(df['events_sequence'], df.incident_type)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "NZWqprZKULJC",
        "outputId": "0afaad0f-70d4-46b5-866d-00b1234ba696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NZWqprZKULJC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [3:54:55<00:00, 78.31s/it] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, after trainign 180 models with different parameters, we can see that the `GradientBoostingClassifier` had an outstanding performance in comparison to the other models. We'll take the results of a 73.46% mean F1-score and 1.7% std in the K-Fold validation as our baseline for future comparisons."
      ],
      "metadata": {
        "id": "0uZwZBTf8Qv-"
      },
      "id": "0uZwZBTf8Qv-"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "DwWKw3k6UVqB",
        "outputId": "abf011ab-38be-42a7-de7b-7a93aa2d2d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "id": "DwWKw3k6UVqB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "74   GradientBoostingClassifier      Count   Borderline-SMOTE       0.737124   \n",
              "84   GradientBoostingClassifier      Count             ADASYN       0.736198   \n",
              "94   GradientBoostingClassifier      Count  RandomOversampler       0.730578   \n",
              "114  GradientBoostingClassifier      Count        SMOTE-Tomek       0.725896   \n",
              "64   GradientBoostingClassifier      Count              SMOTE       0.724962   \n",
              "24   GradientBoostingClassifier      TFIDF             ADASYN       0.723106   \n",
              "54   GradientBoostingClassifier      TFIDF        SMOTE-Tomek       0.713729   \n",
              "4    GradientBoostingClassifier      TFIDF              SMOTE       0.712790   \n",
              "14   GradientBoostingClassifier      TFIDF   Borderline-SMOTE       0.708135   \n",
              "34   GradientBoostingClassifier      TFIDF  RandomOversampler       0.709056   \n",
              "\n",
              "     Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "74       0.015696     0.737124    0.015696        0.745760       0.015078   \n",
              "84       0.015580     0.736198    0.015580        0.743790       0.020372   \n",
              "94       0.014868     0.730578    0.014868        0.747698       0.016284   \n",
              "114      0.016086     0.725896    0.016086        0.734395       0.020848   \n",
              "64       0.017325     0.724962    0.017325        0.732731       0.019960   \n",
              "24       0.023153     0.723106    0.023153        0.748700       0.033380   \n",
              "54       0.018439     0.713729    0.018439        0.744645       0.016469   \n",
              "4        0.020132     0.712790    0.020132        0.746933       0.026266   \n",
              "14       0.023236     0.708135    0.023236        0.744306       0.023617   \n",
              "34       0.022627     0.709056    0.022627        0.727769       0.019977   \n",
              "\n",
              "      F1 Mean    F1 Std  \n",
              "74   0.734606  0.017097  \n",
              "84   0.734363  0.017607  \n",
              "94   0.728193  0.016961  \n",
              "114  0.722390  0.017341  \n",
              "64   0.720797  0.020280  \n",
              "24   0.720530  0.021870  \n",
              "54   0.712426  0.018053  \n",
              "4    0.710731  0.020392  \n",
              "14   0.707300  0.020308  \n",
              "34   0.706443  0.019665  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d73b100-fceb-4933-b24a-19a4ff722446\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.737124</td>\n",
              "      <td>0.015696</td>\n",
              "      <td>0.737124</td>\n",
              "      <td>0.015696</td>\n",
              "      <td>0.745760</td>\n",
              "      <td>0.015078</td>\n",
              "      <td>0.734606</td>\n",
              "      <td>0.017097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.736198</td>\n",
              "      <td>0.015580</td>\n",
              "      <td>0.736198</td>\n",
              "      <td>0.015580</td>\n",
              "      <td>0.743790</td>\n",
              "      <td>0.020372</td>\n",
              "      <td>0.734363</td>\n",
              "      <td>0.017607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.730578</td>\n",
              "      <td>0.014868</td>\n",
              "      <td>0.730578</td>\n",
              "      <td>0.014868</td>\n",
              "      <td>0.747698</td>\n",
              "      <td>0.016284</td>\n",
              "      <td>0.728193</td>\n",
              "      <td>0.016961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.725896</td>\n",
              "      <td>0.016086</td>\n",
              "      <td>0.725896</td>\n",
              "      <td>0.016086</td>\n",
              "      <td>0.734395</td>\n",
              "      <td>0.020848</td>\n",
              "      <td>0.722390</td>\n",
              "      <td>0.017341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.724962</td>\n",
              "      <td>0.017325</td>\n",
              "      <td>0.724962</td>\n",
              "      <td>0.017325</td>\n",
              "      <td>0.732731</td>\n",
              "      <td>0.019960</td>\n",
              "      <td>0.720797</td>\n",
              "      <td>0.020280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.723106</td>\n",
              "      <td>0.023153</td>\n",
              "      <td>0.723106</td>\n",
              "      <td>0.023153</td>\n",
              "      <td>0.748700</td>\n",
              "      <td>0.033380</td>\n",
              "      <td>0.720530</td>\n",
              "      <td>0.021870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.713729</td>\n",
              "      <td>0.018439</td>\n",
              "      <td>0.713729</td>\n",
              "      <td>0.018439</td>\n",
              "      <td>0.744645</td>\n",
              "      <td>0.016469</td>\n",
              "      <td>0.712426</td>\n",
              "      <td>0.018053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.712790</td>\n",
              "      <td>0.020132</td>\n",
              "      <td>0.712790</td>\n",
              "      <td>0.020132</td>\n",
              "      <td>0.746933</td>\n",
              "      <td>0.026266</td>\n",
              "      <td>0.710731</td>\n",
              "      <td>0.020392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.708135</td>\n",
              "      <td>0.023236</td>\n",
              "      <td>0.708135</td>\n",
              "      <td>0.023236</td>\n",
              "      <td>0.744306</td>\n",
              "      <td>0.023617</td>\n",
              "      <td>0.707300</td>\n",
              "      <td>0.020308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.709056</td>\n",
              "      <td>0.022627</td>\n",
              "      <td>0.709056</td>\n",
              "      <td>0.022627</td>\n",
              "      <td>0.727769</td>\n",
              "      <td>0.019977</td>\n",
              "      <td>0.706443</td>\n",
              "      <td>0.019665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d73b100-fceb-4933-b24a-19a4ff722446')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d73b100-fceb-4933-b24a-19a4ff722446 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d73b100-fceb-4933-b24a-19a4ff722446');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65ed5f1b-eff8-45e9-a84c-79e880a955a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65ed5f1b-eff8-45e9-a84c-79e880a955a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65ed5f1b-eff8-45e9-a84c-79e880a955a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ADASYN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010759299327941806,\n        \"min\": 0.7081347900487034,\n        \"max\": 0.7371243034531174,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7081347900487034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0033352250257654447,\n        \"min\": 0.014867686173950224,\n        \"max\": 0.02323561804044807,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.02323561804044807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010759299327941806,\n        \"min\": 0.7081347900487034,\n        \"max\": 0.7371243034531174,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7081347900487034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0033352250257654447,\n        \"min\": 0.014867686173950224,\n        \"max\": 0.02323561804044807,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.02323561804044807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007276635342255667,\n        \"min\": 0.7277690481770891,\n        \"max\": 0.74869983991458,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7443057361327986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0054539961292792895,\n        \"min\": 0.015078012467183984,\n        \"max\": 0.03337968369906465,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.023617444304868916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010441580812235528,\n        \"min\": 0.7064425484589034,\n        \"max\": 0.7346057994643289,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7073000184885069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017421676362839654,\n        \"min\": 0.016960527884608088,\n        \"max\": 0.021870262814374333,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.020307708487362637\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "h5ZsapdFUWGY",
        "outputId": "d0d6b7d2-2524-4472-c915-f155b79ed603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h5ZsapdFUWGY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Processing folds:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [3:06:28<4:39:43, 5594.35s/it]\n",
            "\n",
            "Processing folds:  20%|â–ˆâ–ˆ        | 1/5 [3:47:59<15:11:59, 13679.78s/it]\u001b[A\n",
            "\n",
            "Processing folds:  20%|â–ˆâ–ˆ        | 1/5 [3:49:04<15:16:17, 13744.42s/it]\u001b[A\u001b[A\n",
            "Processing folds:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [3:49:43<4:44:41, 5693.94s/it]  \u001b[A\n",
            "\n",
            "Processing folds:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [3:49:36<4:43:54, 5678.14s/it]  \u001b[A\u001b[A\n",
            "\n",
            "Processing folds:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [5:27:44<3:12:28, 5774.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "Processing folds:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [5:27:56<58:19, 3499.46s/it]  \u001b[A\u001b[A\n",
            "\n",
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [6:29:43<00:00, 4676.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None the less, using the 180 models to build an ensemble model did not improve the results of the F1 score, since it only achieved a 69.53% mean F1-score with 2.11% of std."
      ],
      "metadata": {
        "id": "cPRerlPW8fhe"
      },
      "id": "cPRerlPW8fhe"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "NBkQcsuUUY1h",
        "outputId": "4e50a8c1-53c6-4bf3-e284-4b1a8dd36569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "id": "NBkQcsuUUY1h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple       0.69875     0.022933     0.69875   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.022933       0.712467      0.020184  0.695395  0.021116  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81bbc75f-8ce8-4999-88fa-d137d1955d96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.69875</td>\n",
              "      <td>0.022933</td>\n",
              "      <td>0.69875</td>\n",
              "      <td>0.022933</td>\n",
              "      <td>0.712467</td>\n",
              "      <td>0.020184</td>\n",
              "      <td>0.695395</td>\n",
              "      <td>0.021116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81bbc75f-8ce8-4999-88fa-d137d1955d96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81bbc75f-8ce8-4999-88fa-d137d1955d96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81bbc75f-8ce8-4999-88fa-d137d1955d96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fe3828af-857e-4c24-bcc8-4d84f48d190b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fe3828af-857e-4c24-bcc8-4d84f48d190b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.698749506384099,\n        \"max\": 0.698749506384099,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.698749506384099\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.02293335297121375,\n        \"max\": 0.02293335297121375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02293335297121375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.698749506384099,\n        \"max\": 0.698749506384099,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.698749506384099\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.02293335297121375,\n        \"max\": 0.02293335297121375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02293335297121375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7124666558302026,\n        \"max\": 0.7124666558302026,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7124666558302026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.020184272631123556,\n        \"max\": 0.020184272631123556,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.020184272631123556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6953948852741979,\n        \"max\": 0.6953948852741979,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6953948852741979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.021115977646801207,\n        \"max\": 0.021115977646801207,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.021115977646801207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Representation A: Keep only the events that occur less than 85% of the time\n",
        "We took the paper provided by SCNB as inspiration to filter out some inherent noise that could affect the results of the previous experiment."
      ],
      "metadata": {
        "id": "buth96_X8LJe"
      },
      "id": "buth96_X8LJe"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "temp = pd.concat([X, y], axis=1)\n",
        "X, y = duplicate_minor_classes(temp.clean_events_sequence, temp.incident_type)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "_aqzrdn9ukm_",
        "outputId": "fa41f328-0ebc-43bf-b710-66683cced61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [2:53:51<00:00, 57.95s/it] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the following table we can see that filtering out the noise negatively impacted the model, since this time we achieved a 3 percentag points lower mean F1-score than our base line, i.e. 70.65% with an almost 3x greater standar deviation."
      ],
      "metadata": {
        "id": "stKf5SUS-B0N"
      },
      "id": "stKf5SUS-B0N"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "vJRyX1Ef2S00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "7ddacd62-99d0-406a-a134-8f08b7479ff5"
      },
      "id": "vJRyX1Ef2S00",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"XGBoost\",\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\",\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SMOTE\",\n          \"SMOTE-Tomek\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008910749085169029,\n        \"min\": 0.6818713450292397,\n        \"max\": 0.7076023391812865,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6818713450292397,\n          0.7076023391812865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007609039717072329,\n        \"min\": 0.024920790353991227,\n        \"max\": 0.04598737602652047,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.039766081871345046,\n          0.02717883049970116\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008910749085169029,\n        \"min\": 0.6818713450292397,\n        \"max\": 0.7076023391812865,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6818713450292397,\n          0.7076023391812865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007609039717072329,\n        \"min\": 0.024920790353991227,\n        \"max\": 0.04598737602652047,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.039766081871345046,\n          0.02717883049970116\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014017293509408418,\n        \"min\": 0.6854704714037174,\n        \"max\": 0.7372838493951874,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7114400666779571,\n          0.7128958120576341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007338089392535259,\n        \"min\": 0.024398866474958467,\n        \"max\": 0.04459423979901609,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04459423979901609,\n          0.030605976955227703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00967912221550702,\n        \"min\": 0.6782207441528543,\n        \"max\": 0.7065883474697503,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.680489837802587,\n          0.701747050428334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0073841350723178505,\n        \"min\": 0.026598660058617267,\n        \"max\": 0.04690202011647799,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0437774376323392,\n          0.03011868037402994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ce8a183c-bd21-4002-b288-c25006cf2e36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.705263</td>\n",
              "      <td>0.045987</td>\n",
              "      <td>0.705263</td>\n",
              "      <td>0.045987</td>\n",
              "      <td>0.737284</td>\n",
              "      <td>0.044418</td>\n",
              "      <td>0.706588</td>\n",
              "      <td>0.046902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.707602</td>\n",
              "      <td>0.027179</td>\n",
              "      <td>0.707602</td>\n",
              "      <td>0.027179</td>\n",
              "      <td>0.712896</td>\n",
              "      <td>0.030606</td>\n",
              "      <td>0.701747</td>\n",
              "      <td>0.030119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.700585</td>\n",
              "      <td>0.025194</td>\n",
              "      <td>0.700585</td>\n",
              "      <td>0.025194</td>\n",
              "      <td>0.705640</td>\n",
              "      <td>0.031134</td>\n",
              "      <td>0.696156</td>\n",
              "      <td>0.027643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.694737</td>\n",
              "      <td>0.037609</td>\n",
              "      <td>0.694737</td>\n",
              "      <td>0.037609</td>\n",
              "      <td>0.699809</td>\n",
              "      <td>0.036222</td>\n",
              "      <td>0.690855</td>\n",
              "      <td>0.037930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.697076</td>\n",
              "      <td>0.028264</td>\n",
              "      <td>0.697076</td>\n",
              "      <td>0.028264</td>\n",
              "      <td>0.704267</td>\n",
              "      <td>0.036849</td>\n",
              "      <td>0.690511</td>\n",
              "      <td>0.029788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.694737</td>\n",
              "      <td>0.033777</td>\n",
              "      <td>0.694737</td>\n",
              "      <td>0.033777</td>\n",
              "      <td>0.701423</td>\n",
              "      <td>0.038474</td>\n",
              "      <td>0.687077</td>\n",
              "      <td>0.036004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.040583</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.040583</td>\n",
              "      <td>0.690905</td>\n",
              "      <td>0.043359</td>\n",
              "      <td>0.681567</td>\n",
              "      <td>0.042450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.683041</td>\n",
              "      <td>0.024921</td>\n",
              "      <td>0.683041</td>\n",
              "      <td>0.024921</td>\n",
              "      <td>0.707413</td>\n",
              "      <td>0.024399</td>\n",
              "      <td>0.680730</td>\n",
              "      <td>0.029407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.681871</td>\n",
              "      <td>0.039766</td>\n",
              "      <td>0.681871</td>\n",
              "      <td>0.039766</td>\n",
              "      <td>0.711440</td>\n",
              "      <td>0.044594</td>\n",
              "      <td>0.680490</td>\n",
              "      <td>0.043777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.686550</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.686550</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.685470</td>\n",
              "      <td>0.026368</td>\n",
              "      <td>0.678221</td>\n",
              "      <td>0.026599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce8a183c-bd21-4002-b288-c25006cf2e36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce8a183c-bd21-4002-b288-c25006cf2e36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce8a183c-bd21-4002-b288-c25006cf2e36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25bbca80-6df9-4719-9192-74587e73815e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25bbca80-6df9-4719-9192-74587e73815e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25bbca80-6df9-4719-9192-74587e73815e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "94  GradientBoostingClassifier      Count  RandomOversampler       0.705263   \n",
              "9                      XGBoost      TFIDF              SMOTE       0.707602   \n",
              "74  GradientBoostingClassifier      Count   Borderline-SMOTE       0.700585   \n",
              "64  GradientBoostingClassifier      Count              SMOTE       0.694737   \n",
              "19                     XGBoost      TFIDF   Borderline-SMOTE       0.697076   \n",
              "39                     XGBoost      TFIDF  RandomOversampler       0.694737   \n",
              "59                     XGBoost      TFIDF        SMOTE-Tomek       0.688889   \n",
              "4   GradientBoostingClassifier      TFIDF              SMOTE       0.683041   \n",
              "54  GradientBoostingClassifier      TFIDF        SMOTE-Tomek       0.681871   \n",
              "99                     XGBoost      Count  RandomOversampler       0.686550   \n",
              "\n",
              "    Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "94      0.045987     0.705263    0.045987        0.737284       0.044418   \n",
              "9       0.027179     0.707602    0.027179        0.712896       0.030606   \n",
              "74      0.025194     0.700585    0.025194        0.705640       0.031134   \n",
              "64      0.037609     0.694737    0.037609        0.699809       0.036222   \n",
              "19      0.028264     0.697076    0.028264        0.704267       0.036849   \n",
              "39      0.033777     0.694737    0.033777        0.701423       0.038474   \n",
              "59      0.040583     0.688889    0.040583        0.690905       0.043359   \n",
              "4       0.024921     0.683041    0.024921        0.707413       0.024399   \n",
              "54      0.039766     0.681871    0.039766        0.711440       0.044594   \n",
              "99      0.026309     0.686550    0.026309        0.685470       0.026368   \n",
              "\n",
              "     F1 Mean    F1 Std  \n",
              "94  0.706588  0.046902  \n",
              "9   0.701747  0.030119  \n",
              "74  0.696156  0.027643  \n",
              "64  0.690855  0.037930  \n",
              "19  0.690511  0.029788  \n",
              "39  0.687077  0.036004  \n",
              "59  0.681567  0.042450  \n",
              "4   0.680730  0.029407  \n",
              "54  0.680490  0.043777  \n",
              "99  0.678221  0.026599  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "iiBWV2LYwC0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16fc2e9-3a75-412e-daea-c523b5053571"
      },
      "id": "iiBWV2LYwC0k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing folds:   0%|          | 0/5 [1:27:10<?, ?it/s]\n",
            "\n",
            "Processing folds:  20%|â–ˆâ–ˆ        | 1/5 [1:39:13<6:36:52, 5953.12s/it]\u001b[A\n",
            "Processing folds:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [1:39:23<2:02:52, 2457.49s/it]\u001b[A\n",
            "Processing folds:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [3:12:23<2:09:26, 3883.40s/it]\u001b[A\n",
            "Processing folds:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [3:18:34<41:36, 2496.67s/it]  \u001b[A\n",
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [4:14:51<00:00, 3058.21s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we built an ensemble model to test if we could achieve a better mean F1-score. Unlike the 1st experiment, we achieced a mea F1-score 2 percentage points greater than the ensemble of the 1st experiment. Nonetheless, it was not enought to outperform the baseline model and also it had a slightly greater standard deviation."
      ],
      "metadata": {
        "id": "gLJiO0G7-iJr"
      },
      "id": "gLJiO0G7-iJr"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "ulsxTrri2UsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0a5f18a2-a17b-4571-a6cd-e0db1382fe31"
      },
      "id": "ulsxTrri2UsF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple      0.715642     0.018258    0.715642   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.018258       0.721418      0.017787  0.710738  0.020569  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-249dbb20-45f5-44bf-b653-632ad3193d56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.715642</td>\n",
              "      <td>0.018258</td>\n",
              "      <td>0.715642</td>\n",
              "      <td>0.018258</td>\n",
              "      <td>0.721418</td>\n",
              "      <td>0.017787</td>\n",
              "      <td>0.710738</td>\n",
              "      <td>0.020569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-249dbb20-45f5-44bf-b653-632ad3193d56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-249dbb20-45f5-44bf-b653-632ad3193d56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-249dbb20-45f5-44bf-b653-632ad3193d56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_82e396d5-2819-4dd4-ace0-ae2c2b16f9f2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_82e396d5-2819-4dd4-ace0-ae2c2b16f9f2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7156421394410074,\n        \"max\": 0.7156421394410074,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7156421394410074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.018257979183405326,\n        \"max\": 0.018257979183405326,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018257979183405326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7156421394410074,\n        \"max\": 0.7156421394410074,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7156421394410074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.018257979183405326,\n        \"max\": 0.018257979183405326,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018257979183405326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7214182590215052,\n        \"max\": 0.7214182590215052,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7214182590215052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.017786801341302557,\n        \"max\": 0.017786801341302557,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.017786801341302557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7107377075649038,\n        \"max\": 0.7107377075649038,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7107377075649038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.020568543906062005,\n        \"max\": 0.020568543906062005,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.020568543906062005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation B: Split events into those before and after the incident"
      ],
      "metadata": {
        "id": "MuLCNXm59Wcd"
      },
      "id": "MuLCNXm59Wcd"
    },
    {
      "cell_type": "code",
      "source": [
        "df_before, df_after = Representations(df).representation_b(df)\n",
        "X, y = duplicate_minor_classes(df_before.events_sequence, df_before['class'])\n",
        "df_before = pd.concat([X, y], axis=1)\n",
        "X, y = duplicate_minor_classes(df_after.events_sequence, df_after['class'])\n",
        "df_after = pd.concat([X, y], axis=1)\n",
        "X, y = pd.concat([df_before.events_sequence, df_after.events_sequence]), pd.concat([df_before['class'], df_after['class']])\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "razuBz2VOucS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca41052f-27c3-4395-f46c-d14e6b3d59e7"
      },
      "id": "razuBz2VOucS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|â–Š         | 18/240 [2:15:51<47:01:55, 762.68s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "eVEC5TGedBmj"
      },
      "id": "eVEC5TGedBmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "dVbpIzWPHctr"
      },
      "id": "dVbpIzWPHctr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "AkbQGcBtHfDi"
      },
      "id": "AkbQGcBtHfDi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation C: Generates fixed length overlappng and non-overlaping sequences out of the provided sequences"
      ],
      "metadata": {
        "id": "aseee5o49YQk"
      },
      "id": "aseee5o49YQk"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_c(df, sequence_length=100)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "A7frHCFPeHhB"
      },
      "id": "A7frHCFPeHhB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "ebD6mRosHlvl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ebD6mRosHlvl"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "rpIj_0FDHlvm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rpIj_0FDHlvm"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "fXlUulj9Hlvn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fXlUulj9Hlvn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "7Vk_xyb-G2Pm"
      },
      "id": "7Vk_xyb-G2Pm"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}