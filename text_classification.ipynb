{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Importation"
      ],
      "metadata": {
        "id": "vXgvhkss9klA"
      },
      "id": "vXgvhkss9klA"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "import pickle\n",
        "from joblib import Parallel, delayed\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import parallel_backend\n",
        "import threading\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Experiment`\n",
        "\n",
        "This class is a pipeline that automates the process of training and testing using cross-validation and prepares the system for ensemble evaluations. This class was developed as pipeline to do experiments more easily, since we want to test all possible model, sampling strategies and vectorizers available.\n",
        "\n",
        "One main limitation is the business knowledge we have, since we don not really understand at a very specific level this dataset, like what exactly each incident is, or what does each event in the events sequence represent, we didn't take any apriori assumtios of the data, and we decided to find by bute force what is the best vectorizer, sampling strategy and model for the given dataset. Additionally, we also tested different representations of the sequences in an attempt of removing any noise we were not aware of. These kinds of knowledge limitations impacted on the results we presented since we are treating the dataset as a black box in certain aspects.\n",
        "\n",
        "For the experiments, we are trateing the sequences of events as if they were words in a text. Therefore, we treated this problem as text classification and defined the pipeline as such. Therefore, we will test the **TFIDF Vectorier, Count Vectorizer and Word2Vec** to understand whichone can infere the best embedding space for the provided event sequences.\n",
        "\n",
        "Since we are dealing with a very small data sample (around 1k observations) we wanted to train our models in oversampled data using different sampling methods and find our which can improve the models performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`__init__(self, X, y)`**\n",
        "\n",
        "This class is initialized with the training data and the target column. Whithin this method it:\n",
        "  - Splits `X` (features) and `y` (labels) into training and test sets using **stratified sampling** to ensure class balance.\n",
        "  - Encodes categorical labels (`y`) into numerical values using `LabelEncoder`.\n",
        "\n",
        "We also initialize the following attributes to be accessible in all parts of the pipeline:\n",
        "  - **`self.X_train`, `self.X_test`, `self.y_train`, `self.y_test`:** Prepared splits for training and testing.\n",
        "  - **`self.trai`ed_models` and `self.trained_vectorizers`:** Empty dictionaries to store trained models and vectorizers.\n",
        "  - **`self.results`:** Stores evaluation results for comparison.\n",
        "  - **`sampling_strategies`:** A dictionary of techniques to handle class imbalance, we are using `SMOTE`, `Borderline-SMOTE`, `ADASYN`, `RandomOversampler`, `SMOTE-ENN`, `SMOTE-Tomek`.\n",
        "  - **`vectorizers`:** A dictionary of methods for text representation, we are using `TFIDF`, `Count`,`Word2Vec`\n",
        "  - **`classifiers`:** A set of preconfigured machine learning models, such as `LogisticRegression`,`DecisionTree`,`RandomForest`,`ExtraTreesClassifier`,`GradientBoostingClassifier`,`AdaBoostClassifier`,`GaussianNB`,`KNN`,`SVM`,`XGBoost`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`duplicate_minor_classes(self, X, y, min_instances=5)`**\n",
        "\n",
        "Balances the dataset by duplicating underrepresented classes until they meet the minimum instance threshold.\n",
        "\n",
        "1. Identifies **minor classes** with fewer samples than `min_instances`.\n",
        "2. Duplicates rows corresponding to these classes.\n",
        "3. Merges the duplicated data back with the original dataset.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name)`**\n",
        "\n",
        "Using cross-validation it evaluates a single combination of **Model**, **Vectorizer** and **Sampler**. It returns a list of evaluation metrics (mean and standard deviation) for the specified combination.\n",
        "\n",
        "1. Splits `X` and `y` into 5 folds using **StratifiedKFold**.\n",
        "2. For each fold:\n",
        "   - Transforms the data with the given vectorizer.\n",
        "   - Balances the data using the sampler.\n",
        "   - Trains the model on the resampled training data.\n",
        "   - Predicts on the validation data.\n",
        "3. Calculates metrics:\n",
        "   - Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1 Score\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **`training(self)`**\n",
        "\n",
        "Runs experiments for all combinations of **Model**, **Vectorizer** and **Sampler**.\n",
        "\n",
        "1. Balances the training data using `duplicate_minor_classes`.\n",
        "2. Constructs a task list of all vectorizer-sampler-model combinations.\n",
        "3. Uses parallel processing to execute each task:\n",
        "   - For each combination, calls `test()` to evaluate.\n",
        "4. Aggregates results into a DataFrame for easy comparison.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_task(self, task, progress_bar)`**\n",
        "\n",
        "Handles a single task from the `training()` pipeline to run it in parallel. Returns evaluation metrics for the task.\n",
        "\n",
        "1. Unpacks the task (vectorizer, sampler, model).\n",
        "2. Executes `test()` for the task.\n",
        "3. Updates the progress bar.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test_ensemble(self)`**\n",
        "\n",
        "Evaluates the performance of an ensemble model across multiple folds. Returns evaluation metrics for the ensemble model.\n",
        "\n",
        "1. Splits the data using `StratifiedKFold`.\n",
        "2. For each fold:\n",
        "   - Trains all models, vectorizers, and samplers on the training data.\n",
        "   - Constructs an ensemble model using `EnsembleModel`.\n",
        "   - Tests the ensemble on the validation set.\n",
        "3. Calculates metrics for the ensembleâ€™s performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_fold(self, X_train, X_test, y_train, y_test)`**\n",
        "\n",
        "Handles training and evaluation for a single fold in `test_ensemble` to be executed in parallel along all other folds. Returns evaluation metrics for the ensemble model for that fold.\n",
        "\n",
        "1. Trains all vectorizers and models on the training data.\n",
        "2. Stores trained models and vectorizers for the fold.\n",
        "3. Fits an ensemble model on the predictions.\n",
        "4. Evaluates the ensemble on the validation set.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fr_q4Q0M63DE"
      },
      "id": "Fr_q4Q0M63DE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Word2VecVectorizer`\n",
        "This class converts sentences into numerical vectors using Word2Vec, which captures the semantic meaning of words. This class was defined to provide an interface similar to Scikit-Learn interface and avoid syntaxis issues later on in the `Experiment` class.\n",
        "\n",
        " - `__init__`: Lets you configure how the Word2Vec model works:\n",
        "   - `size` is the number of dimensions for word vectors (e.g., 100-dimensional space).\n",
        "   - `window` is the maximum distance between the current and predicted words.\n",
        "   - `min_count` is the minimum number of times a word must appear to be included in the model.\n",
        "   - `workers` determines how many CPU threads to use for training (faster with more workers).\n",
        " - `fit`: Takes a list of sentences, splits them into words, and trains a Word2Vec model to learn relationships between words.\n",
        " - `transform`: Takes sentences and converts them into vectors. It does this by averaging the vectors of all words in a sentence. If a word isn't in the Word2Vec model, it is ignored, and zeros are used instead.\n",
        " - `fit_transform`: A convenience method that combines the `fit` (training) and `transform` (vectorizing) steps.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SgzoRMgu6W0K"
      },
      "id": "SgzoRMgu6W0K"
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.\n",
        "                                 size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoSampler(TransformerMixin):\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return X, y\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X, y\n",
        "\n",
        "    def fit_resample(self, X, y=None):\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "B4W8MlJVFVf-"
      },
      "id": "B4W8MlJVFVf-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.le = LabelEncoder()\n",
        "        self.y = self.le.fit_transform(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "        self.y_train = self.le.transform(self.y_train)\n",
        "        self.y_test = self.le.transform(self.y_test)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            \"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1),\n",
        "            \"NoSamp\": NoSampler()\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            \"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            \"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1)\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False, n_jobs = 2),\n",
        "        }\n",
        "\n",
        "\n",
        "    def duplicate_minor_classes(self, X, y, min_instances=10):\n",
        "        X = X.reset_index(drop=True)\n",
        "        y  = y.reset_index(drop=True)\n",
        "        class_counts = y.value_counts()\n",
        "\n",
        "        minor_classes = class_counts[class_counts <= min_instances].index\n",
        "\n",
        "        minor_class_rows = X.loc[y.isin(minor_classes)]\n",
        "        minor_class_labels = y.loc[y.isin(minor_classes)]\n",
        "\n",
        "        duplicated_X = pd.concat([minor_class_rows] * 2, ignore_index=True)\n",
        "        duplicated_y = pd.concat([minor_class_labels] * 2, ignore_index=True)\n",
        "\n",
        "        X_balanced = pd.concat([X, duplicated_X], ignore_index=True)\n",
        "        y_balanced = pd.concat([y, duplicated_y], ignore_index=True)\n",
        "\n",
        "        X_balanced.reset_index(drop=True, inplace=True)\n",
        "        y_balanced.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_balanced, y_balanced\n",
        "\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "\n",
        "            X_train, y_train = self.duplicate_minor_classes(X_train, pd.Series(y_train))\n",
        "\n",
        "\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average=\"weighted\"))\n",
        "            precisions.append(precision_score(y_test, y_pred, average=\"weighted\"))\n",
        "            f1s.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "        return [\n",
        "            model_name,\n",
        "            vectorizer_name,\n",
        "            sampler_name,\n",
        "            np.mean(accuracies),\n",
        "            np.std(accuracies),\n",
        "            np.mean(recalls),\n",
        "            np.std(recalls),\n",
        "            np.mean(precisions),\n",
        "            np.std(precisions),\n",
        "            np.mean(f1s),\n",
        "            np.std(f1s),\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        task_list = []\n",
        "\n",
        "        for vect_name, vectorizer in self.vectorizers.items():\n",
        "            for samp_name, sampler in self.sampling_strategies.items():\n",
        "                for clf_name, model in self.classifiers.items():\n",
        "                    task_list.append(\n",
        "                        (clf_name, vect_name, samp_name, deepcopy(model), deepcopy(vectorizer), deepcopy(sampler))\n",
        "                    )\n",
        "\n",
        "        progress_bar = tqdm(total=len(task_list))\n",
        "        with parallel_backend(\"threading\"):\n",
        "            parallel_results = Parallel(n_jobs=-1)(\n",
        "                delayed(self._process_task)(task, progress_bar) for task in task_list\n",
        "            )\n",
        "\n",
        "        results.extend(parallel_results)\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Save results and models\n",
        "        self.results = pd.DataFrame(\n",
        "            results,\n",
        "            columns=[\n",
        "                \"Model\",\n",
        "                \"Vectorizer\",\n",
        "                \"Sampler\",\n",
        "                \"Accuracy Mean\",\n",
        "                \"Accuracy Std\",\n",
        "                \"Recall Mean\",\n",
        "                \"Recall Std\",\n",
        "                \"Precision Mean\",\n",
        "                \"Precision Std\",\n",
        "                \"F1 Mean\",\n",
        "                \"F1 Std\",\n",
        "            ],\n",
        "        )\n",
        "        return self.results\n",
        "\n",
        "    def _process_task(self, task, progress_bar):\n",
        "        clf_name, vect_name, samp_name, model, vectorizer, sampler = task\n",
        "        result = self.test(\n",
        "            model=model,\n",
        "            model_name=clf_name,\n",
        "            vectorizer=vectorizer,\n",
        "            vectorizer_name=vect_name,\n",
        "            sampler=sampler,\n",
        "            sampler_name=samp_name,\n",
        "        )\n",
        "        progress_bar.update(1)\n",
        "        return result\n",
        "\n",
        "    def test_ensemble(self):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        tasks = []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "            X_train, y_train = self.duplicate_minor_classes(X_train, pd.Series(y_train))\n",
        "            tasks.append((X_train, X_test, y_train, y_test))\n",
        "\n",
        "        total_tasks = len(tasks)\n",
        "        progress_bar = tqdm(total=total_tasks, desc=\"Processing folds\")\n",
        "        lock = threading.Lock()  # Lock to manage updates safely across threads\n",
        "\n",
        "        def process_with_progress(*args):\n",
        "            result = self._process_fold(*args)\n",
        "            with lock:\n",
        "                progress_bar.update(1)\n",
        "            return result\n",
        "\n",
        "        with parallel_backend(\"threading\"):\n",
        "            results = Parallel(n_jobs=-1)(\n",
        "                delayed(process_with_progress)(X_train, X_test, y_train, y_test)\n",
        "                for X_train, X_test, y_train, y_test in tasks\n",
        "            )\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        accuracies, recalls, precisions, f1s = zip(*results)\n",
        "\n",
        "        return [\n",
        "            \"Ensemble\", \"Multiple\", \"Multiple\",\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def _process_fold(self, X_train, X_test, y_train, y_test):\n",
        "        fold_trained_models = {}\n",
        "        fold_trained_vectorizers = {}\n",
        "\n",
        "        for vectorizer_name, vectorizer_i in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(vectorizer_i)\n",
        "            X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test_vect = vectorizer.transform(X_test).toarray()\n",
        "            fold_trained_vectorizers[vectorizer_name] = vectorizer\n",
        "\n",
        "            for sampler_name, sampler_i in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(sampler_i)\n",
        "                X_resampled, y_resampled = sampler.fit_resample(X_train_vect, y_train)\n",
        "\n",
        "                for model_name, model in self.classifiers.items():\n",
        "                    trained_model = deepcopy(model)\n",
        "                    trained_model.fit(X_resampled, y_resampled)\n",
        "                    fold_trained_models[(vectorizer_name, sampler_name, model_name)] = trained_model\n",
        "\n",
        "        ensemble = EnsembleModel(fold_trained_models, fold_trained_vectorizers)\n",
        "        ensemble.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = ensemble.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "        return accuracy, recall, precision, f1\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`EnsembleModel`\n",
        "\n",
        "This class combines predictions from multiple models to make a more accurate \"group decision.\"\n",
        " - `__init__`: Takes two things:\n",
        "   - A dictionary of trained models.\n",
        "   - A dictionary of vectorizers (tools that convert text into numbers).\n",
        "   It stores these for use during prediction and training.\n",
        " - `_generate_prediction_matrix`: This creates a matrix where:\n",
        "   - Each row corresponds to an input sample.\n",
        "   - Each column is a model's prediction probabilities for each class.\n",
        " - `fit`: Uses an optimization algorithm (`differential_evolution`) to find the best set of weights for combining the model predictions. The goal is to maximize prediction performance (e.g., F1-score).\n",
        " - `predict`: Uses the optimized weights to combine predictions from all models and makes the final decision by selecting the class with the highest combined probability."
      ],
      "metadata": {
        "id": "JmL3JegE6lTx"
      },
      "id": "JmL3JegE6lTx"
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        def fitness(weights):\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Representations`\n",
        "\n",
        "This class creates different ways to represent sequences of events for machine learning analysis.\n",
        " - `representation_a`: Focuses on filtering events:\n",
        "   - Counts the frequency of each event in all sequences.\n",
        "   - Keeps only the events that occur less than 85% of the time, filtering out common noise.\n",
        "   - Outputs a \"cleaned\" sequence of events and the labels (e.g., incident types).\n",
        " - `representation_b`: Splits event sequences into two parts:\n",
        "   - Events *before* an incident (labeled with the incident type).\n",
        "   - Events *after* an incident (labeled as \"unknown\").\n",
        " - `representation_c`: Breaks sequences into overlapping chunks:\n",
        "   - For example, if you have a sequence of 50 events, it divides them into smaller parts (e.g., chunks of 30 events with 15 overlapping).\n",
        "   - Each chunk is labeled with the incident type.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7kLLXN5Y6viF"
      },
      "id": "7kLLXN5Y6viF"
    },
    {
      "cell_type": "code",
      "source": [
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)\n",
        "\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)\n",
        "            )\n",
        "\n",
        "            self.y = df['incident_type'].copy()\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n",
        "\n",
        "  def representation_b(self, df):\n",
        "\n",
        "    before_incident = []\n",
        "    after_incident = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        before_events = \" \".join([str(event) for event, time in zip(events, seconds) if time <= 0])\n",
        "        if before_events:\n",
        "            before_incident.append({\n",
        "                \"events_sequence\": before_events,\n",
        "                \"class\": incident_type\n",
        "            })\n",
        "\n",
        "        after_events = \" \".join([str(event) for event, time in zip(events, seconds) if time > 0])\n",
        "        if after_events:\n",
        "            after_incident.append({\n",
        "                \"events_sequence\": after_events,\n",
        "                \"class\": 100\n",
        "            })\n",
        "\n",
        "    before_df = pd.DataFrame(before_incident)\n",
        "    after_df = pd.DataFrame(after_incident)\n",
        "\n",
        "    return before_df, after_df\n",
        "\n",
        "\n",
        "  def representation_c(self, df, sequence_length=30):\n",
        "\n",
        "    overlapping_sequences = []\n",
        "    step = sequence_length // 2\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        for i in range(0, len(events) - sequence_length + 1, step):\n",
        "            sequence = [str(i) for i in events[i:i + sequence_length]]\n",
        "            seconds_slice = seconds[i:i + sequence_length]\n",
        "            sequence_class = incident_type\n",
        "\n",
        "            overlapping_sequences.append({\"sequence\": \" \".join(sequence), \"class\": sequence_class})\n",
        "\n",
        "    sequences_df = pd.DataFrame(overlapping_sequences)\n",
        "    return sequences_df.sequence, sequences_df['class']\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "ic7u7acl7qJj"
      },
      "id": "ic7u7acl7qJj"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "e01572fb-ad9e-4de3-ea4b-6ecc6d58a0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "972      4610651  [1024, 1024, 1024, 1024, 1024, 1024, 1024, 102...   \n",
              "375      4451415  [563, 563, 563, 563, 563, 563, 563, 563, 563, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "972  [2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "375  [2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "972  [-14366, -14349, -14339, -14312, -14305, -1430...   50.471103   \n",
              "375  [-14380, -14360, -14358, -14354, -14344, -1433...   51.017457   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "972    5.689640  [18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84....   \n",
              "375    4.882375  [99.0, 97.1, 97.0, 96.6, 94.7, 93.7, 88.9, 84....   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "972  [False, False, False, False, False, False, Fal...   \n",
              "375  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "972  [True, True, True, True, True, True, True, Tru...             99  \n",
              "375  [True, True, True, True, True, True, True, Tru...              9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4af6b15-4f94-47c7-b81b-7804781ed3c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>4610651</td>\n",
              "      <td>[1024, 1024, 1024, 1024, 1024, 1024, 1024, 102...</td>\n",
              "      <td>[2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14366, -14349, -14339, -14312, -14305, -1430...</td>\n",
              "      <td>50.471103</td>\n",
              "      <td>5.689640</td>\n",
              "      <td>[18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84....</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>4451415</td>\n",
              "      <td>[563, 563, 563, 563, 563, 563, 563, 563, 563, ...</td>\n",
              "      <td>[2956, 2956, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14380, -14360, -14358, -14354, -14344, -1433...</td>\n",
              "      <td>51.017457</td>\n",
              "      <td>4.882375</td>\n",
              "      <td>[99.0, 97.1, 97.0, 96.6, 94.7, 93.7, 88.9, 84....</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4af6b15-4f94-47c7-b81b-7804781ed3c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4af6b15-4f94-47c7-b81b-7804781ed3c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4af6b15-4f94-47c7-b81b-7804781ed3c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-489e82f0-1553-4c8a-afba-46f8dbcff64b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-489e82f0-1553-4c8a-afba-46f8dbcff64b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-489e82f0-1553-4c8a-afba-46f8dbcff64b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112596,\n        \"min\": 4451415,\n        \"max\": 4610651,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4451415,\n          4610651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563, 563]\",\n          \"[1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 4180, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4180, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4180, 4068, 2686, 2708, 3234, 4026, 4016, 4026, 4020, 3658, 4068, 3658, 4066, 3658, 4066, 3658, 4068, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4068, 3658, 4066, 3658, 4068, 4056, 4032, 4026, 2708, 2742, 2740, 4030, 4018, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2744, 4026, 2744, 2706, 3636, 3658, 4124, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4394, 1666, 4066, 3636, 3658, 4124, 3620, 2684, 4124, 4126, 4124, 4124, 2708, 4124, 4124, 4124, 2858, 4124, 4126, 4124, 4124, 4126, 4124, 2706, 3634, 4124, 4066, 3634, 4066, 3634, 4066, 4124, 3636, 3658, 3236, 2708, 4124, 3236, 2708, 3986, 4004, 2852, 4110, 2854, 4026, 2708, 2744, 4026, 4030, 4018, 4140, 4148, 4140, 4140, 4152, 2554, 4168, 4156, 4168, 2706, 4124, 4072, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956]\",\n          \"[2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4168, 4140, 4158, 4140, 4162, 4160, 4168, 2956, 2584, 2556, 2956, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2708, 2744, 4124, 4068, 3636, 3658, 4148, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4140, 2956, 4140, 4162, 4150, 4152, 4168, 4156, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 2956, 2956, 4068, 2686, 2708, 2742, 4158, 3760, 3768, 3636, 3658, 2886, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4168, 4140, 2956, 2956, 4140, 4162, 4160, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-14380, -14360, -14358, -14354, -14344, -14335, -14329, -14325, -14323, -14289, -14271, -14270, -14249, -14238, -14217, -14201, -14188, -14171, -14162, -14139, -14108, -14093, -14086, -14008, -13984, -13949, -13942, -13936, -13924, -13916, -13903, -13895, -13887, -13862, -13847, -13827, -13807, -13768, -13766, -13741, -13731, -13729, -13689, -13682, -13665, -13658, -13654, -13650, -13634, -13628, -13615, -13610, -13600, -13596, -13579, -13565, -13558, -13544, -13542, -13515, -13508, -13503, -13460, -13457, -13448, -13432, -13426, -13410, -13407, -13405, -13383, -13372, -13369, -13294, -13294, -13248, -13228, -13221, -13186, -13184, -13168, -13166, -13147, -13144, -13120, -13116, -13089, -13040, -13013, -13012, -12986, -12949, -12318, -12317, -12316, -12315, -11311, -11054, -10951, -10756, -10727, -10470, -10384, -10093, -10038, -9667, -9640, -9457, -9419, -9235, -9200, -8934, -8894, -8732, -8693, -8350, -8200, -7873, -7845, -7096, -7066, -7065, -7061, -6849, -6849, -6844, -6833, -6832, -6756, -6756, -6704, -6682, -6673, -6615, -6558, -6506, -6488, -6485, -6472, -6440, -6431, -6429, -6422, -6411, -6401, -6396, -6393, -6391, -6390, -6388, -6305, -6296, -6232, -6211, -6211, -6201, -6154, -6031, -6030, -5997, -5987, -5983, -5953, -5940, -5937, -5909, -5887, -5887, -5870, -5845, -5804, -5801, -5790, -5788, -5774, -5763, -5761, -5750, -5728, -5716, -5708, -5696, -5695, -5685, -5683, -5647, -5633, -5633, -5555, -5505, -5466, -5440, -5431, -5427, -5416, -5404, -5395, -5364, -5347, -5347, -5312, -5276, -5264, -5243, -5233, -5231, -5175, -5155, -5155, -5073, -5006, -4966, -4957, -4953, -4920, -4905, -4897, -4857, -4765, -4765, -4746, -4726, -4711, -4705, -4695, -4691, -4670, -4668, -4660, -4433, -4432, -4394, -4385, -4382, -4335, -4287, -4287, -4277, -4219, -4209, -4204, -4196, -4170, -4160, -4130, -4129, -4018, -4017, -4010, -3980, -3968, -3966, -3930, -3922, -3913, -3905, -3893, -3878, -3871, -3863, -3786, -3749, -3740, -3630, -3630, -927, -792, -636, -636, -609, -479, -458, -446, -438, -427, -403, -394, -384, -377, -341, -339, -328, -300, -293, -169, -167, -125, -113, -77, -72, -65, -60, -24, -24, -19, -3, -3, 13, 20, 33, 36, 62, 65, 84, 135, 142, 210, 221, 226, 262, 276, 314, 327, 338, 444, 453, 704, 712, 721, 723, 737, 739, 775, 791, 838, 838, 918, 922, 947, 957, 962, 977, 1175, 1177, 1177, 1179, 1180, 1225, 1225, 1225, 1232, 1234, 1239, 1240, 1241, 1242, 1243, 1249, 1249, 1252, 1253, 1268, 1324, 1485, 1501, 1502, 1545, 1567, 1779, 1790, 2212, 2218, 2220, 2238, 2240, 2247, 2251, 2274, 2302, 2302, 2346, 2356, 2360, 2367, 2389, 2398, 2423, 2426, 2429, 2468, 2476, 2515, 2529, 2529, 2599, 2626, 2634, 2643, 2657, 2672, 2695, 2695, 2735, 2744, 2755, 2769, 2777, 2801, 2803, 2838, 2870, 2878, 2914, 2931, 2931, 2978, 2986, 3005, 3016, 3021, 3032, 3044, 3050, 3063, 3074, 3076, 3086, 3088, 3113, 3115, 3130, 3144, 3144, 3182, 3184, 3222, 3226, 3236, 3266, 3267, 3337, 3353, 3362, 3405, 3420, 3420, 3451, 3576, 3578, 3579, 3581, 3584, 3588, 3599]\",\n          \"[-14366, -14349, -14339, -14312, -14305, -14304, -14293, -14290, -14274, -14272, -14261, -14260, -14233, -14231, -14210, -14204, -14183, -14183, -14149, -14131, -14111, -14106, -14104, -14101, -14093, -14086, -14083, -14081, -14032, -14016, -13946, -13860, -13792, -13774, -13741, -13726, -13714, -13685, -13682, -13627, -13625, -13619, -13614, -13587, -13575, -13572, -13533, -13525, -13520, -13478, -13458, -13406, -13406, -13350, -13325, -13313, -13284, -13281, -13221, -13209, -13205, -13166, -13146, -13146, -13065, -13062, -13023, -13010, -12984, -12982, -12971, -12969, -12933, -12931, -12904, -12861, -12861, -12797, -12753, -12748, -12725, -12712, -12709, -12703, -12679, -12675, -12674, -12670, -12669, -12668, -12667, -12667, -12652, -12641, -12638, -12632, -12613, -12591, -12543, -12531, -12521, -12474, -12467, -12433, -12430, -12418, -12367, -12327, -12327, -12286, -12262, -12238, -12222, -12221, -12208, -12169, -12055, -12009, -12003, -11960, -11942, -11724, -11691, -11688, -11678, -11668, -11656, -11653, -11641, -11630, -11618, -11574, -11492, -11438, -11406, -11394, -11388, -11345, -11328, -11186, -11163, -11123, -11123, -11044, -11027, -10993, -10991, -10976, -10974, -10942, -10933, -10921, -10906, -10883, -10883, -10844, -10824, -10801, -10794, -10779, -10778, -10760, -10746, -10728, -10716, -10677, -10642, -10628, -10603, -10566, -10558, -10493, -10459, -10426, -10397, -10370, -10368, -10353, -10308, -10288, -10279, -10262, -10220, -10220, -10156, -10115, -10101, -10029, -9880, -9828, -9826, -9771, -9769, -9723, -9722, -9706, -9636, -9612, -9606, -9576, -9576, -9575, -5795, -5697, -5669, -5004, -5004, -4964, -4959, -4927, -4847, -4836, -4828, -4800, -4797, -4743, -4740, -4690, -4551, -4483, -4469, -4440, -4418, -4416, -4376, -4376, -4363, -4334, -4323, -4303, -4259, -4246, -4244, -4219, -4192, -4161, -4127, -4065, -4057, -4020, -3996, -3982, -3948, -3909, -3893, -3861, -3842, -3809, -3808, -3801, -3797, -3795, -3783, -3769, -3755, -3730, -3730, -3728, -3675, -3642, -3623, -3586, -3574, -3536, -3506, -3506, -3476, -3342, -3325, -3285, -3279, -3268, -3238, -3184, -3106, -3066, -3054, -3043, -3032, -3029, -3018, -3009, -3001, -2999, -2969, -2754, -2735, -2697, -2690, -2649, -2548, -2513, -2502, -2501, -2489, -2470, -2455, -2438, -2436, -2412, -2412, -2385, -2334, -2321, -2291, -2285, -2241, -2231, -2176, -2144, -2138, -2115, -2089, -2086, -2084, -2079, -2072, -2069, -2059, -2033, -1990, -1971, -1962, -1939, -1939, -1893, -1876, -1847, -1833, -1819, -1793, -1781, -1756, -1743, -1740, -1686, -1669, -1669, -1599, -1596, -1529, -1527, -1498, -1486, -1466, -1443, -1411, -1411, -1381, -1349, -1342, -1337, -1304, -1292, -1290, -1253, -1248, -1243, -1200, -1187, -1184, -1155, -1142, -1124, -1091, -1072, -1064, -1051, -1047, -997, -966, -938, -866, -806, -804, -791, -786, -779, -767, -752, -737, -727, -706, -695, -695, -684, -644, -641, -591, -590, -577, -560, -558, -547, -546, -540, -522, -517, -513, -510, -497, -486, -484, -479, -349, -349, -295, -295, -26, -26, 682, 889, 941, 960, 973, 1013, 1026, 1029, 1048, 1049, 1051, 1069, 1081, 1082, 1107, 1109, 1126, 1132, 1146, 1146, 1186, 1205, 1225, 1231, 1233, 1236, 1244, 1251, 1254, 1256, 1301, 1317, 1388, 1472, 1567, 1604, 1640, 1655, 1667, 1695, 1698, 1813, 1819, 1835, 1853, 1918, 1951, 1959, 2067, 2088, 2100, 2143, 2155, 2157, 2175, 2175, 2193, 2229, 2250, 2263, 2292, 2295, 2349, 2360, 2363, 2392, 2405, 2405, 2481, 2484, 2520, 2533, 2575, 2582, 2618, 2626, 2633, 2682, 2684, 2706, 2725, 2725, 2755, 2801, 2806, 2828, 2842, 2848, 2888, 2889, 2894, 2897, 2899, 2905, 2907, 2909, 2927, 2947, 2970, 3017, 3028, 3037, 3081, 3087, 3117, 3119, 3130, 3171, 3209, 3209, 3216, 3246, 3263, 3282, 3294, 3305, 3339, 3440, 3481, 3487, 3526, 3542]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3863307306809311,\n        \"min\": 50.47110252894736,\n        \"max\": 51.01745668783784,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          51.01745668783784,\n          50.47110252894736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5708224185261195,\n        \"min\": 4.882374955855855,\n        \"max\": 5.689639761842105,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.882374955855855,\n          5.689639761842105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[99.0, 97.1, 97.0, 96.6, 94.7, 93.7, 88.9, 84.9, 84.5, 60.4, 56.2, 55.5, 49.1, 45.5, 59.2, 77.7, 78.5, 80.2, 62.7, 40.2, 35.9, 26.7, 0.3, 0.0, 0.0, 29.9, 36.3, 43.6, 39.2, 38.0, 50.3, 66.5, 77.1, 75.3, 73.1, 70.4, 75.3, 108.5, 110.0, 110.0, 106.9, 106.1, 107.0, 105.3, 95.0, 86.9, 86.7, 86.7, 84.6, 83.8, 79.3, 77.7, 75.7, 76.6, 78.1, 80.5, 79.7, 83.5, 87.0, 97.7, 90.0, 83.9, 31.4, 30.3, 32.0, 55.9, 52.8, 42.9, 42.0, 40.0, 21.8, 8.1, 0.2, 0.0, 0.0, 0.0, 14.1, 19.8, 57.2, 57.7, 55.0, 53.8, 46.3, 44.5, 36.5, 35.7, 28.0, 12.1, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.8, 0.0, 0.2, 0.0, 1.8, 0.0, 0.2, 0.0, 0.2, 0.0, 1.1, 0.0, 1.6, 0.0, 0.2, 0.0, 0.4, 0.0, 0.5, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.8, 26.3, 37.9, 37.6, 45.6, 69.7, 72.5, 86.9, 117.3, 118.6, 117.1, 118.0, 118.5, 117.9, 117.8, 117.3, 116.7, 116.9, 116.8, 115.4, 110.7, 0.2, 0.0, 0.0, 0.0, 52.1, 114.2, 114.5, 92.1, 88.2, 87.9, 81.2, 58.8, 52.1, 0.3, 0.0, 0.0, 0.0, 23.7, 71.0, 73.3, 80.8, 82.1, 83.0, 83.8, 84.0, 84.3, 87.6, 87.9, 87.1, 86.0, 85.6, 78.3, 75.5, 0.0, 0.0, 0.0, 76.8, 133.3, 130.1, 123.4, 116.1, 110.9, 98.4, 78.3, 62.7, 0.2, 0.0, 0.0, 22.1, 86.3, 101.0, 117.8, 114.2, 113.0, 0.1, 0.0, 0.0, 83.5, 89.5, 80.6, 78.6, 78.4, 72.8, 63.8, 50.2, 0.0, 0.0, 0.0, 0.0, 20.6, 50.9, 61.4, 77.1, 81.5, 101.1, 103.2, 108.7, 108.1, 107.8, 91.6, 81.0, 77.7, 0.2, 0.0, 0.0, 0.0, 58.4, 76.2, 82.0, 92.0, 119.2, 127.2, 132.1, 131.8, 95.0, 95.0, 93.8, 88.2, 84.0, 83.0, 71.5, 65.9, 61.5, 57.7, 52.1, 40.5, 37.5, 36.8, 32.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.2, 37.8, 35.7, 36.0, 36.1, 48.3, 56.8, 64.2, 68.9, 88.1, 89.0, 93.8, 99.8, 99.9, 99.2, 99.3, 90.8, 88.4, 83.8, 84.1, 84.0, 77.6, 3.5, 3.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 16.0, 15.9, 17.6, 17.1, 18.6, 17.4, 134.5, 116.2, 116.9, 112.8, 111.2, 96.2, 78.1, 0.1, 0.0, 0.0, 56.9, 81.0, 90.0, 103.5, 119.6, 117.8, 117.6, 117.8, 118.4, 139.2, 136.1, 1.6, 0.0, 0.0, 120.7, 133.8, 119.6, 103.7, 58.7, 0.7, 0.0, 0.0, 64.6, 87.0, 106.7, 125.2, 135.3, 136.5, 137.4, 137.2, 137.3, 131.6, 0.3, 0.0, 0.0, 84.9, 100.5, 89.8, 88.5, 88.5, 87.9, 88.5, 88.8, 87.7, 87.8, 87.6, 86.3, 85.9, 64.0, 56.8, 0.2, 0.0, 0.0, 64.7, 68.8, 87.2, 87.7, 100.8, 117.8, 118.1, 116.7, 111.9, 108.6, 0.7, 0.0, 0.0, 44.0, 116.6, 116.9, 117.1, 116.7, 117.3, 117.7, 118.1]\",\n          \"[18.8, 22.5, 26.8, 72.9, 75.3, 74.8, 83.1, 84.6, 85.7, 85.3, 82.4, 82.5, 65.3, 62.2, 18.1, 1.5, 0.0, 0.0, 27.8, 68.5, 87.1, 85.7, 85.2, 85.2, 85.4, 84.4, 83.6, 82.4, 55.5, 55.5, 52.7, 51.3, 55.2, 54.0, 61.2, 80.0, 86.5, 85.0, 84.4, 80.9, 80.3, 80.3, 81.5, 81.8, 85.1, 85.9, 84.6, 83.1, 82.0, 38.1, 0.8, 0.0, 0.0, 49.3, 84.0, 87.3, 81.6, 81.3, 77.1, 72.7, 72.2, 1.0, 0.0, 0.0, 75.2, 78.0, 83.2, 84.3, 82.9, 82.8, 80.4, 80.1, 48.2, 45.6, 0.4, 0.0, 0.0, 29.2, 39.5, 38.5, 48.8, 75.0, 74.1, 73.3, 69.4, 69.0, 69.2, 69.2, 69.0, 68.9, 68.5, 68.7, 63.3, 59.6, 59.0, 56.8, 64.8, 70.0, 82.4, 79.9, 83.5, 84.9, 82.6, 86.0, 87.5, 86.5, 0.4, 0.0, 0.0, 24.3, 60.9, 66.4, 71.8, 72.8, 81.6, 83.5, 87.4, 88.3, 87.3, 85.3, 72.6, 56.4, 87.6, 86.8, 82.8, 88.1, 85.6, 85.4, 86.0, 88.7, 85.2, 86.3, 88.5, 96.0, 88.3, 89.6, 91.3, 85.7, 87.3, 44.4, 2.4, 0.0, 0.0, 58.5, 65.0, 62.5, 61.8, 56.3, 55.9, 54.2, 52.6, 40.1, 2.2, 0.0, 0.0, 18.8, 37.6, 59.1, 55.9, 54.2, 55.1, 68.9, 84.2, 88.8, 87.1, 84.9, 86.0, 80.0, 88.0, 95.5, 95.9, 88.9, 81.6, 85.1, 80.3, 61.6, 60.0, 59.5, 60.0, 42.4, 33.0, 1.9, 0.0, 0.0, 41.5, 69.6, 69.5, 83.9, 90.2, 97.2, 98.4, 95.6, 96.5, 79.1, 78.0, 56.2, 29.7, 10.4, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 12.3, 92.9, 94.9, 90.7, 91.2, 91.5, 94.8, 94.7, 94.2, 86.8, 73.8, 77.1, 69.4, 3.5, 0.1, 0.0, 0.0, 0.0, 22.1, 40.8, 56.4, 67.1, 68.3, 68.1, 87.2, 89.2, 87.9, 89.0, 95.6, 94.7, 89.7, 85.2, 86.9, 86.8, 71.9, 54.2, 52.7, 56.5, 55.4, 55.4, 57.5, 58.0, 57.8, 58.9, 49.6, 2.9, 0.0, 0.0, 0.0, 55.4, 55.5, 56.1, 79.5, 87.3, 1.7, 0.0, 0.0, 40.6, 87.8, 90.1, 97.3, 97.4, 96.4, 98.2, 85.9, 97.4, 88.4, 88.2, 87.6, 97.3, 96.4, 96.2, 97.4, 97.9, 97.3, 63.0, 65.1, 89.5, 98.1, 98.5, 95.2, 98.3, 90.3, 86.5, 86.5, 87.3, 84.6, 57.2, 2.1, 0.0, 0.0, 0.0, 0.0, 96.4, 98.2, 95.3, 93.0, 88.1, 89.1, 86.6, 77.7, 77.3, 77.7, 74.8, 74.6, 74.4, 72.1, 61.2, 60.5, 55.0, 39.5, 32.4, 28.9, 0.1, 0.0, 0.0, 32.7, 35.0, 46.9, 68.3, 85.2, 82.8, 82.5, 84.6, 82.4, 81.9, 0.2, 0.0, 0.0, 62.8, 66.8, 88.1, 87.9, 88.5, 88.1, 79.0, 0.2, 0.0, 0.0, 21.6, 88.0, 87.6, 86.6, 88.6, 88.2, 89.2, 89.4, 88.7, 88.3, 83.8, 82.9, 83.3, 83.6, 71.6, 52.7, 56.1, 55.5, 54.3, 53.3, 53.0, 57.0, 56.2, 55.1, 54.6, 82.0, 84.9, 87.7, 86.9, 86.8, 87.5, 84.8, 57.1, 43.0, 0.5, 0.0, 0.0, 0.0, 36.3, 36.3, 61.3, 62.4, 83.5, 86.3, 86.0, 83.9, 83.4, 81.7, 60.6, 50.9, 45.8, 45.5, 27.6, 2.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.6, 17.7, 21.2, 48.9, 37.5, 37.2, 59.5, 62.0, 66.4, 86.3, 83.2, 84.0, 75.1, 71.7, 24.1, 0.3, 0.0, 0.0, 23.9, 63.8, 86.9, 85.8, 85.5, 85.8, 87.2, 86.5, 86.3, 86.3, 57.1, 54.3, 55.3, 54.4, 26.2, 35.2, 58.6, 83.7, 86.9, 84.1, 81.5, 30.2, 27.7, 25.5, 29.3, 31.9, 29.9, 30.6, 26.2, 32.8, 37.2, 47.2, 4.4, 0.4, 0.0, 0.0, 0.0, 57.3, 87.7, 84.8, 85.1, 84.8, 86.6, 86.0, 85.5, 2.6, 0.0, 0.0, 87.3, 87.6, 85.1, 81.1, 25.1, 22.5, 19.7, 20.7, 28.3, 47.0, 47.0, 2.3, 0.0, 0.0, 32.4, 37.2, 37.6, 47.5, 71.6, 70.8, 65.6, 65.4, 63.3, 62.0, 61.7, 59.8, 59.1, 58.7, 53.0, 54.1, 68.5, 88.3, 86.4, 88.0, 96.0, 97.2, 97.9, 98.3, 96.0, 1.7, 0.0, 0.0, 0.0, 36.7, 79.9, 88.5, 93.1, 97.1, 96.0, 96.3, 96.8, 96.0, 96.8, 77.9]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 9,\n        \"max\": 99,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9,\n          99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Raw Dataset\n",
        "We want to test the performance of the pre-defined pipeline as a baseline for future experiments. That is, the data won't have any further transformation other than those defined in the `Experiment` class."
      ],
      "metadata": {
        "id": "5JiAkAiE3qUo"
      },
      "id": "5JiAkAiE3qUo"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['events_sequence'], df.incident_type\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "NZWqprZKULJC",
        "outputId": "d557e5b8-9dfe-4bd9-dee9-df22f9abbc72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NZWqprZKULJC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|â–         | 3/210 [01:25<1:38:26, 28.53s/it]\n",
            "\n",
            "  0%|          | 0/210 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/210 [00:09<32:42,  9.39s/it]\u001b[A\n",
            "  1%|          | 2/210 [00:18<32:08,  9.27s/it]\u001b[A\n",
            "  1%|â–         | 3/210 [00:29<34:44, 10.07s/it]\u001b[A\n",
            "  2%|â–         | 4/210 [00:43<39:10, 11.41s/it]\u001b[A\n",
            "  2%|â–         | 5/210 [01:15<1:05:17, 19.11s/it]\u001b[A\n",
            "  3%|â–Ž         | 6/210 [01:19<47:41, 14.03s/it]  \u001b[A\n",
            "  3%|â–Ž         | 7/210 [01:25<38:23, 11.35s/it]\u001b[A\n",
            "  4%|â–         | 8/210 [04:43<3:58:05, 70.72s/it]\u001b[A\n",
            "  4%|â–         | 9/210 [09:42<7:55:55, 142.07s/it]\u001b[A\n",
            "  5%|â–         | 10/210 [09:58<5:43:29, 103.05s/it]\u001b[A\n",
            "  5%|â–Œ         | 11/210 [10:10<4:09:08, 75.12s/it] \u001b[A\n",
            "  6%|â–Œ         | 12/210 [10:27<3:10:00, 57.58s/it]\u001b[A\n",
            "  6%|â–Œ         | 13/210 [10:51<2:35:57, 47.50s/it]\u001b[A\n",
            "  7%|â–‹         | 14/210 [27:17<18:00:43, 330.83s/it]\u001b[A\n",
            "  7%|â–‹         | 15/210 [27:49<13:02:58, 240.92s/it]\u001b[A\n",
            "  8%|â–Š         | 16/210 [27:54<9:08:37, 169.68s/it] \u001b[A\n",
            "  8%|â–Š         | 17/210 [28:00<6:28:14, 120.70s/it]\u001b[A\n",
            "  9%|â–Š         | 18/210 [31:03<7:26:04, 139.40s/it]\u001b[A\n",
            "  9%|â–‰         | 19/210 [33:53<7:52:37, 148.47s/it]\u001b[A\n",
            " 10%|â–‰         | 20/210 [34:11<5:46:00, 109.27s/it]\u001b[A\n",
            " 10%|â–ˆ         | 21/210 [34:21<4:10:09, 79.41s/it] \u001b[A\n",
            " 10%|â–ˆ         | 22/210 [34:38<3:10:27, 60.79s/it]\u001b[A\n",
            " 11%|â–ˆ         | 23/210 [35:03<2:35:44, 49.97s/it]\u001b[A\n",
            " 11%|â–ˆâ–        | 24/210 [37:01<3:38:12, 70.39s/it]\u001b[A\n",
            " 12%|â–ˆâ–        | 25/210 [37:36<3:04:49, 59.94s/it]\u001b[A\n",
            " 12%|â–ˆâ–        | 26/210 [37:41<2:12:39, 43.26s/it]\u001b[A\n",
            " 13%|â–ˆâ–Ž        | 27/210 [37:46<1:37:16, 31.89s/it]\u001b[A\n",
            " 13%|â–ˆâ–Ž        | 28/210 [41:15<4:18:16, 85.15s/it]\u001b[A\n",
            " 14%|â–ˆâ–        | 29/210 [44:02<5:30:40, 109.62s/it]\u001b[A\n",
            " 14%|â–ˆâ–        | 30/210 [44:17<4:03:28, 81.16s/it] \u001b[A\n",
            " 15%|â–ˆâ–        | 31/210 [44:24<2:55:32, 58.84s/it]\u001b[A\n",
            " 15%|â–ˆâ–Œ        | 32/210 [44:38<2:15:12, 45.57s/it]\u001b[A\n",
            " 16%|â–ˆâ–Œ        | 33/210 [45:03<1:56:06, 39.36s/it]\u001b[A\n",
            " 16%|â–ˆâ–Œ        | 34/210 [1:01:31<15:50:06, 323.90s/it]\u001b[A\n",
            " 17%|â–ˆâ–‹        | 35/210 [1:02:01<11:27:17, 235.64s/it]\u001b[A\n",
            " 17%|â–ˆâ–‹        | 36/210 [1:02:04<8:01:23, 166.00s/it] \u001b[A\n",
            " 18%|â–ˆâ–Š        | 37/210 [1:02:10<5:39:45, 117.83s/it]\u001b[A\n",
            " 18%|â–ˆâ–Š        | 38/210 [1:04:34<6:00:32, 125.77s/it]\u001b[A\n",
            " 19%|â–ˆâ–Š        | 39/210 [1:05:16<4:47:11, 100.77s/it]\u001b[A\n",
            " 19%|â–ˆâ–‰        | 40/210 [1:05:37<3:37:20, 76.71s/it] \u001b[A\n",
            " 20%|â–ˆâ–‰        | 41/210 [1:05:52<2:44:01, 58.23s/it]\u001b[A\n",
            " 20%|â–ˆâ–ˆ        | 42/210 [1:06:15<2:13:44, 47.77s/it]\u001b[A\n",
            " 20%|â–ˆâ–ˆ        | 43/210 [1:06:33<1:47:54, 38.77s/it]\u001b[A\n",
            " 21%|â–ˆâ–ˆ        | 44/210 [1:06:39<1:19:58, 28.91s/it]\u001b[A\n",
            " 21%|â–ˆâ–ˆâ–       | 45/210 [1:07:18<1:27:45, 31.91s/it]\u001b[A\n",
            " 22%|â–ˆâ–ˆâ–       | 46/210 [1:07:32<1:12:43, 26.60s/it]\u001b[A\n",
            " 22%|â–ˆâ–ˆâ–       | 47/210 [1:07:45<1:00:41, 22.34s/it]\u001b[A\n",
            " 23%|â–ˆâ–ˆâ–Ž       | 48/210 [1:09:48<2:22:18, 52.71s/it]\u001b[A\n",
            " 23%|â–ˆâ–ˆâ–Ž       | 49/210 [1:11:50<3:16:41, 73.30s/it]\u001b[A\n",
            "  1%|          | 2/210 [1:14:10<128:33:47, 2225.13s/it]\n",
            "\n",
            " 24%|â–ˆâ–ˆâ–       | 51/210 [1:12:27<1:59:52, 45.23s/it]\u001b[A\n",
            " 25%|â–ˆâ–ˆâ–       | 52/210 [1:12:50<1:41:38, 38.60s/it]\u001b[A\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 53/210 [1:13:22<1:35:32, 36.51s/it]\u001b[A\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 54/210 [1:28:13<12:41:41, 292.96s/it]\u001b[A\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 55/210 [1:28:55<9:22:33, 217.77s/it] \u001b[A\n",
            " 27%|â–ˆâ–ˆâ–‹       | 56/210 [1:29:07<6:40:27, 156.02s/it]\u001b[A\n",
            " 27%|â–ˆâ–ˆâ–‹       | 57/210 [1:29:18<4:46:24, 112.32s/it]\u001b[A\n",
            " 28%|â–ˆâ–ˆâ–Š       | 58/210 [1:32:45<5:56:42, 140.80s/it]\u001b[A\n",
            " 28%|â–ˆâ–ˆâ–Š       | 59/210 [1:35:44<6:23:04, 152.22s/it]\u001b[A\n",
            " 29%|â–ˆâ–ˆâ–Š       | 60/210 [1:35:50<4:31:31, 108.61s/it]\u001b[A\n",
            " 29%|â–ˆâ–ˆâ–‰       | 61/210 [1:35:55<3:12:21, 77.46s/it] \u001b[A\n",
            " 30%|â–ˆâ–ˆâ–‰       | 62/210 [1:36:03<2:19:40, 56.62s/it]\u001b[A\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 63/210 [1:36:13<1:44:23, 42.61s/it]\u001b[A\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 64/210 [1:40:57<4:39:35, 114.90s/it]\u001b[A\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 65/210 [1:41:08<3:22:38, 83.85s/it] \u001b[A\n",
            " 31%|â–ˆâ–ˆâ–ˆâ–      | 66/210 [1:41:11<2:22:58, 59.57s/it]\u001b[A\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 67/210 [1:41:14<1:41:28, 42.58s/it]\u001b[A\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 68/210 [1:41:39<1:27:58, 37.17s/it]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 69/210 [1:41:46<1:06:24, 28.26s/it]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 70/210 [1:42:07<1:01:04, 26.18s/it]\u001b[A\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 71/210 [1:42:16<48:20, 20.86s/it]  \u001b[A\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 72/210 [1:42:32<44:29, 19.35s/it]\u001b[A\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 73/210 [1:42:46<40:25, 17.70s/it]\u001b[A\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 74/210 [1:42:53<32:51, 14.50s/it]\u001b[A\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 75/210 [1:43:18<39:46, 17.68s/it]\u001b[A\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 76/210 [1:43:21<30:02, 13.45s/it]\u001b[A\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 77/210 [1:43:25<23:16, 10.50s/it]\u001b[A\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 78/210 [1:47:11<2:45:43, 75.33s/it]\u001b[A\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 79/210 [1:48:38<2:51:39, 78.62s/it]\u001b[A\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 80/210 [1:49:00<2:13:56, 61.82s/it]\u001b[A\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 81/210 [1:49:07<1:37:08, 45.19s/it]\u001b[A\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 82/210 [1:49:22<1:17:33, 36.36s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 83/210 [1:49:47<1:09:31, 32.84s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 84/210 [1:58:41<6:24:32, 183.12s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 85/210 [1:59:08<4:44:13, 136.43s/it]\u001b[A\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 86/210 [1:59:13<3:20:15, 96.90s/it] \u001b[A\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/210 [1:59:18<2:22:01, 69.28s/it]\u001b[A\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/210 [2:02:53<3:49:52, 113.06s/it]\u001b[A\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/210 [2:04:23<3:33:59, 106.11s/it]\u001b[A\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 90/210 [2:04:45<2:41:45, 80.88s/it] \u001b[A\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 91/210 [2:04:53<1:57:10, 59.08s/it]\u001b[A\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/210 [2:05:08<1:29:57, 45.74s/it]\u001b[A\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/210 [2:05:28<1:14:21, 38.13s/it]\u001b[A\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 94/210 [2:06:26<1:25:23, 44.17s/it]\u001b[A\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 95/210 [2:06:53<1:14:35, 38.92s/it]\u001b[A\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 96/210 [2:07:00<55:26, 29.18s/it]  \u001b[A\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 97/210 [2:07:04<40:59, 21.76s/it]\u001b[A\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 98/210 [2:10:57<2:38:53, 85.12s/it]\u001b[A\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 99/210 [2:12:24<2:38:18, 85.57s/it]\u001b[A\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 100/210 [2:12:43<2:00:46, 65.87s/it]\u001b[A\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 101/210 [2:12:50<1:27:24, 48.11s/it]\u001b[A\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 102/210 [2:13:03<1:07:35, 37.55s/it]\u001b[A\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 103/210 [2:13:22<57:10, 32.06s/it]  \u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 104/210 [2:21:19<4:52:28, 165.55s/it]\u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 105/210 [2:21:43<3:35:23, 123.08s/it]\u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 106/210 [2:21:48<2:31:59, 87.69s/it] \u001b[A\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 107/210 [2:21:52<1:47:10, 62.43s/it]\u001b[A\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/210 [2:25:41<3:11:13, 112.49s/it]\u001b[A\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/210 [2:27:04<2:54:30, 103.67s/it]\u001b[A\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/210 [2:27:31<2:14:11, 80.51s/it] \u001b[A\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 111/210 [2:27:44<1:39:37, 60.38s/it]\u001b[A\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 112/210 [2:28:04<1:18:51, 48.28s/it]\u001b[A\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 113/210 [2:28:25<1:04:45, 40.06s/it]\u001b[A\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/210 [2:29:36<1:18:55, 49.32s/it]\u001b[A\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 115/210 [2:30:06<1:08:42, 43.39s/it]\u001b[A\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 116/210 [2:30:18<53:32, 34.18s/it]  \u001b[A\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 117/210 [2:30:31<43:02, 27.77s/it]\u001b[A\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 118/210 [2:32:21<1:20:24, 52.44s/it]\u001b[A\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 119/210 [2:33:29<1:26:41, 57.16s/it]\u001b[A\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 120/210 [2:33:54<1:11:16, 47.51s/it]\u001b[A\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 121/210 [2:34:05<54:15, 36.58s/it]  \u001b[A\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 122/210 [2:34:24<45:41, 31.15s/it]\u001b[A\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 123/210 [2:34:51<43:32, 30.02s/it]\u001b[A\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 124/210 [2:39:16<2:23:51, 100.37s/it]\u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 125/210 [2:39:45<1:52:02, 79.09s/it] \u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 126/210 [2:39:53<1:20:41, 57.64s/it]\u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 127/210 [2:40:03<59:52, 43.29s/it]  \u001b[A\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 128/210 [2:43:52<2:15:18, 99.01s/it]\u001b[A\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/210 [2:45:23<2:10:40, 96.79s/it]\u001b[A\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/210 [2:45:34<1:34:28, 70.86s/it]\u001b[A\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 131/210 [2:45:37<1:06:39, 50.62s/it]\u001b[A\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 132/210 [2:45:46<49:32, 38.11s/it]  \u001b[A\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 133/210 [2:45:54<37:21, 29.11s/it]\u001b[A\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 134/210 [2:49:23<1:45:19, 83.15s/it]\u001b[A\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 135/210 [2:49:33<1:16:25, 61.14s/it]\u001b[A\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 136/210 [2:49:36<53:50, 43.66s/it]  \u001b[A\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 137/210 [2:49:39<38:17, 31.47s/it]\u001b[A\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 138/210 [2:50:06<36:00, 30.01s/it]\u001b[A\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 139/210 [2:50:38<36:28, 30.82s/it]\u001b[A\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 140/210 [2:51:08<35:32, 30.47s/it]\u001b[A\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 141/210 [2:51:37<34:38, 30.12s/it]\u001b[A\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 142/210 [2:52:26<40:21, 35.60s/it]\u001b[A\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 143/210 [2:52:29<28:55, 25.91s/it]\u001b[A\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 144/210 [2:52:59<29:46, 27.07s/it]\u001b[A\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 145/210 [2:53:49<36:53, 34.05s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 146/210 [2:54:17<34:22, 32.22s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 147/210 [2:54:43<31:49, 30.31s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 148/210 [2:55:51<43:08, 41.76s/it]\u001b[A\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 149/210 [2:57:20<56:50, 55.90s/it]\u001b[A\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/210 [2:57:50<48:00, 48.02s/it]\u001b[A\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 151/210 [2:58:20<41:59, 42.71s/it]\u001b[A\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 152/210 [2:59:10<43:14, 44.73s/it]\u001b[A\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 153/210 [2:59:46<40:07, 42.24s/it]\u001b[A\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 154/210 [3:11:34<3:45:47, 241.91s/it]\u001b[A\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 155/210 [3:12:19<2:47:46, 183.03s/it]\u001b[A\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 156/210 [3:12:46<2:02:29, 136.11s/it]\u001b[A\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 157/210 [3:13:15<1:31:45, 103.88s/it]\u001b[A\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 158/210 [3:14:18<1:19:32, 91.78s/it] \u001b[A\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 159/210 [3:15:44<1:16:26, 89.94s/it]\u001b[A\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 160/210 [3:16:12<59:32, 71.44s/it]  \u001b[A\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 161/210 [3:16:42<48:03, 58.84s/it]\u001b[A\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 162/210 [3:17:35<45:40, 57.09s/it]\u001b[A\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 163/210 [3:18:06<38:41, 49.39s/it]\u001b[A\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 164/210 [3:18:35<33:13, 43.33s/it]\u001b[A\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 165/210 [3:19:25<33:49, 45.11s/it]\u001b[A\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 166/210 [3:19:50<28:51, 39.35s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 167/210 [3:20:16<25:08, 35.08s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 168/210 [3:21:24<31:28, 44.96s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 169/210 [3:22:54<40:05, 58.67s/it]\u001b[A\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 170/210 [3:23:25<33:30, 50.26s/it]\u001b[A\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 171/210 [3:23:53<28:22, 43.65s/it]\u001b[A\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 172/210 [3:24:37<27:47, 43.88s/it]\u001b[A\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 173/210 [3:25:08<24:37, 39.94s/it]\u001b[A\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 174/210 [3:36:27<2:18:59, 231.64s/it]\u001b[A\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 175/210 [3:37:05<1:41:10, 173.43s/it]\u001b[A\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 176/210 [3:37:13<1:10:08, 123.78s/it]\u001b[A\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 177/210 [3:37:38<51:47, 94.17s/it]   \u001b[A\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 178/210 [3:37:47<36:37, 68.66s/it]\u001b[A\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 179/210 [3:38:56<35:32, 68.79s/it]\u001b[A\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 180/210 [3:39:16<27:02, 54.09s/it]\u001b[A\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 181/210 [3:39:35<21:08, 43.73s/it]\u001b[A\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 182/210 [3:39:53<16:41, 35.76s/it]\u001b[A\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 183/210 [3:40:28<16:06, 35.81s/it]\u001b[A\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 184/210 [3:40:29<10:54, 25.17s/it]\u001b[A\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 185/210 [3:41:17<13:20, 32.02s/it]\u001b[A\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 186/210 [3:41:46<12:27, 31.16s/it]\u001b[A\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 187/210 [3:42:14<11:32, 30.09s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 188/210 [3:43:01<12:57, 35.35s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 189/210 [3:44:06<15:31, 44.34s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 190/210 [3:44:37<13:23, 40.19s/it]\u001b[A\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 191/210 [3:45:07<11:47, 37.22s/it]\u001b[A\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 192/210 [3:45:59<12:25, 41.44s/it]\u001b[A\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 193/210 [3:46:33<11:08, 39.32s/it]\u001b[A\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 194/210 [3:55:18<49:18, 184.91s/it]\u001b[A\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 195/210 [3:56:07<36:05, 144.39s/it]\u001b[A\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 196/210 [3:56:35<25:30, 109.33s/it]\u001b[A\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 197/210 [3:57:03<18:23, 84.88s/it] \u001b[A\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 198/210 [3:58:08<15:47, 78.95s/it]\u001b[A\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 199/210 [3:59:45<15:30, 84.55s/it]\u001b[A\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 200/210 [4:00:13<11:13, 67.33s/it]\u001b[A\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 201/210 [4:00:40<08:17, 55.31s/it]\u001b[A\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 202/210 [4:01:14<06:30, 48.81s/it]\u001b[A\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 203/210 [4:01:43<05:01, 43.12s/it]\u001b[A\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 204/210 [4:07:13<12:53, 129.00s/it]\u001b[A\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 205/210 [4:07:45<08:20, 100.09s/it]\u001b[A\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 206/210 [4:07:59<04:57, 74.28s/it] \u001b[A\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 207/210 [4:08:18<02:52, 57.61s/it]\u001b[A\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 208/210 [4:08:37<01:31, 45.83s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 209/210 [4:08:55<00:37, 37.48s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 210/210 [4:09:33<00:00, 71.30s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp1.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp1.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nnYJCXfWsMjY",
        "outputId": "44d5e13a-5de2-43b2-df02-0ddc0b1bf4a1"
      },
      "id": "nnYJCXfWsMjY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_52ed133b-8ea6-4592-8954-6738e485fa48\", \"exp1.pkl\", 3432959)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, after trainign 180 models with different parameters, we can see that the `GradientBoostingClassifier` had an outstanding performance in comparison to the other models. We'll take the results of a 73.46% mean F1-score and 1.7% std in the K-Fold validation as our baseline for future comparisons."
      ],
      "metadata": {
        "id": "0uZwZBTf8Qv-"
      },
      "id": "0uZwZBTf8Qv-"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "DwWKw3k6UVqB",
        "outputId": "710f3cf9-7e88-4e4d-d1bd-e843072cf81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "id": "DwWKw3k6UVqB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "94   GradientBoostingClassifier      Count             ADASYN       0.699298   \n",
              "104  GradientBoostingClassifier      Count  RandomOversampler       0.694333   \n",
              "74   GradientBoostingClassifier      Count              SMOTE       0.693347   \n",
              "84   GradientBoostingClassifier      Count   Borderline-SMOTE       0.688407   \n",
              "54   GradientBoostingClassifier      TFIDF        SMOTE-Tomek       0.677515   \n",
              "124  GradientBoostingClassifier      Count        SMOTE-Tomek       0.680500   \n",
              "34   GradientBoostingClassifier      TFIDF  RandomOversampler       0.677486   \n",
              "64   GradientBoostingClassifier      TFIDF             NoSamp       0.679496   \n",
              "24   GradientBoostingClassifier      TFIDF             ADASYN       0.673555   \n",
              "134  GradientBoostingClassifier      Count             NoSamp       0.680491   \n",
              "\n",
              "     Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "94       0.009880     0.699298    0.009880        0.693292       0.009541   \n",
              "104      0.019053     0.694333    0.019053        0.705052       0.017707   \n",
              "74       0.023312     0.693347    0.023312        0.698465       0.015648   \n",
              "84       0.021736     0.688407    0.021736        0.684475       0.023663   \n",
              "54       0.032724     0.677515    0.032724        0.708091       0.018617   \n",
              "124      0.015156     0.680500    0.015156        0.681979       0.012754   \n",
              "34       0.034528     0.677486    0.034528        0.686205       0.026626   \n",
              "64       0.027137     0.679496    0.027137        0.691487       0.023965   \n",
              "24       0.022593     0.673555    0.022593        0.697297       0.016998   \n",
              "134      0.018784     0.680491    0.018784        0.689769       0.025222   \n",
              "\n",
              "      F1 Mean    F1 Std  \n",
              "94   0.691044  0.009947  \n",
              "104  0.689394  0.018435  \n",
              "74   0.687498  0.021960  \n",
              "84   0.680387  0.022421  \n",
              "54   0.677958  0.028411  \n",
              "124  0.675060  0.014813  \n",
              "34   0.674007  0.031581  \n",
              "64   0.671905  0.024160  \n",
              "24   0.671654  0.016708  \n",
              "134  0.669836  0.018454  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.699298</td>\n",
              "      <td>0.009880</td>\n",
              "      <td>0.699298</td>\n",
              "      <td>0.009880</td>\n",
              "      <td>0.693292</td>\n",
              "      <td>0.009541</td>\n",
              "      <td>0.691044</td>\n",
              "      <td>0.009947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.705052</td>\n",
              "      <td>0.017707</td>\n",
              "      <td>0.689394</td>\n",
              "      <td>0.018435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.693347</td>\n",
              "      <td>0.023312</td>\n",
              "      <td>0.693347</td>\n",
              "      <td>0.023312</td>\n",
              "      <td>0.698465</td>\n",
              "      <td>0.015648</td>\n",
              "      <td>0.687498</td>\n",
              "      <td>0.021960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.688407</td>\n",
              "      <td>0.021736</td>\n",
              "      <td>0.688407</td>\n",
              "      <td>0.021736</td>\n",
              "      <td>0.684475</td>\n",
              "      <td>0.023663</td>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.022421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.032724</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.032724</td>\n",
              "      <td>0.708091</td>\n",
              "      <td>0.018617</td>\n",
              "      <td>0.677958</td>\n",
              "      <td>0.028411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.015156</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.015156</td>\n",
              "      <td>0.681979</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>0.675060</td>\n",
              "      <td>0.014813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.677486</td>\n",
              "      <td>0.034528</td>\n",
              "      <td>0.677486</td>\n",
              "      <td>0.034528</td>\n",
              "      <td>0.686205</td>\n",
              "      <td>0.026626</td>\n",
              "      <td>0.674007</td>\n",
              "      <td>0.031581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.679496</td>\n",
              "      <td>0.027137</td>\n",
              "      <td>0.679496</td>\n",
              "      <td>0.027137</td>\n",
              "      <td>0.691487</td>\n",
              "      <td>0.023965</td>\n",
              "      <td>0.671905</td>\n",
              "      <td>0.024160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.673555</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.673555</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.697297</td>\n",
              "      <td>0.016998</td>\n",
              "      <td>0.671654</td>\n",
              "      <td>0.016708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.680491</td>\n",
              "      <td>0.018784</td>\n",
              "      <td>0.680491</td>\n",
              "      <td>0.018784</td>\n",
              "      <td>0.689769</td>\n",
              "      <td>0.025222</td>\n",
              "      <td>0.669836</td>\n",
              "      <td>0.018454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83c6387d-03ec-4642-96c1-1ce836d9f79e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83c6387d-03ec-4642-96c1-1ce836d9f79e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83c6387d-03ec-4642-96c1-1ce836d9f79e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"ADASYN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008718023804336845,\n        \"min\": 0.6735550894990978,\n        \"max\": 0.6992976637565234,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735550894990978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007533888121982147,\n        \"min\": 0.00987965098702527,\n        \"max\": 0.03452770497976163,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.022592547630823866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008718023804336845,\n        \"min\": 0.6735550894990978,\n        \"max\": 0.6992976637565234,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735550894990978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007533888121982147,\n        \"min\": 0.00987965098702527,\n        \"max\": 0.03452770497976163,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.022592547630823866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008632778629395467,\n        \"min\": 0.6819785350143458,\n        \"max\": 0.7080914142615653,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6972972589833883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0056642362176959945,\n        \"min\": 0.009540814487384995,\n        \"max\": 0.026625564094362193,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0169983066383649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007866143527520535,\n        \"min\": 0.669836055763601,\n        \"max\": 0.6910439143921288,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6716540110754181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006418536526410559,\n        \"min\": 0.009947033990819459,\n        \"max\": 0.03158140601409704,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0167084519863505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "h5ZsapdFUWGY",
        "outputId": "8688f73b-b5d4-4a98-c4ea-b14419098958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h5ZsapdFUWGY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [4:26:26<00:00, 3197.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None the less, using the 180 models to build an ensemble model did not improve the results of the F1 score, since it only achieved a 69.53% mean F1-score with 2.11% of std."
      ],
      "metadata": {
        "id": "cPRerlPW8fhe"
      },
      "id": "cPRerlPW8fhe"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "NBkQcsuUUY1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "dae3ec40-f2d4-4337-c2ad-4caf83205eed"
      },
      "id": "NBkQcsuUUY1h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple      0.675574     0.019847    0.675574   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.019847       0.676288      0.019961  0.667454  0.018378  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fafffc7-06d8-41b3-8821-e3290335194f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.675574</td>\n",
              "      <td>0.019847</td>\n",
              "      <td>0.675574</td>\n",
              "      <td>0.019847</td>\n",
              "      <td>0.676288</td>\n",
              "      <td>0.019961</td>\n",
              "      <td>0.667454</td>\n",
              "      <td>0.018378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fafffc7-06d8-41b3-8821-e3290335194f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fafffc7-06d8-41b3-8821-e3290335194f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fafffc7-06d8-41b3-8821-e3290335194f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f1ec16aa-4d03-407f-ba57-3970aef99e36\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1ec16aa-4d03-407f-ba57-3970aef99e36 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6755743061990928,\n        \"max\": 0.6755743061990928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6755743061990928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019846856091082086,\n        \"max\": 0.019846856091082086,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019846856091082086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6755743061990928,\n        \"max\": 0.6755743061990928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6755743061990928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019846856091082086,\n        \"max\": 0.019846856091082086,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019846856091082086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.676288026479922,\n        \"max\": 0.676288026479922,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.676288026479922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019961168147456174,\n        \"max\": 0.019961168147456174,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019961168147456174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6674541593719706,\n        \"max\": 0.6674541593719706,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6674541593719706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0183776098684052,\n        \"max\": 0.0183776098684052,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0183776098684052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Representation A: Keep only the events that occur less than 85% of the time\n",
        "We took the paper provided by SCNB as inspiration to filter out some inherent noise that could affect the results of the previous experiment."
      ],
      "metadata": {
        "id": "buth96_X8LJe"
      },
      "id": "buth96_X8LJe"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "_aqzrdn9ukm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d8d099-46b9-4786-f583-898b207d74a7"
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 210/210 [3:00:22<00:00, 51.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp2.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp2.pkl')"
      ],
      "metadata": {
        "id": "r3Z6xbDwn3QA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "73676113-0ac0-4a2c-c654-47facda07d2e"
      },
      "id": "r3Z6xbDwn3QA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3e74f71-376e-4aa9-bddb-61959f101948\", \"exp2.pkl\", 689091)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the following table we can see that filtering out the noise negatively impacted the model, since this time we achieved a 3 percentag points lower mean F1-score than our base line, i.e. 70.65% with an almost 3x greater standar deviation."
      ],
      "metadata": {
        "id": "stKf5SUS-B0N"
      },
      "id": "stKf5SUS-B0N"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "vJRyX1Ef2S00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "e24197a9-bbbf-43e8-aaec-5ad109f497d5"
      },
      "id": "vJRyX1Ef2S00",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "104  GradientBoostingClassifier      Count  RandomOversampler       0.692362   \n",
              "4    GradientBoostingClassifier      TFIDF              SMOTE       0.677564   \n",
              "134  GradientBoostingClassifier      Count             NoSamp       0.685451   \n",
              "74   GradientBoostingClassifier      Count              SMOTE       0.678501   \n",
              "9                       XGBoost      TFIDF              SMOTE       0.679564   \n",
              "94   GradientBoostingClassifier      Count             ADASYN       0.678520   \n",
              "59                      XGBoost      TFIDF        SMOTE-Tomek       0.676564   \n",
              "84   GradientBoostingClassifier      Count   Borderline-SMOTE       0.675545   \n",
              "124  GradientBoostingClassifier      Count        SMOTE-Tomek       0.673599   \n",
              "64   GradientBoostingClassifier      TFIDF             NoSamp       0.676569   \n",
              "\n",
              "     Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "104      0.015539     0.692362    0.015539        0.713046       0.015279   \n",
              "4        0.026962     0.677564    0.026962        0.704565       0.021570   \n",
              "134      0.010444     0.685451    0.010444        0.701284       0.012506   \n",
              "74       0.023227     0.678501    0.023227        0.680099       0.023338   \n",
              "9        0.029786     0.679564    0.029786        0.676154       0.037139   \n",
              "94       0.020992     0.678520    0.020992        0.674466       0.023335   \n",
              "59       0.022819     0.676564    0.022819        0.679385       0.027989   \n",
              "84       0.015661     0.675545    0.015661        0.679817       0.011690   \n",
              "124      0.011871     0.673599    0.011871        0.681708       0.008188   \n",
              "64       0.028997     0.676569    0.028997        0.689269       0.031692   \n",
              "\n",
              "      F1 Mean    F1 Std  \n",
              "104  0.689194  0.014109  \n",
              "4    0.677456  0.025040  \n",
              "134  0.675476  0.008441  \n",
              "74   0.672320  0.023137  \n",
              "9    0.670813  0.030060  \n",
              "94   0.670713  0.021415  \n",
              "59   0.669826  0.022084  \n",
              "84   0.669716  0.014653  \n",
              "124  0.668974  0.013821  \n",
              "64   0.667489  0.029637  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c80da962-6fb2-4986-8d0e-41e384f24a85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.692362</td>\n",
              "      <td>0.015539</td>\n",
              "      <td>0.692362</td>\n",
              "      <td>0.015539</td>\n",
              "      <td>0.713046</td>\n",
              "      <td>0.015279</td>\n",
              "      <td>0.689194</td>\n",
              "      <td>0.014109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.677564</td>\n",
              "      <td>0.026962</td>\n",
              "      <td>0.677564</td>\n",
              "      <td>0.026962</td>\n",
              "      <td>0.704565</td>\n",
              "      <td>0.021570</td>\n",
              "      <td>0.677456</td>\n",
              "      <td>0.025040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.685451</td>\n",
              "      <td>0.010444</td>\n",
              "      <td>0.685451</td>\n",
              "      <td>0.010444</td>\n",
              "      <td>0.701284</td>\n",
              "      <td>0.012506</td>\n",
              "      <td>0.675476</td>\n",
              "      <td>0.008441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.678501</td>\n",
              "      <td>0.023227</td>\n",
              "      <td>0.678501</td>\n",
              "      <td>0.023227</td>\n",
              "      <td>0.680099</td>\n",
              "      <td>0.023338</td>\n",
              "      <td>0.672320</td>\n",
              "      <td>0.023137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.679564</td>\n",
              "      <td>0.029786</td>\n",
              "      <td>0.679564</td>\n",
              "      <td>0.029786</td>\n",
              "      <td>0.676154</td>\n",
              "      <td>0.037139</td>\n",
              "      <td>0.670813</td>\n",
              "      <td>0.030060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.678520</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.678520</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.674466</td>\n",
              "      <td>0.023335</td>\n",
              "      <td>0.670713</td>\n",
              "      <td>0.021415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.679385</td>\n",
              "      <td>0.027989</td>\n",
              "      <td>0.669826</td>\n",
              "      <td>0.022084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.675545</td>\n",
              "      <td>0.015661</td>\n",
              "      <td>0.675545</td>\n",
              "      <td>0.015661</td>\n",
              "      <td>0.679817</td>\n",
              "      <td>0.011690</td>\n",
              "      <td>0.669716</td>\n",
              "      <td>0.014653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.673599</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.673599</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.681708</td>\n",
              "      <td>0.008188</td>\n",
              "      <td>0.668974</td>\n",
              "      <td>0.013821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.676569</td>\n",
              "      <td>0.028997</td>\n",
              "      <td>0.676569</td>\n",
              "      <td>0.028997</td>\n",
              "      <td>0.689269</td>\n",
              "      <td>0.031692</td>\n",
              "      <td>0.667489</td>\n",
              "      <td>0.029637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c80da962-6fb2-4986-8d0e-41e384f24a85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c80da962-6fb2-4986-8d0e-41e384f24a85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c80da962-6fb2-4986-8d0e-41e384f24a85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-480ce585-0e21-4fc1-8fb9-3212b527ab90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-480ce585-0e21-4fc1-8fb9-3212b527ab90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-480ce585-0e21-4fc1-8fb9-3212b527ab90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"XGBoost\",\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\",\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RandomOversampler\",\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005519352039372778,\n        \"min\": 0.6735989855143151,\n        \"max\": 0.6923620933521925,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735989855143151,\n          0.6775642588889432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069657189326862235,\n        \"min\": 0.010443541729230555,\n        \"max\": 0.029785851049938618,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01187084230264346,\n          0.026961722730560852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005519352039372778,\n        \"min\": 0.6735989855143151,\n        \"max\": 0.6923620933521925,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735989855143151,\n          0.6775642588889432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069657189326862235,\n        \"min\": 0.010443541729230555,\n        \"max\": 0.029785851049938618,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01187084230264346,\n          0.026961722730560852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013525709401644402,\n        \"min\": 0.6744655315633677,\n        \"max\": 0.7130464872749165,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.681708156357779,\n          0.7045650650043218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009368102952934727,\n        \"min\": 0.008188026193425122,\n        \"max\": 0.03713883755484578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.008188026193425122,\n          0.02156968703496574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006374818771861471,\n        \"min\": 0.6674892832876439,\n        \"max\": 0.6891937311417309,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6689739460552422,\n          0.6774558687531858\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0072278786108977335,\n        \"min\": 0.008441444307940946,\n        \"max\": 0.030060373708929743,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.013820769427991299,\n          0.02503964919473056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "iiBWV2LYwC0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c7f16e-964b-43d9-ffae-cdd2e5b0077d"
      },
      "id": "iiBWV2LYwC0k",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [3:07:44<00:00, 2252.97s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we built an ensemble model to test if we could achieve a better mean F1-score. Unlike the 1st experiment, we achieced a mea F1-score 2 percentage points greater than the ensemble of the 1st experiment. Nonetheless, it was not enought to outperform the baseline model and also it had a slightly greater standard deviation."
      ],
      "metadata": {
        "id": "gLJiO0G7-iJr"
      },
      "id": "gLJiO0G7-iJr"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "ulsxTrri2UsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6c8a49a9-1928-4cf0-b4c5-4984f87cd58a"
      },
      "id": "ulsxTrri2UsF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple      0.684485     0.009068    0.684485   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.009068       0.671497       0.02027  0.669622  0.013434  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad597886-d9aa-4695-aa60-a93e4bda9824\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.684485</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>0.684485</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>0.671497</td>\n",
              "      <td>0.02027</td>\n",
              "      <td>0.669622</td>\n",
              "      <td>0.013434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad597886-d9aa-4695-aa60-a93e4bda9824')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad597886-d9aa-4695-aa60-a93e4bda9824 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad597886-d9aa-4695-aa60-a93e4bda9824');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c17e3800-5bc8-4ad2-ae79-aa77665e2483\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c17e3800-5bc8-4ad2-ae79-aa77665e2483 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6844851972882017,\n        \"max\": 0.6844851972882017,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6844851972882017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.009067607265627584,\n        \"max\": 0.009067607265627584,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.009067607265627584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6844851972882017,\n        \"max\": 0.6844851972882017,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6844851972882017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.009067607265627584,\n        \"max\": 0.009067607265627584,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.009067607265627584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6714970825116477,\n        \"max\": 0.6714970825116477,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6714970825116477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0202704073322489,\n        \"max\": 0.0202704073322489,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0202704073322489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6696223467346046,\n        \"max\": 0.6696223467346046,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6696223467346046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.013433611988409247,\n        \"max\": 0.013433611988409247,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.013433611988409247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation B: Split events into those before and after the incident"
      ],
      "metadata": {
        "id": "MuLCNXm59Wcd"
      },
      "id": "MuLCNXm59Wcd"
    },
    {
      "cell_type": "code",
      "source": [
        "df_before, df_after = Representations(df).representation_b(df)\n",
        "X, y = pd.concat([df_before.events_sequence, df_after.events_sequence]), pd.concat([df_before['class'], df_after['class']])\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "razuBz2VOucS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1434c015-cf6f-49c3-c569-8bc716845230"
      },
      "id": "razuBz2VOucS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|â–ˆâ–ˆâ–Œ       | 53/210 [6:04:53<10:42:12, 245.43s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp3.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp3.pkl')"
      ],
      "metadata": {
        "id": "T0CkuDvsIWPk"
      },
      "id": "T0CkuDvsIWPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "eVEC5TGedBmj"
      },
      "id": "eVEC5TGedBmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "dVbpIzWPHctr"
      },
      "id": "dVbpIzWPHctr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "AkbQGcBtHfDi"
      },
      "id": "AkbQGcBtHfDi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation C: Generates fixed length overlappng and non-overlaping sequences out of the provided sequences"
      ],
      "metadata": {
        "id": "aseee5o49YQk"
      },
      "id": "aseee5o49YQk"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_c(df, sequence_length=100)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "A7frHCFPeHhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d60ea7-84cb-4066-d080-fcefd9b2a340"
      },
      "id": "A7frHCFPeHhB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|â–Š         | 16/210 [7:12:17<90:12:04, 1673.84s/it] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "ebD6mRosHlvl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ebD6mRosHlvl"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "rpIj_0FDHlvm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rpIj_0FDHlvm"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "fXlUulj9Hlvn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fXlUulj9Hlvn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "7Vk_xyb-G2Pm"
      },
      "id": "7Vk_xyb-G2Pm"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}