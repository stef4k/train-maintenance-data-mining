{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee",
      "metadata": {
        "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee"
      },
      "source": [
        "# Text classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58",
      "metadata": {
        "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58"
      },
      "source": [
        "Manually remove the first ';' from the first row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "cfc47e86-0afd-4d88-c84c-6cfcafdc21fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "195      4441897  [536, 536, 536, 536, 536, 536, 536, 536, 536, ...   \n",
              "717      4466199  [1022, 1022, 1022, 1022, 1022, 1022, 1022, 102...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "195  [4026, 4016, 4020, 4026, 4016, 4114, 4168, 414...   \n",
              "717  [4066, 4066, 4068, 4068, 4066, 4068, 4066, 406...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "195  [-13431, -13430, -13423, -13423, -9161, -9144,...   50.557854   \n",
              "717  [-13611, -13280, -12866, -12489, -12288, -1165...   50.522553   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "195    4.471380  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "717    5.544939  [0.2, 0.6, 0.2, 0.5, 0.4, 0.1, 1.8, 0.5, 0.3, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "195  [False, False, False, False, False, False, Fal...   \n",
              "717  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "195  [True, True, True, True, True, True, True, Fal...              4  \n",
              "717  [True, True, True, True, True, True, True, Tru...             99  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e3d1974-bc42-430c-9b87-6916b2973d38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>4441897</td>\n",
              "      <td>[536, 536, 536, 536, 536, 536, 536, 536, 536, ...</td>\n",
              "      <td>[4026, 4016, 4020, 4026, 4016, 4114, 4168, 414...</td>\n",
              "      <td>[-13431, -13430, -13423, -13423, -9161, -9144,...</td>\n",
              "      <td>50.557854</td>\n",
              "      <td>4.471380</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>4466199</td>\n",
              "      <td>[1022, 1022, 1022, 1022, 1022, 1022, 1022, 102...</td>\n",
              "      <td>[4066, 4066, 4068, 4068, 4066, 4068, 4066, 406...</td>\n",
              "      <td>[-13611, -13280, -12866, -12489, -12288, -1165...</td>\n",
              "      <td>50.522553</td>\n",
              "      <td>5.544939</td>\n",
              "      <td>[0.2, 0.6, 0.2, 0.5, 0.4, 0.1, 1.8, 0.5, 0.3, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e3d1974-bc42-430c-9b87-6916b2973d38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e3d1974-bc42-430c-9b87-6916b2973d38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e3d1974-bc42-430c-9b87-6916b2973d38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4bcaabe-baad-4225-8637-2f0f0da2a3df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4bcaabe-baad-4225-8637-2f0f0da2a3df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4bcaabe-baad-4225-8637-2f0f0da2a3df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17184,\n        \"min\": 4441897,\n        \"max\": 4466199,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4466199,\n          4441897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1022, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042, 1042]\",\n          \"[536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1074, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1082, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093, 1093]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[4066, 4066, 4068, 4068, 4066, 4068, 4066, 4066, 4066, 4408, 4066, 4066, 4066, 4068, 4068, 4068, 4068, 3990, 4068, 3990, 4068, 3990, 4066, 3990, 4068, 4068, 2742, 4148, 4026, 2708, 4026, 4020, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 3990, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 3990, 2956, 2956, 2956, 2956, 4068, 3632, 4066, 4066, 3636, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 3990, 2956, 2956, 4068, 3636, 3982, 2956, 3990, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2682, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 3982, 2956, 3980, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4078, 4120, 4068, 4066, 2708, 4026, 4016, 4026, 4020, 4068, 4066, 4068, 4068, 4066, 4068, 4066, 3360, 158, 3636, 3658, 4124, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2686, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4408, 2956, 4066, 3636, 3658, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 148, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 4068, 3636, 3658, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 3990, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 3982, 2956, 2956, 3990, 2956, 2956, 2956, 4068, 3636, 3658, 3990, 3982, 2956, 2956, 2956, 2956, 4412, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 3982, 3990, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 2686, 2708, 4016, 4026, 4020, 4068, 4066, 3990, 4068, 3658, 3990, 4066, 4068, 4066, 3658, 3990, 4068, 3658, 3990, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 4068, 148, 4068, 4068, 4068, 3658, 4068, 4068, 4068, 4066, 4068, 4068, 3658, 4066, 4068, 2744, 4148, 4026, 2708, 4026, 4020, 3360, 158, 154, 3636, 3658, 4078, 2732, 4124, 3360, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956]\",\n          \"[4026, 4016, 4020, 4026, 4016, 4114, 4168, 4140, 3986, 4114, 4002, 4028, 4032, 4026, 2852, 4110, 2854, 4026, 4016, 4020, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4394, 1090, 1286, 4396, 3256, 4068, 4066, 4016, 4026, 4020, 3256, 4082, 4092, 4094, 2402, 4080, 4396, 1286, 4392, 1094, 1286, 3084, 1720, 1740, 1760, 1780, 4114, 4168, 4140, 3986, 4114, 4004, 4032, 4392, 1094, 4028, 2852, 4016, 4026, 4110, 2854, 4140, 4152, 4026, 4020, 4168, 4156, 4406, 4410, 4408, 4412, 1422, 1286, 4016, 4016, 4026, 4028, 4026, 4016, 4020, 4026, 4016, 4114, 4168, 4140, 3986, 4114, 4002, 4032, 4028, 4026, 4110, 4026, 4016, 4020, 4026, 4140, 4162, 4150, 4152, 4168, 2862, 4120, 4156, 2610, 4406, 4410, 4408, 4412, 3256, 4068, 4066, 4026, 4016, 4020, 3256, 4092, 4082, 4094, 2402, 4080, 4114, 4168, 4140, 3986, 4114, 4004, 4032, 4028, 4016, 4026, 4110, 4140, 4162, 4150, 4152, 4020, 4026, 4168, 4026, 4156, 4406, 4410, 4408, 4412, 2610, 2744, 3634, 3634, 3254, 3254, 4124, 4148, 2686, 4066, 4068, 2708, 2742, 4026, 4148, 4120, 3632, 4076, 2686, 4068, 4066, 3632, 3982, 4120, 2682, 4048, 4066, 2686, 2736, 2708, 4394, 1226, 1286, 4020, 4026, 2744, 4026, 4148, 2708, 2740, 4030, 4020, 4026, 4126, 2686, 2708, 2744, 4148, 4168, 4140, 3986, 4002, 4032, 2852, 4028, 4110, 4026, 2854, 4026, 4016, 4020, 4026, 4140, 4162, 4150, 4152, 4168, 4156, 4406, 4410, 4412, 4408, 3256, 4068, 4066, 2744, 4148, 2708, 4026, 4020, 3254, 3254, 3254, 2852, 2854, 4124, 2858, 3256, 2970, 4082, 4090, 4092, 4084, 4090, 4094, 4090, 4090, 4090, 3236, 2974, 4100, 3634, 4124, 4124, 4396, 148, 3982, 3982, 4396, 148, 2682, 4124, 2682, 4124, 2402, 4124, 3982, 3236, 4080, 4396, 4394, 1224, 4396, 4124, 4392, 2708, 2970, 2988, 4100, 2702, 1250, 1224, 4168, 4140, 3986, 2744, 4004, 4032, 2852, 4028, 4110, 2708, 4026, 2854, 2988, 4148, 4392, 4140, 4162, 4150, 4152, 4030, 2708, 4020, 4026, 4030, 4168, 4026, 4156, 4406, 4410, 4408, 4412, 1224, 4016, 4016, 4028, 4026, 4026, 4016, 4020, 4026, 4016, 4114, 4168, 4140, 3986, 4114, 4004, 4032, 4028, 2852, 4026, 4110, 2854, 2708, 2744, 4026, 4148, 4394, 4030, 4026, 2708, 4020, 4140, 4162, 4150, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4394, 2852, 2854, 3254, 3254, 4396, 3254, 4124, 2858, 3256, 4066, 4068, 4026, 4016, 4020, 3256, 4082, 4092, 4094, 2402, 4080, 3256, 4114, 4168, 4140, 3986, 4114, 4002, 4028, 4032, 4026, 2852, 4016, 4110, 2854, 4140, 4162, 4150, 4152, 4020, 4026, 4026, 4168, 4156, 4406, 4410, 4408, 4412, 2610]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-13611, -13280, -12866, -12489, -12288, -11651, -11098, -10729, -10525, -10427, -10366, -10236, -10006, -9726, -9411, -9135, -8882, -8824, -8600, -8476, -8352, -8304, -7999, -7947, -7599, -7350, -7008, -7008, -7007, -7006, -7006, -7005, -6643, -6640, -6640, -6510, -6489, -6468, -6431, -6370, -6354, -6354, -6295, -6288, -6275, -6251, -6210, -6180, -6170, -6158, -6149, -6131, -6107, -6075, -6047, -6025, -5998, -5994, -5986, -5970, -5946, -5916, -5916, -5869, -5850, -5838, -5836, -5826, -5811, -5805, -5805, -5800, -5776, -5751, -5725, -5697, -5657, -5624, -5614, -5558, -5510, -5497, -5479, -5465, -5412, -5374, -5352, -5280, -5252, -5251, -5251, -5245, -5199, -5159, -5149, -5126, -5116, -5093, -5070, -4999, -4963, -4959, -4926, -4905, -4895, -4855, -4841, -4840, -4839, -4835, -4795, -4705, -4659, -4650, -4630, -4576, -4560, -4559, -4547, -4518, -4465, -4423, -4411, -4409, -4406, -4358, -4344, -4282, -4275, -4148, -4106, -4087, -4075, -4031, -4015, -4005, -3973, -3906, -3896, -3895, -3877, -3862, -3844, -3806, -3790, -3765, -3752, -3750, -3697, -3672, -3620, -3617, -3607, -3550, -3547, -3518, -3506, -3485, -3457, -3428, -3428, -3402, -3360, -3351, -3344, -3308, -3282, -3282, -3240, -3196, -3183, -3181, -3137, -3108, -3108, -3041, -3034, -3029, -3021, -2985, -2972, -2970, -2929, -2903, -2875, -2875, -2839, -2808, -2803, -2796, -2790, -2783, -2780, -2748, -2728, -2710, -2664, -2623, -2621, -2595, -2583, -2568, -2554, -2554, -2546, -2515, -2491, -2456, -2453, -2420, -2408, -2399, -2390, -2389, -2387, -2383, -2373, -2368, -2366, -2317, -2311, -2309, -2287, -2279, -2184, -2184, -2157, -2146, -2142, -2107, -2104, -2094, -2072, -2065, -2062, -2048, -2041, -2036, -2033, -2031, -1984, -1971, -1961, -1957, -1952, -1929, -1910, -1910, -1880, -1808, -1805, -1787, -1781, -1756, -1756, -1718, -1700, -1634, -1631, -1613, -1584, -1567, -1557, -1542, -1486, -1482, -1450, -1431, -1431, -1396, -1388, -1347, -1342, -1332, -1326, -1315, -1266, -1258, -1219, -1208, -1200, -1145, -1128, -1128, -1070, -1056, -1014, -988, -947, -912, -824, -814, -619, -508, -507, -496, -245, -244, -243, -242, 1369, 1614, 1982, 2415, 2728, 3113, 3535, -14315, -14296, -13894, -13894, -13761, -13681, -13665, -13609, -13480, -13480, -13442, -13429, -13422, -13399, -13382, -13357, -13344, -13330, -13279, -13224, -13224, -13200, -13144, -13136, -13084, -13076, -13008, -12997, -12980, -12909, -12903, -12865, -12836, -12836, -12815, -12803, -12797, -12739, -12724, -12713, -12697, -12662, -12634, -12627, -12627, -12524, -12487, -12452, -12452, -12424, -12405, -12324, -12301, -12287, -12216, -12216, -12137, -12125, -12119, -12108, -12092, -12013, -11841, -11825, -11824, -11820, -11817, -11810, -11801, -11786, -11781, -11741, -11738, -11699, -11696, -11685, -11680, -11649, -11590, -11590, -11300, -11267, -11260, -11254, -11248, -11201, -11193, -11192, -11182, -11180, -11179, -11163, -11162, -11151, -11150, -11125, -11123, -11119, -11104, -11096, -11079, -11079, -11048, -11039, -11024, -11003, -10997, -10996, -10993, -10985, -10978, -10975, -10937, -10927, -10883, -10831, -10788, -10776, -10752, -10727, -10714, -10714, -10675, -10652, -10629, -10626, -10574, -10572, -10567, -10561, -10523, -10491, -10491, -10444, -10430, -10427, -10368, -10364, -10344, -10344, -10340, -10300, -10293, -10256, -10234, -10222, -10222, -10179, -10156, -10156, -10144, -10114, -10112, -10059, -10048, -10045, -10004, -9989, -9989, -9915, -9912, -9875, -9860, -9822, -9804, -9790, -9771, -9760, -9746, -9725, -9709, -9709, -9675, -9634, -9627, -9614, -9599, -9575, -9442, -9409, -9396, -9396, -9372, -9337, -9334, -9332, -9320, -9277, -9225, -9198, -9186, -9172, -9151, -9133, -9112, -9112, -9065, -9049, -8958, -8919, -8916, -8914, -8884, -8880, -8868, -8868, -8823, -8797, -8774, -8760, -8691, -8673, -8650, -8634, -8624, -8598, -8583, -8583, -8561, -8558, -8487, -8475, -8465, -8428, -8374, -8351, -8335, -8335, -8302, -8300, -8271, -8269, -8258, -8221, -8218, -8182, -8155, -8128, -8105, -8082, -8073, -8061, -8052, -8051, -8042, -8027, -7998, -7982, -7982, -7951, -7950, -7946, -7932, -7919, -7889, -7867, -7841, -7809, -7785, -7767, -7758, -7747, -7738, -7709, -7674, -7653, -7640, -7634, -7597, -7579, -7579, -7516, -7480, -7461, -7442, -7379, -7349, -7348, -7338, -7005, -7004, -7003, -6369, -5945, -5802, -5556, -5509, -5463, -5250, -5250, -5244, -5198, -4961, -4904, -4894, -4838, -4648, -4629, -4357, -4342, -4003, -3972, -3696, -3670, -3456, -3306, -3273, -3135, -2901, -2514, -2490, -2278, -1928, -1779, -1448, -1143, -910, -823, -506, -506, -244, -244, -243, -242, -242, -241, 252, 257, 274, 1161, 1161, 1169, 1184, 1192, 1359, 1370, 1386, 1386, 1482, 1510, 1536, 1549, 1563, 1615, 1650, 1650, 1719, 1728, 1780, 1787, 1843, 1854, 1871, 1943, 1949, 1983, 1991, 1991, 2032, 2040, 2103, 2122, 2135, 2157, 2201, 2231, 2238, 2379, 2417, 2437, 2437, 2587, 2692, 2719, 2730, 2750, 2750, 2789, 2796, 2810, 2827, 2919, 2921, 2924, 2927, 2936, 2948, 2970, 2978, 3020, 3024, 3065, 3070, 3082, 3087, 3114, 3172, 3172, 3270, 3303, 3309, 3324, 3391, 3403, 3405, 3417, 3419, 3421, 3442, 3444, 3459, 3461, 3498, 3500, 3529, 3537, 3555, 3555, 3596]\",\n          \"[-13431, -13430, -13423, -13423, -9161, -9144, -9144, -9133, -9112, -9112, -8798, -8798, -8798, -8797, -8796, -8796, -8794, -8763, -8762, -8725, -8717, -8707, -8680, -8677, -8664, -8662, -8654, -8651, -8643, -8643, -8639, -8540, -8410, -8352, -8350, -7784, -7784, -7783, -7537, -7281, -7281, -7273, -1392, -406, -88, -88, 813, 813, 1641, 2388, 2399, 2399, 2399, 2399, 2961, 2961, 2968, 2987, 2987, 3288, 3288, 3288, 3288, 3289, 3290, 3290, 3290, 3290, 3292, 3318, 3327, 3350, 3351, 3352, 3355, 3367, 3368, 3376, 3380, 3414, 3476, -13620, -13591, -13564, -13564, -13433, -13432, -13425, -13425, -9163, -9146, -9146, -9136, -9115, -9115, -8800, -8800, -8799, -8798, -8797, -8764, -8763, -8726, -8726, -8718, -8714, -8711, -8706, -8681, -8679, -8679, -8678, -8676, -8666, -8665, -8656, -8652, -8411, -8353, -8351, -7786, -7785, -7784, -7538, -7270, -7269, -7261, -1393, -407, 2960, 2960, 2967, 2986, 2986, 3285, 3285, 3286, 3287, 3287, 3288, 3316, 3320, 3322, 3327, 3348, 3348, 3349, 3350, 3352, 3363, 3366, 3373, 3374, 3408, -13958, -13956, -13944, -13940, -13938, -13935, -13920, -13864, -13862, -13862, -13859, -13784, -13784, -13783, -13773, -13741, -13734, -13660, -13659, -13658, -13617, -13613, -13611, -13593, -13593, -13593, -13592, -13592, -13591, -13587, -13587, -13587, -13565, -13565, -13434, -13434, -13434, -13433, -13429, -13427, -13426, -13426, -13426, -13412, -13408, -9165, -9165, -9148, -9137, -9116, -8801, -8801, -8799, -8799, -8799, -8798, -8797, -8764, -8763, -8726, -8726, -8718, -8713, -8711, -8708, -8681, -8678, -8666, -8664, -8655, -8654, -8411, -8353, -8351, -7786, -7786, -7785, -7785, -7784, -7691, -7690, -7674, -7649, -7647, -7642, -7578, -7538, -7378, -7342, -7342, -7342, -7310, -7310, -7310, -7282, -7269, -7255, -7183, -7003, -7002, -6695, -6646, -6165, -6037, -6037, -5660, -4024, -3486, -3486, -2801, -2357, -1863, -1430, -1393, -862, -803, -426, -407, -86, -14, -14, 92, 796, 814, 1014, 1035, 1053, 1142, 1145, 1145, 1652, 2960, 2967, 2986, 3283, 3283, 3283, 3285, 3285, 3285, 3286, 3286, 3287, 3287, 3288, 3293, 3315, 3319, 3321, 3324, 3345, 3347, 3347, 3347, 3347, 3348, 3349, 3351, 3363, 3365, 3374, 3374, 3484, -13618, -13589, -13562, -13561, -13431, -13430, -13423, -13423, -9161, -9144, -9144, -9133, -9112, -9112, -8801, -8801, -8800, -8799, -8799, -8799, -8797, -8765, -8765, -8765, -8765, -8762, -8731, -8728, -8727, -8727, -8720, -8715, -8713, -8707, -8683, -8680, -8668, -8666, -8656, -8656, -8638, -8631, -8629, -8555, -8554, -8540, -8531, -8510, -8449, -8412, -8355, -8353, -7787, -7786, -7785, -7540, -7257, -7257, -7249, -1394, -408, -180, 2959, 2959, 2966, 2985, 2985, 3288, 3288, 3288, 3289, 3290, 3290, 3290, 3292, 3318, 3323, 3325, 3330, 3350, 3350, 3352, 3352, 3354, 3365, 3368, 3375, 3377, 3405]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02496127863687837,\n        \"min\": 50.52255333870523,\n        \"max\": 50.55785391748768,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.52255333870523,\n          50.55785391748768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7591204231265184,\n        \"min\": 4.471380417980296,\n        \"max\": 5.54493881584022,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.54493881584022,\n          4.471380417980296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[0.2, 0.6, 0.2, 0.5, 0.4, 0.1, 1.8, 0.5, 0.3, 84.8, 1.0, 0.3, 1.3, 3.3, 0.3, 3.0, 0.2, 50.8, 0.1, 51.0, 0.3, 39.0, 0.2, 39.2, 0.2, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 36.7, 74.6, 108.7, 90.5, 0.0, 0.0, 0.0, 64.8, 75.3, 80.3, 86.1, 109.0, 113.0, 114.6, 117.1, 117.7, 116.8, 118.2, 115.8, 114.2, 117.2, 104.5, 93.6, 77.7, 41.2, 0.2, 0.0, 0.0, 47.6, 76.7, 89.8, 91.5, 100.5, 97.2, 100.8, 100.8, 103.5, 114.8, 117.4, 117.7, 119.1, 118.2, 117.6, 99.8, 0.0, 0.0, 0.0, 8.0, 46.2, 115.4, 66.7, 37.9, 31.2, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 33.9, 32.0, 37.2, 38.0, 53.8, 58.0, 67.8, 74.0, 48.9, 0.0, 0.0, 9.2, 46.4, 49.8, 51.5, 60.9, 87.2, 86.6, 23.2, 0.2, 0.0, 61.8, 79.0, 79.4, 84.3, 87.4, 88.1, 88.4, 87.8, 87.6, 87.3, 0.1, 0.0, 48.3, 58.7, 58.0, 57.4, 56.2, 55.5, 44.5, 23.8, 0.0, 0.0, 46.2, 57.8, 57.8, 57.6, 57.6, 57.9, 57.8, 81.1, 85.5, 86.8, 86.4, 0.0, 0.0, 71.3, 75.4, 81.6, 87.5, 88.1, 87.7, 88.0, 66.5, 0.1, 0.0, 0.0, 6.5, 63.6, 64.3, 59.2, 0.0, 0.0, 0.0, 0.0, 82.1, 83.6, 83.9, 0.2, 0.0, 0.0, 65.0, 75.2, 82.8, 87.9, 87.7, 87.8, 87.9, 73.3, 0.0, 0.0, 0.0, 24.7, 80.5, 83.2, 83.9, 84.8, 86.2, 86.9, 88.0, 87.6, 87.8, 87.6, 88.3, 87.7, 87.7, 88.0, 86.1, 65.7, 65.5, 59.8, 0.1, 0.0, 32.2, 39.9, 85.1, 80.3, 82.0, 81.1, 80.7, 79.8, 79.8, 62.0, 51.2, 48.8, 34.4, 34.0, 33.8, 24.0, 0.1, 0.0, 0.0, 7.2, 24.9, 30.2, 39.4, 36.6, 28.6, 24.6, 28.4, 29.9, 38.4, 38.2, 38.0, 38.0, 38.2, 31.9, 30.2, 28.3, 27.9, 27.4, 0.2, 0.0, 0.0, 15.4, 36.4, 34.2, 13.9, 0.0, 0.0, 0.0, 13.7, 37.0, 57.9, 57.5, 73.9, 85.2, 86.6, 87.6, 62.4, 47.8, 42.0, 0.2, 0.0, 0.0, 14.3, 32.0, 66.1, 65.9, 65.3, 66.4, 66.9, 86.3, 86.8, 87.8, 87.9, 87.8, 0.0, 0.0, 0.0, 60.8, 74.7, 57.8, 35.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.4, 0.1, 0.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.2, 15.1, 0.2, 0.0, 0.0, 0.0, 13.9, 33.0, 53.9, 71.2, 82.0, 79.6, 57.5, 0.2, 0.0, 0.0, 0.0, 80.7, 84.4, 84.5, 72.7, 67.3, 65.8, 54.3, 28.5, 30.9, 0.0, 0.0, 0.0, 0.0, 22.6, 39.3, 54.0, 79.8, 88.7, 88.6, 49.3, 32.6, 31.7, 31.6, 27.1, 0.0, 0.0, 0.0, 0.0, 25.7, 30.6, 13.8, 0.1, 0.0, 0.0, 0.0, 11.1, 20.1, 25.5, 25.5, 0.1, 0.0, 16.9, 19.4, 25.4, 29.1, 34.5, 34.9, 33.1, 32.1, 21.7, 23.8, 29.1, 28.1, 22.4, 22.0, 0.0, 0.0, 0.0, 0.0, 15.3, 17.1, 19.3, 21.7, 52.7, 71.3, 74.0, 86.0, 86.0, 86.8, 87.0, 87.0, 88.4, 89.2, 70.0, 66.5, 58.6, 21.8, 0.9, 0.0, 0.0, 0.0, 28.7, 72.2, 84.2, 85.0, 85.8, 86.2, 86.8, 87.2, 87.7, 88.2, 87.8, 87.9, 87.8, 88.3, 88.3, 54.9, 0.2, 0.0, 0.0, 45.0, 85.3, 85.4, 85.6, 87.9, 87.4, 87.6, 84.3, 0.1, 0.0, 0.0, 55.3, 84.6, 85.4, 10.9, 0.3, 0.0, 0.0, 0.0, 58.0, 73.1, 46.0, 0.2, 0.0, 0.0, 51.4, 85.6, 85.6, 84.7, 87.2, 87.3, 88.1, 86.3, 81.5, 0.4, 0.0, 0.0, 85.6, 85.2, 82.7, 59.3, 56.8, 59.6, 58.4, 55.0, 53.2, 30.9, 2.4, 0.0, 0.0, 24.7, 89.0, 87.2, 78.0, 58.8, 57.8, 58.5, 0.2, 0.0, 0.0, 6.1, 83.8, 84.2, 84.5, 86.6, 87.7, 88.0, 87.9, 87.8, 72.5, 35.2, 2.1, 0.0, 0.0, 70.0, 73.8, 88.0, 65.4, 55.4, 53.0, 9.0, 0.2, 0.0, 0.0, 51.2, 84.6, 58.6, 58.5, 58.2, 57.8, 50.3, 39.2, 32.6, 0.1, 0.0, 0.0, 3.9, 13.5, 37.7, 51.9, 67.3, 104.2, 52.8, 0.2, 0.0, 0.0, 39.5, 44.3, 82.5, 83.9, 93.6, 114.6, 115.5, 118.5, 119.6, 118.4, 118.2, 117.9, 117.8, 117.6, 118.0, 118.0, 100.5, 65.1, 0.2, 0.0, 0.0, 22.4, 25.7, 39.2, 66.5, 87.5, 113.0, 119.0, 118.9, 118.1, 118.1, 118.2, 117.8, 118.2, 117.7, 118.0, 106.5, 83.0, 81.7, 84.6, 0.1, 0.0, 0.0, 93.5, 112.7, 87.3, 35.4, 32.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 101.2, 0.0, 0.0, 45.3, 0.0, 0.1, 0.0, 0.0, 67.2, 0.1, 0.0, 49.3, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.1, 0.0, 0.2, 0.1, 0.3, 0.0, 0.1, 0.2, 0.1, 0.2, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.5, 0.0, 0.0, 0.0, 28.1, 59.8, 78.0, 80.2, 62.7, 0.1, 0.0, 0.0, 73.8, 77.8, 87.4, 85.0, 64.7, 64.1, 54.9, 31.0, 30.8, 0.2, 0.0, 0.0, 22.5, 29.5, 53.6, 59.8, 64.6, 65.6, 37.9, 32.6, 30.6, 21.8, 0.1, 0.0, 0.0, 13.0, 21.4, 18.5, 0.0, 0.0, 0.0, 9.8, 15.7, 23.0, 25.2, 22.0, 23.2, 25.7, 26.3, 25.7, 24.5, 22.2, 23.3, 26.0, 27.7, 22.0, 21.5, 20.6, 20.2, 0.1, 0.0, 0.0, 0.0, 16.8, 16.5, 18.4, 27.3, 56.6, 60.5, 66.1, 66.2, 66.2, 62.6, 61.9, 58.1, 58.3, 46.3, 45.1, 13.1, 0.0, 0.0, 0.0, 26.2]\",\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.8, 0.0, 0.0, 0.0, 2.5, 2.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.578125, 0.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59375, 0.234375, 0.234375, 0.265625, 0.171875, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.921875, 86.921875, 76.15625, 47.03125, 116.4375, 116.171875, 47.53125, 0.0, 57.140625, 0.0, 32.59375, 0.0, 31.453125, 86.421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67,\n        \"min\": 4,\n        \"max\": 99,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          99,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.\n",
        "                                 size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            # Collect probability predictions for multiclass\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        # Convert predictions to a 3D array: (num_samples, num_classes, num_models)\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        # Define fitness function for genetic algorithm\n",
        "        def fitness(weights):\n",
        "            # Apply weights to model predictions\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            # Get the predicted class with the highest weighted probability\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            # Return negative weighted F1 score for optimization\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        # Genetic algorithm for weight optimization\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        # Store optimized weights\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        # Generate predictions for the input data\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)  # Transforming string into actual list\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            # Step 2: Sort events by frequency and calculate percentages\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)  # Ensure event_type is string\n",
        "\n",
        "            # Step 3: Filter events with percentage <= 85%\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            # Step 4: Clean the 'events_sequence' column\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)  # Convert string to list\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])  # Filter low-frequency events\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)  # Remove brackets and commas\n",
        "            )\n",
        "\n",
        "            # Step 5: Extract the target column\n",
        "            self.y = df['incident_type'].copy()  # Separate target column\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n",
        "\n",
        "  def representation_b(self, df):\n",
        "\n",
        "    before_incident = []\n",
        "    after_incident = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Convertir las cadenas a listas\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        # Filtrar eventos antes del incidente (t <= 0)\n",
        "        before_events = \" \".join([str(event) for event, time in zip(events, seconds) if time <= 0])\n",
        "        if before_events:\n",
        "            before_incident.append({\n",
        "                \"events_sequence\": before_events,\n",
        "                \"class\": incident_type\n",
        "            })\n",
        "\n",
        "        # Filtrar eventos despus del incidente (t > 0)\n",
        "        after_events = \" \".join([str(event) for event, time in zip(events, seconds) if time > 0])\n",
        "        if after_events:\n",
        "            after_incident.append({\n",
        "                \"events_sequence\": after_events,\n",
        "                \"class\": 100\n",
        "            })\n",
        "\n",
        "    # Convertir listas a DataFrames\n",
        "    before_df = pd.DataFrame(before_incident)\n",
        "    after_df = pd.DataFrame(after_incident)\n",
        "\n",
        "    return before_df, after_df\n",
        "\n",
        "\n",
        "  def representation_c(df, sequence_length=30):\n",
        "\n",
        "    overlapping_sequences = []\n",
        "    step = sequence_length // 2  # Paso entre ventanas solapadas\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Convertir eventos y tiempos en listas\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        # Generar cadenas antes del incidente\n",
        "        for i in range(0, len(events) - sequence_length + 1, step):\n",
        "            sequence = events[i:i + sequence_length]\n",
        "            seconds_slice = seconds[i:i + sequence_length]\n",
        "\n",
        "            # Verificar si la mayora de los tiempos son antes o despus del incidente\n",
        "            if all(sec <= 0 for sec in seconds_slice):\n",
        "                sequence_class = incident_type\n",
        "            elif all(sec > 0 for sec in seconds_slice):\n",
        "                sequence_class = 100\n",
        "            else:\n",
        "                # Mezcla de antes y despus del incidente, no considerar esta secuencia\n",
        "                continue\n",
        "\n",
        "            overlapping_sequences.append({\"sequence\": sequence, \"class\": sequence_class})\n",
        "\n",
        "    # Crear un nuevo DataFrame con las secuencias generadas\n",
        "    sequences_df = pd.DataFrame(overlapping_sequences)\n",
        "    return sequences_df\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.le = LabelEncoder()\n",
        "        self.y = self.le.fit_transform(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
        "        self.y_train = self.le.transform(self.y_train)\n",
        "        self.y_test = self.le.transform(self.y_test)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            #\"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            #\"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            #\"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1)\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False),\n",
        "        }\n",
        "\n",
        "\n",
        "    def duplicate_minor_classes(self, X, y, min_instances=5):\n",
        "        X = X.reset_index(drop=True)\n",
        "        y  = y.reset_index(drop=True)\n",
        "        class_counts = y.value_counts()\n",
        "\n",
        "        # Identificar las clases minoritarias\n",
        "        minor_classes = class_counts[class_counts < min_instances].index\n",
        "\n",
        "        # Filtrar las filas correspondientes a las clases minoritarias\n",
        "        minor_class_rows = X.loc[y.isin(minor_classes)]\n",
        "        minor_class_labels = y.loc[y.isin(minor_classes)]\n",
        "\n",
        "        # Duplicar las filas y etiquetas correspondientes\n",
        "        duplicated_X = pd.concat([minor_class_rows] * 2, ignore_index=True)\n",
        "        duplicated_y = pd.concat([minor_class_labels] * 2, ignore_index=True)\n",
        "\n",
        "        # Combinar con las filas y etiquetas originales\n",
        "        X_balanced = pd.concat([X, duplicated_X], ignore_index=True)\n",
        "        y_balanced = pd.concat([y, duplicated_y], ignore_index=True)\n",
        "\n",
        "        X_balanced.reset_index(drop=True, inplace=True)\n",
        "        y_balanced.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_balanced, y_balanced\n",
        "\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        \"\"\"Test a model with Stratified K-Fold and return an array with metric results.\"\"\"\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "        X, y = self.X_train, self.y_train\n",
        "\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for each fold\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "            precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "            f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "        # Return average metrics as a result array\n",
        "        return [\n",
        "            model_name, vectorizer_name, sampler_name,\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        progress_bar = tqdm(total = len(self.vectorizers.keys()) * len(self.sampling_strategies.keys()) * len(self.classifiers.keys()))\n",
        "        self.X_train, self.y_train = self.duplicate_minor_classes(self.X_train, pd.Series(self.y_train))\n",
        "        # Iterate over vectorizers, samplers, and classifiers\n",
        "        for vect_name, ovectorizer in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(ovectorizer)\n",
        "            for samp_name, osampler in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(osampler)\n",
        "                for clf_name, omodel in self.classifiers.items():\n",
        "                    model = deepcopy(omodel)\n",
        "\n",
        "                    result = self.test(\n",
        "                        model=model,\n",
        "                        model_name=clf_name,\n",
        "                        vectorizer=vectorizer,\n",
        "                        vectorizer_name=vect_name,\n",
        "                        sampler=sampler,\n",
        "                        sampler_name=samp_name\n",
        "                    )\n",
        "                    # Store the trained model and add result to the results list\n",
        "                    results.append(result)\n",
        "\n",
        "                    vectorizer = deepcopy(ovectorizer)\n",
        "                    sampler = deepcopy(osampler)\n",
        "                    model = deepcopy(omodel)\n",
        "                    vectorizer.fit(self.X_train)\n",
        "                    X_train = vectorizer.transform(self.X_train).toarray()\n",
        "                    X_resampled, y_resampled = sampler.fit_resample(X_train, self.y_train)\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    self.trained_models[(vect_name, samp_name, clf_name)] = model\n",
        "                    self.trained_vectorizers[vect_name] = vectorizer\n",
        "                    self.trainer_samplers[(vect_name, samp_name)] = sampler\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "        # Convert results to a DataFrame for better readability\n",
        "        columns = [\n",
        "            'Model', 'Vectorizer', 'Sampler',\n",
        "            'Accuracy Mean', 'Accuracy Std',\n",
        "            'Recall Mean', 'Recall Std',\n",
        "            'Precision Mean', 'Precision Std',\n",
        "            'F1 Mean', 'F1 Std'\n",
        "        ]\n",
        "        results_df = pd.DataFrame(results, columns=columns)\n",
        "        self.results = results_df\n",
        "        return results_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.events_sequence, df.incident_type\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "XWMj2hzMHL9L",
        "outputId": "4f1ee666-80a6-49f0-a008-1542f5bb017f"
      },
      "id": "XWMj2hzMHL9L",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [00:23<03:32, 23.59s/it]\u001b[A\n",
            " 20%|        | 2/10 [00:27<01:37, 12.25s/it]\u001b[A\n",
            " 30%|       | 3/10 [00:37<01:17, 11.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bace606ab6b7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincident_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnsembleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_vectorizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-821fff858fe2>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     result = self.test(\n\u001b[0m\u001b[1;32m    113\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-821fff858fe2>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5BnuWhimN5ri",
        "outputId": "898c2aec-0cd3-49b4-a3b1-1e03425c143a"
      },
      "id": "5BnuWhimN5ri",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Vectorizer Sampler  Accuracy Mean  Accuracy Std  \\\n",
              "0          LogisticRegression      Count   SMOTE       0.471486      0.017767   \n",
              "1                DecisionTree      Count   SMOTE       0.459303      0.032458   \n",
              "2                RandomForest      Count   SMOTE       0.640542      0.031054   \n",
              "3        ExtraTreesClassifier      Count   SMOTE       0.679255      0.037355   \n",
              "4  GradientBoostingClassifier      Count   SMOTE       0.705687      0.006607   \n",
              "5          AdaBoostClassifier      Count   SMOTE       0.481773      0.055515   \n",
              "6                  GaussianNB      Count   SMOTE       0.513224      0.022765   \n",
              "7                         KNN      Count   SMOTE       0.290267      0.021185   \n",
              "8                         SVM      Count   SMOTE       0.311629      0.039142   \n",
              "9                     XGBoost      Count   SMOTE       0.696540      0.016580   \n",
              "\n",
              "   Recall Mean  Recall Std  Precision Mean  Precision Std   F1 Mean    F1 Std  \n",
              "0     0.471486    0.017767        0.512338       0.008860  0.469512  0.015478  \n",
              "1     0.459303    0.032458        0.471232       0.032722  0.460248  0.032103  \n",
              "2     0.640542    0.031054        0.648740       0.037938  0.632973  0.032436  \n",
              "3     0.679255    0.037355        0.683635       0.048037  0.670914  0.042893  \n",
              "4     0.705687    0.006607        0.714770       0.008536  0.703078  0.007395  \n",
              "5     0.481773    0.055515        0.548591       0.051530  0.493769  0.054542  \n",
              "6     0.513224    0.022765        0.575248       0.017215  0.515439  0.016750  \n",
              "7     0.290267    0.021185        0.332371       0.022227  0.286779  0.021274  \n",
              "8     0.311629    0.039142        0.372378       0.042770  0.303558  0.036071  \n",
              "9     0.696540    0.016580        0.704206       0.027843  0.693191  0.017171  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94382e7c-fd92-4a02-acdb-019dc1b79af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.471486</td>\n",
              "      <td>0.017767</td>\n",
              "      <td>0.471486</td>\n",
              "      <td>0.017767</td>\n",
              "      <td>0.512338</td>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.469512</td>\n",
              "      <td>0.015478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.459303</td>\n",
              "      <td>0.032458</td>\n",
              "      <td>0.459303</td>\n",
              "      <td>0.032458</td>\n",
              "      <td>0.471232</td>\n",
              "      <td>0.032722</td>\n",
              "      <td>0.460248</td>\n",
              "      <td>0.032103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.640542</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>0.640542</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>0.648740</td>\n",
              "      <td>0.037938</td>\n",
              "      <td>0.632973</td>\n",
              "      <td>0.032436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.679255</td>\n",
              "      <td>0.037355</td>\n",
              "      <td>0.679255</td>\n",
              "      <td>0.037355</td>\n",
              "      <td>0.683635</td>\n",
              "      <td>0.048037</td>\n",
              "      <td>0.670914</td>\n",
              "      <td>0.042893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.705687</td>\n",
              "      <td>0.006607</td>\n",
              "      <td>0.705687</td>\n",
              "      <td>0.006607</td>\n",
              "      <td>0.714770</td>\n",
              "      <td>0.008536</td>\n",
              "      <td>0.703078</td>\n",
              "      <td>0.007395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.481773</td>\n",
              "      <td>0.055515</td>\n",
              "      <td>0.481773</td>\n",
              "      <td>0.055515</td>\n",
              "      <td>0.548591</td>\n",
              "      <td>0.051530</td>\n",
              "      <td>0.493769</td>\n",
              "      <td>0.054542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.513224</td>\n",
              "      <td>0.022765</td>\n",
              "      <td>0.513224</td>\n",
              "      <td>0.022765</td>\n",
              "      <td>0.575248</td>\n",
              "      <td>0.017215</td>\n",
              "      <td>0.515439</td>\n",
              "      <td>0.016750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.290267</td>\n",
              "      <td>0.021185</td>\n",
              "      <td>0.290267</td>\n",
              "      <td>0.021185</td>\n",
              "      <td>0.332371</td>\n",
              "      <td>0.022227</td>\n",
              "      <td>0.286779</td>\n",
              "      <td>0.021274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.311629</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.311629</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.372378</td>\n",
              "      <td>0.042770</td>\n",
              "      <td>0.303558</td>\n",
              "      <td>0.036071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.696540</td>\n",
              "      <td>0.016580</td>\n",
              "      <td>0.696540</td>\n",
              "      <td>0.016580</td>\n",
              "      <td>0.704206</td>\n",
              "      <td>0.027843</td>\n",
              "      <td>0.693191</td>\n",
              "      <td>0.017171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94382e7c-fd92-4a02-acdb-019dc1b79af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94382e7c-fd92-4a02-acdb-019dc1b79af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94382e7c-fd92-4a02-acdb-019dc1b79af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96c11d16-e69a-4a6e-98f5-7cc68d497b58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96c11d16-e69a-4a6e-98f5-7cc68d497b58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96c11d16-e69a-4a6e-98f5-7cc68d497b58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_05aedcd2-fe1b-46f1-9afd-9d124899679c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_05aedcd2-fe1b-46f1-9afd-9d124899679c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SVM\",\n          \"DecisionTree\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1524002320259485,\n        \"min\": 0.29026727442245936,\n        \"max\": 0.705687351082565,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.311628509271729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014002205221427363,\n        \"min\": 0.00660709904069551,\n        \"max\": 0.0555148780985835,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.03914198530559259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1524002320259485,\n        \"min\": 0.29026727442245936,\n        \"max\": 0.705687351082565,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.311628509271729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014002205221427363,\n        \"min\": 0.00660709904069551,\n        \"max\": 0.0555148780985835,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.03914198530559259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13552677103497912,\n        \"min\": 0.33237089377815876,\n        \"max\": 0.7147699843912887,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3723777786972883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015484528982873887,\n        \"min\": 0.00853622834879934,\n        \"max\": 0.05153011304298673,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04277037008554203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15166895469109204,\n        \"min\": 0.2867785729744833,\n        \"max\": 0.7030777419702039,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.30355799618980644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014517456475804751,\n        \"min\": 0.00739548066817252,\n        \"max\": 0.05454181546113614,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.036070545229701774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aqzrdn9ukm_",
        "outputId": "cfe6ef9c-1924-49fd-9df1-3faca8f566e5"
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [00:07<01:10,  7.84s/it]\u001b[A\n",
            " 20%|        | 2/10 [00:10<00:36,  4.59s/it]\u001b[A\n",
            " 30%|       | 3/10 [00:16<00:38,  5.54s/it]\u001b[A\n",
            " 40%|      | 4/10 [00:25<00:39,  6.65s/it]\u001b[A\n",
            " 50%|     | 5/10 [03:41<06:15, 75.13s/it]\u001b[A\n",
            " 60%|    | 6/10 [03:49<03:29, 52.31s/it]\u001b[A\n",
            " 70%|   | 7/10 [03:51<01:47, 35.82s/it]\u001b[A\n",
            " 80%|  | 8/10 [03:52<00:49, 24.85s/it]\u001b[A\n",
            " 90%| | 9/10 [04:41<00:32, 32.40s/it]\u001b[A\n",
            "100%|| 10/10 [05:28<00:00, 32.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.83      0.70        24\n",
            "           1       0.61      0.69      0.65        16\n",
            "           2       0.71      0.74      0.72        23\n",
            "           3       0.43      0.60      0.50         5\n",
            "           4       0.90      0.88      0.89        64\n",
            "           5       0.73      0.73      0.73        30\n",
            "           6       0.83      0.54      0.66        35\n",
            "\n",
            "    accuracy                           0.75       197\n",
            "   macro avg       0.69      0.72      0.69       197\n",
            "weighted avg       0.77      0.75      0.75       197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3_juRB6oN_xb",
        "outputId": "a4d8dbbe-ec5b-437a-d1ef-aecf281df642"
      },
      "id": "3_juRB6oN_xb",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Vectorizer Sampler  Accuracy Mean  Accuracy Std  \\\n",
              "0          LogisticRegression      Count   SMOTE       0.626277      0.043505   \n",
              "1                DecisionTree      Count   SMOTE       0.503087      0.022870   \n",
              "2                RandomForest      Count   SMOTE       0.639527      0.032466   \n",
              "3        ExtraTreesClassifier      Count   SMOTE       0.657868      0.028028   \n",
              "4  GradientBoostingClassifier      Count   SMOTE       0.709764      0.017843   \n",
              "5          AdaBoostClassifier      Count   SMOTE       0.495882      0.076081   \n",
              "6                  GaussianNB      Count   SMOTE       0.491837      0.016405   \n",
              "7                         KNN      Count   SMOTE       0.400186      0.020440   \n",
              "8                         SVM      Count   SMOTE       0.484730      0.014635   \n",
              "9                     XGBoost      Count   SMOTE       0.675168      0.028482   \n",
              "\n",
              "   Recall Mean  Recall Std  Precision Mean  Precision Std   F1 Mean    F1 Std  \n",
              "0     0.626277    0.043505        0.635346       0.042035  0.626121  0.041839  \n",
              "1     0.503087    0.022870        0.525175       0.031072  0.507673  0.022681  \n",
              "2     0.639527    0.032466        0.638117       0.038609  0.629648  0.033773  \n",
              "3     0.657868    0.028028        0.664988       0.031401  0.648764  0.028840  \n",
              "4     0.709764    0.017843        0.718387       0.016190  0.707514  0.019191  \n",
              "5     0.495882    0.076081        0.528046       0.066722  0.496413  0.078922  \n",
              "6     0.491837    0.016405        0.565589       0.023900  0.494206  0.013334  \n",
              "7     0.400186    0.020440        0.469941       0.022513  0.408985  0.021411  \n",
              "8     0.484730    0.014635        0.560749       0.011080  0.483875  0.018098  \n",
              "9     0.675168    0.028482        0.677742       0.033846  0.668889  0.028916  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.626277</td>\n",
              "      <td>0.043505</td>\n",
              "      <td>0.626277</td>\n",
              "      <td>0.043505</td>\n",
              "      <td>0.635346</td>\n",
              "      <td>0.042035</td>\n",
              "      <td>0.626121</td>\n",
              "      <td>0.041839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.503087</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>0.503087</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>0.525175</td>\n",
              "      <td>0.031072</td>\n",
              "      <td>0.507673</td>\n",
              "      <td>0.022681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.639527</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>0.639527</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>0.638117</td>\n",
              "      <td>0.038609</td>\n",
              "      <td>0.629648</td>\n",
              "      <td>0.033773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.657868</td>\n",
              "      <td>0.028028</td>\n",
              "      <td>0.657868</td>\n",
              "      <td>0.028028</td>\n",
              "      <td>0.664988</td>\n",
              "      <td>0.031401</td>\n",
              "      <td>0.648764</td>\n",
              "      <td>0.028840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.709764</td>\n",
              "      <td>0.017843</td>\n",
              "      <td>0.709764</td>\n",
              "      <td>0.017843</td>\n",
              "      <td>0.718387</td>\n",
              "      <td>0.016190</td>\n",
              "      <td>0.707514</td>\n",
              "      <td>0.019191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.495882</td>\n",
              "      <td>0.076081</td>\n",
              "      <td>0.495882</td>\n",
              "      <td>0.076081</td>\n",
              "      <td>0.528046</td>\n",
              "      <td>0.066722</td>\n",
              "      <td>0.496413</td>\n",
              "      <td>0.078922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.491837</td>\n",
              "      <td>0.016405</td>\n",
              "      <td>0.491837</td>\n",
              "      <td>0.016405</td>\n",
              "      <td>0.565589</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.494206</td>\n",
              "      <td>0.013334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.400186</td>\n",
              "      <td>0.020440</td>\n",
              "      <td>0.400186</td>\n",
              "      <td>0.020440</td>\n",
              "      <td>0.469941</td>\n",
              "      <td>0.022513</td>\n",
              "      <td>0.408985</td>\n",
              "      <td>0.021411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.484730</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.484730</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.560749</td>\n",
              "      <td>0.011080</td>\n",
              "      <td>0.483875</td>\n",
              "      <td>0.018098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.675168</td>\n",
              "      <td>0.028482</td>\n",
              "      <td>0.675168</td>\n",
              "      <td>0.028482</td>\n",
              "      <td>0.677742</td>\n",
              "      <td>0.033846</td>\n",
              "      <td>0.668889</td>\n",
              "      <td>0.028916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6da2b473-b7ba-44ba-9eb2-d7ac858f75fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2575f4e-9757-455a-9478-69251b0f317f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2575f4e-9757-455a-9478-69251b0f317f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2575f4e-9757-455a-9478-69251b0f317f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c9c7b802-e14b-4d8d-933e-ed93624e4f1b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c9c7b802-e14b-4d8d-933e-ed93624e4f1b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SVM\",\n          \"DecisionTree\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10460477008068274,\n        \"min\": 0.40018647052729717,\n        \"max\": 0.7097638039987568,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48473013570910606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018345361577286654,\n        \"min\": 0.01463508597700476,\n        \"max\": 0.0760807361541652,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01463508597700476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10460477008068274,\n        \"min\": 0.40018647052729717,\n        \"max\": 0.7097638039987568,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48473013570910606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018345361577286654,\n        \"min\": 0.01463508597700476,\n        \"max\": 0.0760807361541652,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01463508597700476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07984414061308821,\n        \"min\": 0.46994128352857956,\n        \"max\": 0.7183869128095757,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5607489349836725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015624627155135084,\n        \"min\": 0.01107966133204304,\n        \"max\": 0.06672168794063564,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01107966133204304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09995007657646919,\n        \"min\": 0.4089852202407232,\n        \"max\": 0.7075139643123525,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48387475469993924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01888244647301909,\n        \"min\": 0.013334167290706925,\n        \"max\": 0.07892160591071905,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01809783348065855\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_before, df_after = Representations(df).representation_b(df)\n",
        "X, y = pd.concat([df_before.events_sequence, df_after.events_sequence]), pd.concat([df_before['class'], df_after['class']])\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "razuBz2VOucS",
        "outputId": "b7b50aa3-0411-4fda-e8fd-c97f6da111a6"
      },
      "id": "razuBz2VOucS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [01:18<11:46, 78.48s/it]\u001b[A\n",
            " 20%|        | 2/10 [01:41<06:07, 45.99s/it]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "eVEC5TGedBmj"
      },
      "id": "eVEC5TGedBmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_c(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "id": "A7frHCFPeHhB"
      },
      "id": "A7frHCFPeHhB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}