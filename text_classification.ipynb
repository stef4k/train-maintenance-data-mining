{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee",
      "metadata": {
        "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee"
      },
      "source": [
        "# Text classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58",
      "metadata": {
        "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58"
      },
      "source": [
        "Manually remove the first ';' from the first row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "902d09cb-cb78-4401-fb5b-1e6bc3739002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "846      4602047  [1051, 1051, 1051, 1051, 1051, 1051, 1051, 105...   \n",
              "267      4445901  [506, 506, 506, 506, 506, 506, 506, 506, 506, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "846  [4394, 1566, 1570, 2744, 4168, 4140, 3986, 400...   \n",
              "267  [2674, 4394, 1566, 1570, 4396, 2742, 4148, 402...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "846  [-14390, -14390, -14390, -5621, -5520, -5501, ...   50.649112   \n",
              "267  [-14380, -14209, -14209, -14209, -14121, -6476...   50.462717   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "846     5.57423  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "267     4.82072  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "846  [False, False, False, False, False, False, Fal...   \n",
              "267  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "846  [True, True, True, True, True, False, False, F...             13  \n",
              "267  [True, True, True, True, True, True, True, Tru...              4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ac5f714-01bd-453c-9420-f0c2ea50b91e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>4602047</td>\n",
              "      <td>[1051, 1051, 1051, 1051, 1051, 1051, 1051, 105...</td>\n",
              "      <td>[4394, 1566, 1570, 2744, 4168, 4140, 3986, 400...</td>\n",
              "      <td>[-14390, -14390, -14390, -5621, -5520, -5501, ...</td>\n",
              "      <td>50.649112</td>\n",
              "      <td>5.57423</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, False, False, F...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>4445901</td>\n",
              "      <td>[506, 506, 506, 506, 506, 506, 506, 506, 506, ...</td>\n",
              "      <td>[2674, 4394, 1566, 1570, 4396, 2742, 4148, 402...</td>\n",
              "      <td>[-14380, -14209, -14209, -14209, -14121, -6476...</td>\n",
              "      <td>50.462717</td>\n",
              "      <td>4.82072</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ac5f714-01bd-453c-9420-f0c2ea50b91e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ac5f714-01bd-453c-9420-f0c2ea50b91e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ac5f714-01bd-453c-9420-f0c2ea50b91e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07eaf9b8-747b-47b4-ab98-1d7ed92d2955\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07eaf9b8-747b-47b4-ab98-1d7ed92d2955')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07eaf9b8-747b-47b4-ab98-1d7ed92d2955 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110411,\n        \"min\": 4445901,\n        \"max\": 4602047,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4445901,\n          4602047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 506, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 553, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079, 1079]\",\n          \"[1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[2674, 4394, 1566, 1570, 4396, 2742, 4148, 4026, 2708, 4026, 4020, 3632, 4120, 4120, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 4394, 4396, 4026, 4016, 4020, 4026, 4066, 4066, 4066, 4066, 4066, 4026, 4028, 4020, 4026, 4026, 3658, 4066, 4066, 4066, 4068, 4394, 1566, 1570, 4396, 4394, 4396, 4016, 4026, 4026, 4020, 4066, 4394, 154, 152, 4396, 2742, 4026, 2708, 4020, 4026, 4148, 4394, 154, 152, 4396, 4394, 154, 152, 4396, 3636, 3658, 4394, 154, 152, 4120, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4394, 154, 152, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4180, 2956, 2956, 2956, 2956, 3982, 4048, 4068, 2736, 2708, 2708, 4020, 4026, 4028, 4016, 4020, 4026, 4026, 4068, 4394, 154, 152, 4396, 4068, 3658, 4068, 3658, 4394, 154, 152, 4396, 4394, 154, 152, 4066, 4396, 3658, 2674, 4394, 1566, 1570, 2742, 4148, 3632, 4168, 4408, 4412, 4140, 3986, 4004, 2852, 4110, 2854, 4026, 2708, 2744, 4026, 4030, 4018, 4026, 4148, 4140, 4162, 4150, 4152, 2554, 4168, 4156, 2852, 2854, 4124, 2858, 2658, 2688, 3254, 3254, 3254, 2896, 4066, 4068, 2708, 2742, 4148, 3632, 2852, 2854, 2886, 4120, 2858, 2658, 2688, 2708, 3254, 3254, 3254, 2970, 4082, 4092, 4090, 4084, 4090, 4094, 3234, 2974, 4100, 4120, 2686, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2744, 4026, 4148, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 4078, 2956, 2956, 2956, 4066, 3636, 3658, 4078, 4124, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 4048, 4020, 4028, 2708, 4026, 4030, 2740, 2708, 4020, 4026, 4030, 4026, 4396, 2972, 3236, 2982, 2708, 2972, 2986, 3236, 3636, 4100, 2702, 4394, 1252, 2972, 4396, 3236, 2976, 4100, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4394, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4394, 2956, 2956, 2956, 2956, 4396, 2956, 4394, 2956, 4068, 4396, 3636]\",\n          \"[4394, 1566, 1570, 2744, 4168, 4140, 3986, 4004, 2852, 4110, 2854, 4092, 4094, 4026, 2708, 2744, 4026, 4396, 1752, 4030, 4018, 4026, 4148, 4140, 4162, 4150, 4152, 4168, 4066, 4068, 4156, 4406, 4410, 4408, 4412, 3634, 4066, 4068, 3742, 3634, 4396, 1752, 3754, 3742, 3634, 4066, 4068, 3634, 3254, 2896, 3254, 3254, 4124, 2682, 2858, 2658, 2688, 2852, 2854, 2708, 4396, 1432, 2742, 4148, 3254, 3254, 3254, 4120, 2858, 2658, 2688, 2886, 4120, 2688, 2682, 2708, 2970, 4066, 4068, 4082, 4092, 4090, 4084, 4090, 4094, 3234, 3144, 2974, 4100, 2852, 2854, 3632, 4120, 2956, 2956, 2956, 2956, 2708, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 942, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2708, 2942, 3254, 3254, 3254, 3254, 3254, 2744, 4026, 2944, 4168, 4140, 3986, 4002, 2852, 4110, 2854, 4026, 2708, 2744, 4396, 942, 4030, 4018, 4026, 4148, 4140, 4162, 4150, 4152, 4168, 4156, 2492, 4406, 4410, 4408, 4412, 2948, 4394, 2960, 4396, 2742, 2946, 4394, 2960, 2962, 4396, 2742, 4394, 960, 4396, 2744, 3254, 3254, 3254, 4124, 4124]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-14380, -14209, -14209, -14209, -14121, -6476, -6476, -6475, -6474, -6474, -6473, -6110, -6094, -5938, -5909, -5777, -5716, -5669, -5658, -5639, -5620, -5589, -5573, -5542, -5511, -5506, -5449, -5435, -5356, -5344, -5199, -5139, -5128, -5096, -5061, -5005, -5003, -4992, -4986, -4976, -4958, -4954, -4952, -4942, -4930, -4913, -4906, -4901, -4885, -4874, -4858, -4836, -4820, -4813, -4769, -4730, -4709, -4693, -4670, -4645, -4622, -4619, -4617, -4606, -4578, -4565, -4562, -4508, -4470, -4436, -4420, -4414, -4399, -4366, -4348, -4329, -4320, -4264, -4221, -4209, -4193, -4169, -4156, -4141, -4129, -4116, -4111, -4103, -4090, -4081, -4068, -4058, -4055, -4042, -4026, -4004, -3982, -3976, -3971, -3931, -3929, -3890, -3888, -3874, -3848, -3806, -3780, -3742, -3734, -3719, -3710, -3674, -3666, -3645, -3602, -3440, -3368, -3367, -3366, -3366, -1451, -1155, -933, -316, 60, 91, 91, 98, 98, 99, 332, 1332, 2249, 3249, 3539, -14391, -14391, -14391, -14238, -14209, -14121, -6477, -6477, -6476, -6475, -3667, -3606, -3606, -3605, -3444, -3370, -3370, -3368, -3368, -3368, -3223, -3132, -3132, -3131, -2975, -2962, -2962, -2953, -2883, -2023, -2023, -1987, -1987, -1986, -1984, -1908, -1887, -1877, -1846, -1822, -1799, -1793, -1767, -1743, -1706, -1700, -1684, -1655, -1616, -1586, -1543, -1542, -1530, -1515, -1502, -1488, -1453, -1429, -1429, -1384, -1363, -1355, -1336, -1320, -1305, -1292, -1270, -1254, -1243, -1214, -1199, -1189, -1157, -1140, -1140, -1070, -1055, -1023, -973, -935, -915, -915, -894, -894, -893, -871, -836, -820, -818, -806, -774, -765, -757, -730, -718, -709, -667, -656, -617, -602, -595, -555, -544, -502, -500, -478, -435, -400, -384, -363, -351, -318, -291, -291, -234, -231, -224, -197, -182, -174, -159, -157, -93, -76, -60, -20, -3, 12, 40, 58, 58, 59, 60, 74, 89, 89, 89, 90, 96, 96, 98, 1330, 1633, 1633, 1635, 1894, 2247, 2316, 3248, 3280, 3323, 3323, 3324, 3443, 3454, 3454, 3455, 3537, 3561, 3590, -14380, -14208, -14208, -14208, -8446, -8446, -8435, -8432, -8432, -8431, -8424, -8406, -8221, -8219, -8219, -8217, -8216, -8127, -8127, -8127, -8122, -8119, -8119, -8113, -8112, -8108, -8105, -8100, -8094, -8094, -8091, -7961, -7959, -7957, -7890, -7889, -7889, -7875, -7874, -7865, -7839, -7823, -7822, -7814, -7689, -7689, -7641, -7634, -7632, -7629, -7615, -7533, -7532, -7532, -7525, -7475, -7474, -7468, -7402, -7373, -7373, -7372, -7345, -7345, -7345, -7291, -7186, -7167, -7141, -7008, -6609, -6468, -6412, -6371, -6361, -6340, -6320, -6289, -6274, -6247, -6217, -6212, -6182, -6169, -6103, -6095, -6078, -6049, -6000, -5973, -5965, -5944, -5935, -5896, -5880, -5874, -5867, -5865, -5860, -5858, -5850, -5843, -5831, -5799, -5786, -5755, -5748, -5747, -5744, -5712, -5684, -5677, -5645, -5637, -5601, -5574, -5572, -5565, -5553, -5545, -5535, -5528, -5514, -5507, -5486, -5474, -5473, -5448, -5441, -5393, -5355, -5347, -5304, -5296, -5244, -5203, -5203, -5150, -5102, -5053, -5021, -5000, -4997, -4975, -4907, -4864, -4856, -4733, -4733, -4733, -3746, -3746, -3733, -3730, -3608, -3589, -3586, -3565, -3536, -3506, -3498, -3494, -3476, -3471, -3451, -3446, -3439, -3429, -3378, -3356, -3329, -3329, -3316, -3307, -3274, -3216, -3205, -3161, -3153, -3088, -3086, -3020, -3020, -3013, -3005, -2942, -2893, -2883, -2825, -2824, -2807, -2807, -2796, -2789, -2751, -2733, -2727, -2709, -2699, -2684, -2674, -2658, -2649, -2614, -2597, -2592, -2574, -2558, -2558, -2548, -2545, -2514, -2452, -2435, -2411, -2394, -2394, -2381, -2374, -2289, -2280, -2202, -2186, -2186, -2137, -2104, -2099, -2048, -2042, -2032, -1983, -1982, -1971, -1971, -1960, -1957, -1909, -1903, -1879, -1864, -1861, -1839, -1834, -1768, -1751, -1736, -1718, -1687, -1662, -1633, -1623, -1615, -1584, -1173, 59, 61, 90, 91, 91, 95, 96, 97, 97, 97, 97, 99, 107, 122, 138, 248, 259, 271, 290, 291, 331, 455, 458, 458, 458, 466, 467, 481, 630, 630, 639, 656, 699, 728, 764, 779, 797, 799, 857, 859, 909, 912, 947, 956, 967, 975, 979, 988, 1005, 1014, 1019, 1053, 1062, 1064, 1105, 1113, 1118, 1152, 1160, 1162, 1206, 1214, 1254, 1264, 1273, 1279, 1301, 1326, 1332, 1442, 1442, 1481, 1504, 1533, 1545, 1556, 1561, 1572, 1599, 1621, 1632, 1636, 1658, 1688, 1698, 1711, 1760, 1778, 1788, 1827, 1841, 1860, 1879, 1882, 1897, 1900, 1926, 1941, 1972, 1979, 1992, 1995, 2027, 2033, 2044, 2048, 2103, 2122, 2151, 2185, 2201, 2214, 2236, 2248, 2317, 2380, 2439, 2516, 2531, 2549, 2588, 2590, 2605, 2612, 2615, 2622, 2650, 2667, 2676, 2697, 2699, 2724, 2732, 2743, 2769, 2777, 2779, 2812, 2825, 2829, 2837, 2867, 2873, 2877, 2884, 2915, 2924, 2926, 2973, 2975, 3025, 3034, 3072, 3081, 3083, 3093, 3103, 3128, 3145, 3157, 3179, 3191, 3216, 3239, 3249, 3282, 3326, 3336, 3363, 3402, 3424, 3447, 3452, 3457, 3499, 3539, 3564, 3592]\",\n          \"[-14390, -14390, -14390, -5621, -5520, -5501, -5477, -5189, -5186, -5186, -5185, -5184, -5184, -5183, -5110, -5110, -5110, -5100, -5100, -5096, -5094, -5094, -5088, -5080, -5077, -5075, -5070, -5055, -5053, -5053, -5052, -5040, -5039, -5030, -5029, -4991, -4935, -4935, -4909, -4885, -4885, -4885, -4838, -4831, -4772, -4769, -4769, -4737, -4696, -4669, -4667, -4666, -4642, -4638, -4549, -4548, -4548, -4508, -4506, -4482, -4416, -4416, -4405, -4405, -4333, -4298, -4296, -4276, -4199, -4198, -4198, -4191, -4171, -4168, -4163, -4138, -4091, -4075, -4075, -4062, -4062, -4061, -4033, -4033, -4033, -3977, -3946, -3832, -3828, -3818, -3816, -3808, -3647, -3514, -3434, -3424, -3419, -3336, -2530, -2398, -2389, -2375, -2371, -2331, -2330, -2327, -2316, -2298, -2292, -2290, -2275, -2267, -2260, -2257, -2254, -2200, -2188, -2179, -2176, -2171, -2155, -2081, -2048, -1947, -1941, -1932, -1911, -1819, -1757, -1723, -1682, -1567, -1561, -1533, -1527, -1440, -1407, -1386, -1256, -1232, -1137, -1112, -1094, -992, -968, -885, -852, -811, -785, -736, -720, -530, -510, -431, -382, -381, -333, -331, -195, -195, -70, 212, 244, 305, 626, 628, 628, 630, 632, 665, 665, 716, 716, 747, 748, 748, 862, 863, 866, 868, 873, 911, 914, 924, 925, 927, 937, 939, 1253, 1253, 1254, 1276, 1403, 1426, 1426, 1429, 1432, 1472, 1500, 1500, 1500, 1518, 2173, 2245, 2292, 2293, 2693, 3550]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13180070036098127,\n        \"min\": 50.4627172,\n        \"max\": 50.64911153798077,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.4627172,\n          50.64911153798077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5328120049090577,\n        \"min\": 4.820720294635488,\n        \"max\": 5.574230258173078,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.820720294635488,\n          5.574230258173078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.6, 20.6, 25.7, 28.7, 35.0, 35.6, 32.6, 31.8, 30.7, 33.9, 33.2, 17.1, 39.8, 20.8, 19.1, 0.0, 11.2, 17.5, 31.7, 29.4, 52.7, 53.6, 63.5, 67.7, 75.4, 84.8, 85.1, 84.8, 85.3, 84.6, 88.0, 88.8, 87.8, 85.9, 83.9, 87.1, 85.7, 84.9, 87.1, 79.1, 83.4, 83.5, 85.7, 85.9, 82.8, 80.8, 80.7, 80.5, 80.3, 85.9, 80.9, 76.1, 29.2, 21.7, 45.6, 62.1, 66.4, 75.9, 80.5, 78.4, 77.8, 77.1, 80.6, 86.0, 86.3, 85.8, 80.7, 78.6, 81.7, 85.9, 84.2, 83.9, 82.9, 80.6, 79.5, 87.5, 85.2, 84.1, 80.7, 76.9, 72.4, 81.6, 81.0, 80.4, 84.8, 84.5, 81.5, 81.2, 78.7, 75.4, 43.6, 35.8, 31.8, 30.2, 27.8, 26.8, 14.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 2.2, 0.6, 0.2, 1.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2, 0.6, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.9, 23.5, 26.4, 33.5, 35.6, 36.6, 37.0, 43.9, 54.5, 73.0, 75.7, 80.8, 85.8, 80.0, 73.5, 76.5, 77.0, 81.3, 80.5, 78.7, 53.2, 0.1, 0.0, 0.0, 14.8, 37.9, 45.7, 62.4, 72.9, 80.3, 84.1, 86.9, 84.9, 80.7, 72.4, 68.5, 57.4, 1.5, 0.0, 0.0, 84.2, 82.9, 80.0, 53.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 15.1, 54.0, 66.1, 68.0, 77.3, 77.6, 77.3, 76.4, 75.0, 74.5, 73.6, 79.6, 86.5, 81.3, 81.2, 81.3, 79.2, 78.2, 74.4, 74.1, 72.4, 68.7, 65.6, 64.6, 55.9, 42.7, 0.0, 0.0, 0.0, 50.9, 55.1, 57.2, 50.0, 47.7, 45.8, 44.4, 44.4, 25.3, 23.9, 23.1, 15.6, 13.0, 11.7, 0.0, 1.2, 1.2, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 90.2, 90.3, 89.9, 60.8, 0.4, 0.0, 0.6, 0.0, 15.8, 15.8, 17.3, 32.8, 29.2, 29.2, 29.4, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.5, 24.8, 26.8, 27.5, 31.9, 34.6, 32.9, 34.9, 35.8, 32.9, 32.7, 33.2, 33.5, 27.7, 26.2, 17.3, 0.0, 15.4, 29.5, 30.3, 27.1, 25.3, 31.0, 56.9, 63.6, 71.4, 73.6, 77.6, 77.0, 81.8, 88.4, 96.4, 122.9, 130.2, 145.2, 146.1, 145.8, 145.6, 140.9, 148.2, 148.8, 146.9, 146.3, 147.1, 151.7, 151.4, 150.6, 149.9, 150.2, 150.8, 151.2, 146.3, 147.3, 135.7, 130.3, 130.2, 129.5, 130.4, 123.7, 127.3, 129.0, 139.9, 139.5, 134.4, 38.1, 37.9, 24.1, 21.7, 50.3, 51.4, 50.2, 49.8, 46.6, 28.5, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.2, 52.8, 52.5, 52.1, 55.2, 83.2, 89.2, 91.8, 107.3, 113.3, 123.5, 121.5, 115.5, 109.0, 36.7, 0.2, 0.0, 0.0, 0.0, 0.0, 44.2, 92.0, 97.8, 120.6, 122.3, 1.6, 0.0, 0.0, 0.0, 0.0, 0.0, 69.4, 99.9, 104.3, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 44.8, 69.8, 77.5, 101.6, 104.8, 109.9, 112.5, 118.3, 108.7, 70.0, 48.9, 38.6, 0.1, 0.0, 0.0, 0.0, 0.0, 41.7, 77.5, 48.0, 0.3, 0.0, 0.0, 0.0, 0.0, 126.2, 128.1, 0.1, 0.0, 0.0, 0.0, 66.8, 76.2, 118.9, 110.6, 88.8, 1.3, 0.1, 0.0, 0.0, 0.0, 0.0, 53.2, 55.9, 46.6, 36.8, 32.6, 19.8, 19.8, 0.0, 14.4, 37.1, 37.7, 30.7, 30.7, 23.8, 22.9, 22.4, 0.0, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.7, 21.4, 31.9, 44.1, 54.3, 62.7, 63.5, 86.2, 86.6, 100.7, 101.5, 115.6, 119.9, 120.3, 119.3, 118.0, 117.3, 117.2, 116.7, 116.7, 124.6, 119.1, 117.3, 122.8, 124.3, 126.0, 122.0, 122.7, 122.5, 127.9, 124.9, 114.3, 111.3, 105.7, 102.9, 72.9, 15.8, 0.2, 0.0, 0.0, 18.1, 58.2, 83.2, 90.0, 94.8, 95.2, 97.0, 100.0, 96.4, 91.7, 89.8, 90.3, 100.5, 102.3, 108.0, 88.9, 81.2, 77.0, 77.8, 70.1, 59.2, 57.7, 58.4, 60.7, 61.2, 69.3, 69.8, 72.4, 76.1, 82.1, 83.4, 69.4, 64.5, 55.2, 52.7, 40.6, 37.1, 37.5, 32.0, 29.4, 28.0, 18.4, 0.1, 0.0, 13.6, 27.8, 28.0, 30.8, 36.3, 72.0, 74.0, 91.1, 98.5, 101.3, 106.4, 111.3, 112.7, 114.8, 115.1, 115.3, 123.9, 126.0, 124.9, 119.6, 118.6, 118.2, 120.6, 116.7, 115.4, 112.7, 99.1, 99.2, 99.6, 100.0, 116.4, 122.3, 122.3, 114.5, 113.7, 104.1, 105.9, 114.0, 113.9, 113.3, 111.0, 104.5, 90.0, 86.6, 83.6, 81.4, 85.9, 66.8, 24.2, 0.2, 0.0, 18.3, 30.7, 43.0, 54.8, 46.4, 31.2, 28.1, 30.0, 30.7, 0.2, 0.0, 0.0]\",\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.3, 26.2, 25.4, 25.0, 0.0, 0.0, 12.7, 13.8, 23.0, 26.8, 29.5, 29.0, 28.6, 27.5, 33.6, 33.6, 33.6, 32.4, 32.0, 31.7, 31.6, 31.5, 34.3, 31.2, 32.2, 32.6, 33.3, 32.5, 34.3, 30.0, 35.1, 36.0, 34.9, 33.3, 25.6, 23.6, 26.4, 24.5, 31.1, 31.6, 29.8, 29.6, 31.0, 32.2, 32.3, 26.8, 29.2, 40.2, 41.2, 40.8, 43.1, 41.5, 33.0, 30.2, 14.2, 15.5, 14.5, 15.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 4,\n        \"max\": 13,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16737a51-b8eb-4428-b351-51113364e62c",
      "metadata": {
        "id": "16737a51-b8eb-4428-b351-51113364e62c"
      },
      "source": [
        "Now I will analyze the percentage of each event type appearing at least once in an event sequence:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7",
      "metadata": {
        "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7"
      },
      "source": [
        "We save in a list all event codes that appear in less than 85% of the event sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba05e687-439c-4f60-a78e-681a6cd75090",
      "metadata": {
        "id": "ba05e687-439c-4f60-a78e-681a6cd75090"
      },
      "outputs": [],
      "source": [
        "events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage<=85].event_type)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617",
      "metadata": {
        "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617"
      },
      "source": [
        "## Text preprocessing\n",
        "Before we start with text classification we need to clean the sequences of events. As seen one value of `events_sequence` contains commas and brackets even though it is a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb37149f-424d-4374-b560-e330b3942c6e",
      "metadata": {
        "id": "cb37149f-424d-4374-b560-e330b3942c6e",
        "outputId": "3fda74f1-2317-46d2-c22f-5e8818b7ba8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[2744, 4004, 2852, 4110, 2854, 4396, 1132, 4140, 4148, 2708, 4026, 1032, 1082, 4152, 4030, 4018, 4168, 4156, 4394, 152, 2742, 4410, 4406, 4068, 4408, 4412, 4066, 2744, 4026, 4148, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 4148, 2708, 4026, 4140, 4152, 4030, 4018, 4140, 4168, 4156, 2852, 2854, 4124, 2858, 2658, 2688, 3254, 3254, 3254, 2970, 4082, 4090, 4092, 2982, 3236, 4100, 2702, 4394, 1250, 2970, 2980, 2970, 2980, 2970, 2982, 2970, 2982, 4168, 4140, 3986, 2742, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4030, 4018, 4148, 4140, 4152, 4168, 4156, 4120, 2858, 2658, 2688, 3254, 3254, 2970, 2982, 2708, 2970, 2982, 4100, 2702, 1250, 4394, 2744, 4026, 4148, 2970, 2980, 4168, 4140, 4168, 3986, 2744, 4002, 2852, 4110, 2854, 2980, 2708, 4026, 4148, 2552, 4168, 4140, 4152, 4030, 4018, 4026, 4140, 4168, 4156, 2970, 2982, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 1250, 4394, 4168, 4140, 3986, 2744, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4140, 4030, 4018, 4140, 4140, 2552, 4168, 4140, 4148, 4140, 4140, 4152, 4168, 4156, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4066, 2708, 2708, 3082, 4394, 3086, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2742, 4026, 4148, 2708, 3036, 4394, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 2982, 4148, 2708, 4026, 4140, 4152, 4168, 4030, 4018, 4156, 4406, 4410, 4408, 4412, 2980, 2980, 2970, 3492, 4066, 4068, 4396, 2980, 2708, 2970, 2980, 2970, 2980, 2970, 2980, 2744, 4148, 2970, 2980, 2970, 2980, 4124, 3224, 2690, 3224, 2690, 3224, 2690, 3224, 2690, 4126, 3224, 2690, 2684, 2846, 4124, 3224, 4022, 3032, 4394, 2654, 2708, 4392, 1200, 1202, 2652, 3260, 4092, 2708, 2980, 4396, 1286, 3132, 4394, 4396, 1286, 2652, 2654, 2708, 3082, 4392, 4394, 1200, 1202, 2708, 4394, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2708, 4124, 4072, 2970, 2982, 2708, 2970, 4082, 4090, 4092, 4084, 4094, 4090, 3236, 2974, 4100, 4124, 2708, 2970, 2980, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 4394, 1250, 2708, 2708, 3082, 1286, 3082, 1720, 1740, 1760, 1780, 1286, 2652, 3260, 4094, 3082, 3086, 1286, 1286, 1720, 1740, 1780, 2652, 3260, 4094, 2708, 2970, 4396, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708, 2970, 4082, 4090, 4092, 4084, 4090, 4094, 2988, 3236, 4100, 2702, 4394, 1250, 2970, 4396, 2980, 2970, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.events_sequence.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21",
      "metadata": {
        "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21"
      },
      "source": [
        "Also, as observed before some event types are so common they do not actually bring a lot of value (as mentioned in the paper as well). We remove those common event types\n",
        "\n",
        "The steps to clean the event sequences are:\n",
        "- keep non-common event types mentioned in list `events_low_frequency`\n",
        "- remove symbols: [] , and store sequences of events as a string without brackets and commas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca",
      "metadata": {
        "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee5c214-1eaa-4f4c-c074-ae542c7178f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/180 [4:04:58<179:39:05, 3674.69s/it]\n"
          ]
        }
      ],
      "source": [
        "df['clean_events_sequence'] = df.events_sequence.apply(ast.literal_eval).apply(lambda x: [i for i in x if i in events_low_frequency]).astype(str)\\\n",
        "                .replace(r'[\\[\\],]', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b",
      "metadata": {
        "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b"
      },
      "source": [
        "## Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18e3f2d-8402-4608-bddc-696b656096be",
      "metadata": {
        "id": "b18e3f2d-8402-4608-bddc-696b656096be"
      },
      "source": [
        "Now we try to experiment using text techniques to transform the list events sequence:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['incident_type'].value_counts()\n",
        "df = df[~df[\"incident_type\"].isin([7, 16, 3, 6, 17])].copy()\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "cyslsE2taYSE"
      },
      "id": "cyslsE2taYSE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518",
      "metadata": {
        "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518"
      },
      "outputs": [],
      "source": [
        "target = df['incident_type'].copy() # target column separated\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.clean_events_sequence, target, test_size=0.2,  random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951515d0-d264-4008-a0b9-862d4de245b9",
      "metadata": {
        "id": "951515d0-d264-4008-a0b9-862d4de245b9"
      },
      "source": [
        "Since the dataset is imbalanced we will use different strategies to battle that. Here we set a new sampling strategy based on a basic script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
      "metadata": {
        "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
        "outputId": "92d8d13d-8ca4-4f30-a5fc-1864dca75f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{99: 183, 14: 157, 9: 131, 2: 129, 4: 97, 11: 59}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Define custom sampling strategy based on class distribution\n",
        "# Each non-majority class will have equal samples to 15% of the majority class plus their previous samples\n",
        "class_counts = pd.Series(y_train).value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(pd.Series(y_train).value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "sampling_strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89063fd-fac4-49af-bac6-4e7556984ea9",
      "metadata": {
        "id": "e89063fd-fac4-49af-bac6-4e7556984ea9"
      },
      "source": [
        "Starting with CountVectorizer:\n",
        "- Tokenization: Splits text into individual words (tokens).\n",
        "- Builds a Vocabulary: Creates a dictionary of unique words (tokens) from the entire corpus.\n",
        "- Counts the Occurrence: Calculates the frequency (count) of each word in each document.\n",
        "- Transforms Text into a Sparse Matrix: Returns a matrix of shape (n_samples, n_features), where n_samples is the number of documents and n_features is the number of unique words in the vocabulary.\n",
        "\n",
        "  We firstly set the sampling strategy for SMOTE:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739",
      "metadata": {
        "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739"
      },
      "source": [
        "Now we set the pipeline to be used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642",
      "metadata": {
        "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d",
      "metadata": {
        "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d"
      },
      "outputs": [],
      "source": [
        "text_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                     #('decision_tree', DecisionTreeClassifier()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    #('random_forest', RandomForestClassifier())\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199354cb-7476-434b-92fd-f5ba688b62ce",
      "metadata": {
        "id": "199354cb-7476-434b-92fd-f5ba688b62ce"
      },
      "source": [
        "Training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
      "metadata": {
        "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
        "outputId": "1f8d5b9d-228b-4164-9b06-2194b5bee407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                ('smote',\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                ('extra_trees', ExtraTreesClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(k_neighbors=2, random_state=1,\n",
              "      sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59, 14: 157, 99: 183})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "text_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f",
      "metadata": {
        "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f"
      },
      "source": [
        "Print the results for the particular split of test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
      "metadata": {
        "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
        "outputId": "04527af2-cbe6-42ea-967e-c2123b7affb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.73      0.79      0.76        28\n",
            "           4       0.83      0.79      0.81        19\n",
            "           9       0.91      0.42      0.57        24\n",
            "          11       1.00      0.00      0.00         5\n",
            "          13       0.65      0.89      0.75        61\n",
            "          14       0.70      0.53      0.60        30\n",
            "          99       0.53      0.57      0.55        30\n",
            "\n",
            "    accuracy                           0.68       197\n",
            "   macro avg       0.76      0.57      0.58       197\n",
            "weighted avg       0.71      0.68      0.66       197\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_predict = text_clf.predict(X_test)\n",
        "print(classification_report(y_test, clf_predict, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            # Collect probability predictions for multiclass\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        # Convert predictions to a 3D array: (num_samples, num_classes, num_models)\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        # Define fitness function for genetic algorithm\n",
        "        def fitness(weights):\n",
        "            # Apply weights to model predictions\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            # Get the predicted class with the highest weighted probability\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            # Return negative weighted F1 score for optimization\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        # Genetic algorithm for weight optimization\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        # Store optimized weights\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        # Generate predictions for the input data\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)  # Transforming string into actual list\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            # Step 2: Sort events by frequency and calculate percentages\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)  # Ensure event_type is string\n",
        "\n",
        "            # Step 3: Filter events with percentage <= 85%\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            # Step 4: Clean the 'events_sequence' column\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)  # Convert string to list\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])  # Filter low-frequency events\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)  # Remove brackets and commas\n",
        "            )\n",
        "\n",
        "            # Step 5: Extract the target column\n",
        "            self.y = df['incident_type'].copy()  # Separate target column\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.le = LabelEncoder().fit(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            #\"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            #\"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            #\"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            #\"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            #\"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1)\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False),\n",
        "        }\n",
        "\n",
        "\n",
        "    def drop_small_classes(self, X, y, min_instances=25):\n",
        "        # Convert y to a pandas Series if not already\n",
        "        y_series = pd.Series(y) if not isinstance(y, pd.Series) else y\n",
        "\n",
        "        # Count instances per class\n",
        "        class_counts = y_series.value_counts()\n",
        "\n",
        "        # Filter classes with at least min_instances\n",
        "        valid_classes = class_counts[class_counts >= min_instances].index\n",
        "\n",
        "        # Create a mask for rows with valid classes\n",
        "        mask = y_series.isin(valid_classes)\n",
        "\n",
        "        # Filter X and y\n",
        "        X_filtered = X[mask] if isinstance(X, pd.DataFrame) else X[mask, :]\n",
        "        y_filtered = y_series[mask]\n",
        "\n",
        "        X_filtered.reset_index(drop=True, inplace=True)\n",
        "        y_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_filtered, y_filtered\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        \"\"\"Test a model with Stratified K-Fold and return an array with metric results.\"\"\"\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "        X, y = self.drop_small_classes(self.X, self.y)\n",
        "\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = self.le.transform((y[train_index])), self.le.transform(y[test_index])\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for each fold\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "            precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "            f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "        # Return average metrics as a result array\n",
        "        return [\n",
        "            model_name, vectorizer_name, sampler_name,\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        progress_bar = tqdm(total = len(self.vectorizers.keys()) * len(self.sampling_strategies.keys()) * len(self.classifiers.keys()))\n",
        "        # Iterate over vectorizers, samplers, and classifiers\n",
        "        for vect_name, ovectorizer in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(ovectorizer)\n",
        "            for samp_name, osampler in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(osampler)\n",
        "                for clf_name, omodel in self.classifiers.items():\n",
        "                    model = deepcopy(omodel)\n",
        "\n",
        "                    result = self.test(\n",
        "                        model=model,\n",
        "                        model_name=clf_name,\n",
        "                        vectorizer=vectorizer,\n",
        "                        vectorizer_name=vect_name,\n",
        "                        sampler=sampler,\n",
        "                        sampler_name=samp_name\n",
        "                    )\n",
        "                    # Store the trained model and add result to the results list\n",
        "                    results.append(result)\n",
        "\n",
        "                    vectorizer = deepcopy(ovectorizer)\n",
        "                    sampler = deepcopy(osampler)\n",
        "                    model = deepcopy(omodel)\n",
        "                    vectorizer.fit(self.X_train)\n",
        "                    X_train = vectorizer.transform(self.X_train).toarray()\n",
        "                    X_resampled, y_resampled = sampler.fit_resample(X_train, self.le.transform(self.y_train))\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    self.trained_models[(vect_name, samp_name, clf_name)] = model\n",
        "                    self.trained_vectorizers[vect_name] = vectorizer\n",
        "                    self.trainer_samplers[(vect_name, samp_name)] = sampler\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "        # Convert results to a DataFrame for better readability\n",
        "        columns = [\n",
        "            'Model', 'Vectorizer', 'Sampler',\n",
        "            'Accuracy Mean', 'Accuracy Std',\n",
        "            'Recall Mean', 'Recall Std',\n",
        "            'Precision Mean', 'Precision Std',\n",
        "            'F1 Mean', 'F1 Std'\n",
        "        ]\n",
        "        results_df = pd.DataFrame(results, columns=columns)\n",
        "        self.results = results_df\n",
        "        return results_df\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()\n",
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_aqzrdn9ukm_",
        "outputId": "106f24bb-f7c4-4c52-be57-a247c0ecb80e"
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [03:05<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'key of type tuple not found and not a MultiIndex'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-2acd672d5bbf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepresentations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnsembleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_vectorizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-963e266754a2>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     result = self.test(\n\u001b[0m\u001b[1;32m    218\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-963e266754a2>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_small_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-963e266754a2>\u001b[0m in \u001b[0;36mdrop_small_classes\u001b[0;34m(self, X, y, min_instances)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Filter X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mX_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0my_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_rows_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = EnsembleModel(exp.trained_models, exp.trained_vectorizers)\n",
        "ensemble.fit(exp.X_train, exp.y_train)\n",
        "ensemble_predictions = ensemble.predict(exp.X_test)\n",
        "print(classification_report(exp.y_test, ensemble_predictions, zero_division=1))"
      ],
      "metadata": {
        "id": "82KPufqm2CZp"
      },
      "id": "82KPufqm2CZp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7dea2210-71e8-4c09-8a20-347a24c61512",
      "metadata": {
        "id": "7dea2210-71e8-4c09-8a20-347a24c61512"
      },
      "source": [
        "Now we calculate the cross validation:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events_list = []\n",
        "events_pre_incident = []\n",
        "events_post_incident = []\n",
        "\n",
        "for i, (events, seconds_to_incident_sequence, vehicles_sequence, train_kph_sequence, dj_ac_state_sequence, dj_dc_state_sequence) in tqdm(enumerate(zip(df[\"events_sequence\"],\n",
        "                                                                                                                                                      df[\"seconds_to_incident_sequence\"],\n",
        "                                                                                                                                                      df[\"vehicles_sequence\"],\n",
        "                                                                                                                                                      df[\"train_kph_sequence\"],\n",
        "                                                                                                                                                      df[\"dj_ac_state_sequence\"],\n",
        "                                                                                                                                                      df[\"dj_dc_state_sequence\"])), total=len(df)):\n",
        "    events = ast.literal_eval(events)\n",
        "    seconds_to_incident_sequence = ast.literal_eval(seconds_to_incident_sequence)\n",
        "    vehicles_sequence = ast.literal_eval(vehicles_sequence)\n",
        "    train_kph_sequence = ast.literal_eval(train_kph_sequence)\n",
        "    dj_ac_state_sequence = ast.literal_eval(dj_ac_state_sequence)\n",
        "    dj_dc_state_sequence = ast.literal_eval(dj_dc_state_sequence)\n",
        "\n",
        "\n",
        "    pre_incidents = []\n",
        "    pre_incidents_vehicles = []\n",
        "    pre_incidents_kph = []\n",
        "    pre_incidents_ac = []\n",
        "    pre_incidents_dc = []\n",
        "\n",
        "\n",
        "    post_incidents = []\n",
        "    post_incidents_vehicles = []\n",
        "    post_incidents_kph = []\n",
        "    post_incidents_ac = []\n",
        "    post_incidents_dc = []\n",
        "\n",
        "    event_seq = []\n",
        "    prev_event = 0\n",
        "\n",
        "    for event, time_to_incident, vehicle, kph, ac, dc in zip(events, seconds_to_incident_sequence, vehicles_sequence, train_kph_sequence, dj_ac_state_sequence, dj_dc_state_sequence):\n",
        "      #if event != prev_event:\n",
        "      event_seq.append(str(event))\n",
        "      if time_to_incident <= 0:\n",
        "          pre_incidents.append(str(event))\n",
        "          pre_incidents_vehicles.append(str(vehicle))\n",
        "          pre_incidents_kph.append(str(kph))\n",
        "          pre_incidents_ac.append(str(ac))\n",
        "          pre_incidents_dc.append(str(dc))\n",
        "      else:\n",
        "          post_incidents.append(str(event))\n",
        "          post_incidents_vehicles.append(str(vehicle))\n",
        "          post_incidents_kph.append(str(kph))\n",
        "          post_incidents_ac.append(str(ac))\n",
        "          post_incidents_dc.append(str(dc))\n",
        "      #prev_event = event\n",
        "\n",
        "    # Append the pre and post incident lists to the main lists\n",
        "    events_pre_incident.append(pre_incidents)\n",
        "    events_post_incident.append(post_incidents)\n",
        "    events_list.append(event_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs6FuHq84zef",
        "outputId": "4a43108b-c44f-41a1-d63a-b57faf758154"
      },
      "id": "Rs6FuHq84zef",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1011/1011 [00:15<00:00, 64.88it/s] \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}