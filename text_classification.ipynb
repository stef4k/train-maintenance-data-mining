{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee",
      "metadata": {
        "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee"
      },
      "source": [
        "# Text classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "\n",
        "#from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58",
      "metadata": {
        "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58"
      },
      "source": [
        "Manually remove the first ';' from the first row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "610172fa-b252-4a11-da0b-8b0fdb42eb92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>4457555</td>\n",
              "      <td>[604, 604, 604, 604, 604, 604, 604, 604, 604, ...</td>\n",
              "      <td>[2434, 4002, 4032, 2852, 4110, 2854, 4028, 402...</td>\n",
              "      <td>[-13421, -13421, -13421, -13418, -13418, -1341...</td>\n",
              "      <td>50.936962</td>\n",
              "      <td>5.311587</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>4455349</td>\n",
              "      <td>[702, 702, 702, 702, 702, 702, 702, 702, 702, ...</td>\n",
              "      <td>[4066, 4068, 4124, 3634, 2682, 3620, 4148, 412...</td>\n",
              "      <td>[-12509, -12509, -11526, -11525, -11522, -1152...</td>\n",
              "      <td>50.903678</td>\n",
              "      <td>4.388016</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "525      4457555  [604, 604, 604, 604, 604, 604, 604, 604, 604, ...   \n",
              "473      4455349  [702, 702, 702, 702, 702, 702, 702, 702, 702, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "525  [2434, 4002, 4032, 2852, 4110, 2854, 4028, 402...   \n",
              "473  [4066, 4068, 4124, 3634, 2682, 3620, 4148, 412...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "525  [-13421, -13421, -13421, -13418, -13418, -1341...   50.936962   \n",
              "473  [-12509, -12509, -11526, -11525, -11522, -1152...   50.903678   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "525    5.311587  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "473    4.388016  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "525  [False, False, False, False, False, False, Fal...   \n",
              "473  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "525  [False, False, False, False, False, False, Fal...             99  \n",
              "473  [True, True, True, True, True, True, True, Tru...             99  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';')\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16737a51-b8eb-4428-b351-51113364e62c",
      "metadata": {
        "id": "16737a51-b8eb-4428-b351-51113364e62c"
      },
      "source": [
        "Now I will analyze the percentage of each event type appearing at least once in an event sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642",
      "metadata": {
        "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642"
      },
      "outputs": [],
      "source": [
        "events_types_dict = {}\n",
        "for events_sequence in df['events_sequence']:\n",
        "    row_list = ast.literal_eval(events_sequence) #transforming string into actual list\n",
        "    unique_events = set(row_list)\n",
        "    for event in unique_events:\n",
        "        if not events_types_dict.get(event):\n",
        "            events_types_dict[event] = 0\n",
        "        events_types_dict[event] += 1\n",
        "sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "# Convert the sorted dictionary to a DataFrame\n",
        "sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "# Cast the 'event_type' column to string\n",
        "sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7",
      "metadata": {
        "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7"
      },
      "source": [
        "We save in a list all event codes that appear in less than 85% of the event sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba05e687-439c-4f60-a78e-681a6cd75090",
      "metadata": {
        "id": "ba05e687-439c-4f60-a78e-681a6cd75090"
      },
      "outputs": [],
      "source": [
        "events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage<=85].event_type)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617",
      "metadata": {
        "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617"
      },
      "source": [
        "## Text preprocessing\n",
        "Before we start with text classification we need to clean the sequences of events. As seen one value of `events_sequence` contains commas and brackets even though it is a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb37149f-424d-4374-b560-e330b3942c6e",
      "metadata": {
        "id": "cb37149f-424d-4374-b560-e330b3942c6e",
        "outputId": "3377afe2-eec9-454a-8a0f-04f6182a8f63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[2744, 4004, 2852, 4110, 2854, 4396, 1132, 4140, 4148, 2708, 4026, 1032, 1082, 4152, 4030, 4018, 4168, 4156, 4394, 152, 2742, 4410, 4406, 4068, 4408, 4412, 4066, 2744, 4026, 4148, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 4148, 2708, 4026, 4140, 4152, 4030, 4018, 4140, 4168, 4156, 2852, 2854, 4124, 2858, 2658, 2688, 3254, 3254, 3254, 2970, 4082, 4090, 4092, 2982, 3236, 4100, 2702, 4394, 1250, 2970, 2980, 2970, 2980, 2970, 2982, 2970, 2982, 4168, 4140, 3986, 2742, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4030, 4018, 4148, 4140, 4152, 4168, 4156, 4120, 2858, 2658, 2688, 3254, 3254, 2970, 2982, 2708, 2970, 2982, 4100, 2702, 1250, 4394, 2744, 4026, 4148, 2970, 2980, 4168, 4140, 4168, 3986, 2744, 4002, 2852, 4110, 2854, 2980, 2708, 4026, 4148, 2552, 4168, 4140, 4152, 4030, 4018, 4026, 4140, 4168, 4156, 2970, 2982, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 1250, 4394, 4168, 4140, 3986, 2744, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4140, 4030, 4018, 4140, 4140, 2552, 4168, 4140, 4148, 4140, 4140, 4152, 4168, 4156, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4066, 2708, 2708, 3082, 4394, 3086, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2742, 4026, 4148, 2708, 3036, 4394, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 2982, 4148, 2708, 4026, 4140, 4152, 4168, 4030, 4018, 4156, 4406, 4410, 4408, 4412, 2980, 2980, 2970, 3492, 4066, 4068, 4396, 2980, 2708, 2970, 2980, 2970, 2980, 2970, 2980, 2744, 4148, 2970, 2980, 2970, 2980, 4124, 3224, 2690, 3224, 2690, 3224, 2690, 3224, 2690, 4126, 3224, 2690, 2684, 2846, 4124, 3224, 4022, 3032, 4394, 2654, 2708, 4392, 1200, 1202, 2652, 3260, 4092, 2708, 2980, 4396, 1286, 3132, 4394, 4396, 1286, 2652, 2654, 2708, 3082, 4392, 4394, 1200, 1202, 2708, 4394, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2708, 4124, 4072, 2970, 2982, 2708, 2970, 4082, 4090, 4092, 4084, 4094, 4090, 3236, 2974, 4100, 4124, 2708, 2970, 2980, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 4394, 1250, 2708, 2708, 3082, 1286, 3082, 1720, 1740, 1760, 1780, 1286, 2652, 3260, 4094, 3082, 3086, 1286, 1286, 1720, 1740, 1780, 2652, 3260, 4094, 2708, 2970, 4396, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708, 2970, 4082, 4090, 4092, 4084, 4090, 4094, 2988, 3236, 4100, 2702, 4394, 1250, 2970, 4396, 2980, 2970, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708]'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.events_sequence.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21",
      "metadata": {
        "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21"
      },
      "source": [
        "Also, as observed before some event types are so common they do not actually bring a lot of value (as mentioned in the paper as well). We remove those common event types\n",
        "\n",
        "The steps to clean the event sequences are:\n",
        "- keep non-common event types mentioned in list `events_low_frequency`\n",
        "- remove symbols: [] , and store sequences of events as a string without brackets and commas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca",
      "metadata": {
        "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca"
      },
      "outputs": [],
      "source": [
        "df['clean_events_sequence'] = df.events_sequence.apply(ast.literal_eval).apply(lambda x: [i for i in x if i in events_low_frequency]).astype(str)\\\n",
        "                .replace(r'[\\[\\],]', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b",
      "metadata": {
        "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b"
      },
      "source": [
        "## Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18e3f2d-8402-4608-bddc-696b656096be",
      "metadata": {
        "id": "b18e3f2d-8402-4608-bddc-696b656096be"
      },
      "source": [
        "Now we try to experiment using text techniques to transform the list events sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518",
      "metadata": {
        "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518"
      },
      "outputs": [],
      "source": [
        "target = df['incident_type'].copy() # target column separated\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.clean_events_sequence, target, test_size=0.2,  random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951515d0-d264-4008-a0b9-862d4de245b9",
      "metadata": {
        "id": "951515d0-d264-4008-a0b9-862d4de245b9"
      },
      "source": [
        "Since the dataset is imbalanced we will use different strategies to battle that. Here we set a new sampling strategy based on a basic script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
      "metadata": {
        "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
        "outputId": "eb303c48-0c0e-4222-90c4-393b38844fd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{99: 167,\n",
              " 14: 155,\n",
              " 2: 135,\n",
              " 9: 135,\n",
              " 4: 105,\n",
              " 11: 58,\n",
              " 17: 47,\n",
              " 6: 45,\n",
              " 3: 43,\n",
              " 7: 43,\n",
              " 16: 43}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define custom sampling strategy based on class distribution\n",
        "# Each non-majority class will have equal samples to 15% of the majority class plus their previous samples\n",
        "class_counts = y_train.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(y_train.value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "sampling_strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89063fd-fac4-49af-bac6-4e7556984ea9",
      "metadata": {
        "id": "e89063fd-fac4-49af-bac6-4e7556984ea9"
      },
      "source": [
        "Starting with CountVectorizer:\n",
        "- Tokenization: Splits text into individual words (tokens).\n",
        "- Builds a Vocabulary: Creates a dictionary of unique words (tokens) from the entire corpus.\n",
        "- Counts the Occurrence: Calculates the frequency (count) of each word in each document.\n",
        "- Transforms Text into a Sparse Matrix: Returns a matrix of shape (n_samples, n_features), where n_samples is the number of documents and n_features is the number of unique words in the vocabulary.\n",
        "\n",
        "  We firstly set the sampling strategy for SMOTE:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739",
      "metadata": {
        "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739"
      },
      "source": [
        "Now we set the pipeline to be used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d",
      "metadata": {
        "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d"
      },
      "outputs": [],
      "source": [
        "text_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                     #('decision_tree', DecisionTreeClassifier()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    #('random_forest', RandomForestClassifier())\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199354cb-7476-434b-92fd-f5ba688b62ce",
      "metadata": {
        "id": "199354cb-7476-434b-92fd-f5ba688b62ce"
      },
      "source": [
        "Training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
      "metadata": {
        "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
        "outputId": "ad1ccee0-3e2d-4a60-b8dd-9d850c876ec6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 135, 3: 43, 4: 105, 6: 45, 7: 43,\n",
              "                                          9: 135, 11: 58, 14: 155, 16: 43,\n",
              "                                          17: 47, 99: 167})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 135, 3: 43, 4: 105, 6: 45, 7: 43,\n",
              "                                          9: 135, 11: 58, 14: 155, 16: 43,\n",
              "                                          17: 47, 99: 167})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(k_neighbors=2, random_state=1,\n",
              "      sampling_strategy={2: 135, 3: 43, 4: 105, 6: 45, 7: 43, 9: 135, 11: 58,\n",
              "                         14: 155, 16: 43, 17: 47, 99: 167})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier()</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                ('smote',\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 135, 3: 43, 4: 105, 6: 45, 7: 43,\n",
              "                                          9: 135, 11: 58, 14: 155, 16: 43,\n",
              "                                          17: 47, 99: 167})),\n",
              "                ('extra_trees', ExtraTreesClassifier())])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f",
      "metadata": {
        "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f"
      },
      "source": [
        "Print the results for the particular split of test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
      "metadata": {
        "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
        "outputId": "ccbf12ac-4c25-4ae1-94dd-8186ba402f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.61      0.87      0.71        23\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      0.42      0.45        12\n",
            "           6       0.00      1.00      0.00         0\n",
            "           9       0.61      0.52      0.56        21\n",
            "          11       0.50      0.14      0.22         7\n",
            "          13       0.64      0.79      0.71        57\n",
            "          14       0.66      0.58      0.61        33\n",
            "          17       1.00      0.00      0.00         2\n",
            "          99       0.56      0.47      0.51        47\n",
            "\n",
            "    accuracy                           0.61       203\n",
            "   macro avg       0.51      0.48      0.38       203\n",
            "weighted avg       0.61      0.61      0.59       203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_predict = text_clf.predict(X_test)\n",
        "print(classification_report(y_test, clf_predict, zero_division=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131b2808-6a94-4c7e-b5e1-952832511e85",
      "metadata": {
        "id": "131b2808-6a94-4c7e-b5e1-952832511e85"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dea2210-71e8-4c09-8a20-347a24c61512",
      "metadata": {
        "id": "7dea2210-71e8-4c09-8a20-347a24c61512"
      },
      "source": [
        "Now we calculate the cross validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb09cd66-9c74-40d7-b566-8789fcac9c48",
      "metadata": {
        "id": "eb09cd66-9c74-40d7-b566-8789fcac9c48"
      },
      "outputs": [],
      "source": [
        "class_counts = target.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy_cross_val = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(y_train.value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "cross_val_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy_cross_val, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e64929b-894e-4eab-89a5-8f3511bbf8e2",
      "metadata": {
        "id": "5e64929b-894e-4eab-89a5-8f3511bbf8e2",
        "outputId": "f256a97b-0e15-4102-c8c1-f52e9f7ff6db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6409043854696029"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = cross_val_score(cross_val_clf, df.clean_events_sequence.sample(frac=1, random_state=1), target.sample(frac=1, random_state=1),\n",
        "                        cv=4, scoring='accuracy',n_jobs = -1)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a8558d-4b91-4f10-83fd-bb11738944f9",
      "metadata": {
        "id": "d9a8558d-4b91-4f10-83fd-bb11738944f9"
      },
      "source": [
        "Create a custom scoring f1 function with zero_division parameter for cross validation to avoid nan values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9e7a78-c871-4a73-b78c-a061d729ea16",
      "metadata": {
        "id": "4b9e7a78-c871-4a73-b78c-a061d729ea16"
      },
      "outputs": [],
      "source": [
        "# Create a custom scoring function with zero_division parameter\n",
        "def custom_f1_score(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "# Wrap the custom scoring function using make_scorer\n",
        "f1_scorer = make_scorer(custom_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7745109b-673e-4128-9d46-3cdab6b2da93",
      "metadata": {
        "id": "7745109b-673e-4128-9d46-3cdab6b2da93",
        "outputId": "db9c57cf-ad7c-4133-a2e8-a63fc21a047b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.61823676 0.61774323 0.65055584 0.57616849]\n",
            "0.615676079863001\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(cross_val_clf, df.clean_events_sequence.sample(frac=1, random_state=1), target.sample(frac=1, random_state=1),\n",
        "                        cv=4, scoring=f1_scorer,n_jobs = -1)\n",
        "print(scores)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d786ce5a-f7ea-4873-ad20-e37fb230e201",
      "metadata": {
        "id": "d786ce5a-f7ea-4873-ad20-e37fb230e201"
      },
      "source": [
        "F1 is calculated as:\n",
        "$$ F1 Score= 2×\\frac{Precision×Recall}{Precision+Recall}\n",
        "​\n",
        "$$\n",
        "There are some minority classes with no correct predictions ($recall=0$) resulting in a null value for the whole f1 score when using a non-custom f1 scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091c8078-9125-4d27-9bb7-4324688918bf",
      "metadata": {
        "id": "091c8078-9125-4d27-9bb7-4324688918bf"
      },
      "source": [
        "## GridsearchCV\n",
        "Now we use gridsearchCV to find the optimal parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e22f86-1790-4f29-badb-3baefd9a084d",
      "metadata": {
        "scrolled": true,
        "id": "77e22f86-1790-4f29-badb-3baefd9a084d",
        "outputId": "45d3ded7-70c6-4033-b7e7-bd8e3d77f144"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{99: 222,\n",
              " 14: 196,\n",
              " 2: 166,\n",
              " 9: 164,\n",
              " 4: 125,\n",
              " 11: 73,\n",
              " 17: 57,\n",
              " 6: 53,\n",
              " 3: 52,\n",
              " 16: 51,\n",
              " 7: 51}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_counts = target.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy_grid = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(y_train.value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "sampling_strategy_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a495103-d65d-4f38-9dc9-c04afadd49b0",
      "metadata": {
        "id": "6a495103-d65d-4f38-9dc9-c04afadd49b0"
      },
      "outputs": [],
      "source": [
        "grid_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy_grid, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f0c64e-3389-44a4-8060-68f6b3405a5a",
      "metadata": {
        "id": "55f0c64e-3389-44a4-8060-68f6b3405a5a",
        "outputId": "d37d1752-0dca-4627-9c94-060ffb949066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__n_estimators': 300, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
            "Best Score F1: 0.6406886229518796\n",
            "Accuracy: 0.6548246439550787\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for GridSearchCV 15%\n",
        "param_grid = {\n",
        "    'vect__max_features': [500, 1000],       # Example parameter for CountVectorizer\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (1,3)],   # Unigrams, bigrams, trigrams\n",
        "    'extra_trees__n_estimators': [100, 200, 300, 400],        # Number of trees in ExtraTrees\n",
        "    'extra_trees__max_depth': [None, 10]        # Depth of each tree\n",
        "}\n",
        "\n",
        "# Cross-validation strategy set here to replicate results\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# Define GridSearchCV with the pipeline and parameter grid\n",
        "grid_search = GridSearchCV(grid_clf, param_grid, cv=cv, scoring=f1_scorer, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "grid_search.fit(df.clean_events_sequence, target)\n",
        "\n",
        "# Output the best parameters and the best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score F1:\", grid_search.best_score_)\n",
        "print(\"Accuracy:\", str(np.mean(cross_val_score(grid_search.best_estimator_, df.clean_events_sequence, target, cv=cv, scoring='accuracy'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc6c7f72",
      "metadata": {
        "id": "cc6c7f72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043c4514",
      "metadata": {
        "id": "043c4514"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b46fda7",
      "metadata": {
        "id": "4b46fda7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "137fe5af",
      "metadata": {
        "id": "137fe5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279ce8a3-6db5-4a42-ffd2-743bb339520e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install hmmlearn umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a85fd88",
      "metadata": {
        "id": "8a85fd88"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from gensim.models import Word2Vec\n",
        "from hmmlearn import hmm\n",
        "import umap\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';')\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "dKvfCS63GPrh",
        "outputId": "3ea89644-97b2-41d7-884d-88c805bb56fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "id": "dKvfCS63GPrh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  incident_id  \\\n",
              "450         450      4454311   \n",
              "51           51      4435123   \n",
              "726         726      4466907   \n",
              "953         953      4609337   \n",
              "734         734      4467155   \n",
              "\n",
              "                                     vehicles_sequence  \\\n",
              "450  [1019, 1019, 1019, 1019, 1019, 1019, 1019, 101...   \n",
              "51   [576, 576, 576, 576, 576, 576, 576, 576, 576, ...   \n",
              "726  [537, 537, 537, 537, 537, 537, 537, 537, 537, ...   \n",
              "953  [685, 685, 685, 685, 685, 685, 685, 685, 685, ...   \n",
              "734  [529, 529, 529, 529, 529, 529, 529, 529, 529, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "450  [1566, 1570, 3634, 4124, 2956, 2956, 2956, 295...   \n",
              "51   [4396, 1286, 4394, 1566, 1570, 4396, 2742, 414...   \n",
              "726  [668, 2534, 2492, 2494, 4102, 4106, 2498, 3986...   \n",
              "953  [1566, 1570, 2744, 4148, 3634, 4168, 4140, 398...   \n",
              "734  [4016, 4114, 4168, 3986, 4114, 4002, 4028, 403...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "450  [-9291, -9291, -7523, -6041, -6018, -5943, -59...   50.590768   \n",
              "51   [-13601, -13601, -7131, -7131, -7131, -7036, -...   50.816996   \n",
              "726  [-5858, -5737, -5556, -5256, -5240, -5240, -49...   50.445925   \n",
              "953  [-5031, -5031, -2756, -2756, -2658, -2632, -26...   50.892857   \n",
              "734  [-13030, -12982, -12982, -12939, -12939, -1261...   50.584885   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "450    5.451064  [0.0, 0.0, 0.0, 0.0, 12.2, 25.5, 24.9, 24.7, 0...   \n",
              "51     3.243953  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "726    3.898664  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "953    4.409133  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "734    4.622090  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "450  [False, False, False, False, False, False, Fal...   \n",
              "51   [False, False, False, False, False, False, Fal...   \n",
              "726  [False, False, False, False, False, False, Fal...   \n",
              "953  [False, False, False, False, False, False, Fal...   \n",
              "734  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "450  [True, True, True, True, True, True, True, Tru...             99  \n",
              "51   [True, True, True, True, True, True, True, Tru...              2  \n",
              "726  [True, False, False, False, False, False, Fals...              2  \n",
              "953  [True, True, True, True, True, True, False, Fa...             99  \n",
              "734  [True, True, True, False, False, False, False,...             13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d60ffc48-55fa-45a9-a914-b7694c2300d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>450</td>\n",
              "      <td>4454311</td>\n",
              "      <td>[1019, 1019, 1019, 1019, 1019, 1019, 1019, 101...</td>\n",
              "      <td>[1566, 1570, 3634, 4124, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-9291, -9291, -7523, -6041, -6018, -5943, -59...</td>\n",
              "      <td>50.590768</td>\n",
              "      <td>5.451064</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 12.2, 25.5, 24.9, 24.7, 0...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>4435123</td>\n",
              "      <td>[576, 576, 576, 576, 576, 576, 576, 576, 576, ...</td>\n",
              "      <td>[4396, 1286, 4394, 1566, 1570, 4396, 2742, 414...</td>\n",
              "      <td>[-13601, -13601, -7131, -7131, -7131, -7036, -...</td>\n",
              "      <td>50.816996</td>\n",
              "      <td>3.243953</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>726</td>\n",
              "      <td>4466907</td>\n",
              "      <td>[537, 537, 537, 537, 537, 537, 537, 537, 537, ...</td>\n",
              "      <td>[668, 2534, 2492, 2494, 4102, 4106, 2498, 3986...</td>\n",
              "      <td>[-5858, -5737, -5556, -5256, -5240, -5240, -49...</td>\n",
              "      <td>50.445925</td>\n",
              "      <td>3.898664</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, False, False, False, False, False, Fals...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>953</td>\n",
              "      <td>4609337</td>\n",
              "      <td>[685, 685, 685, 685, 685, 685, 685, 685, 685, ...</td>\n",
              "      <td>[1566, 1570, 2744, 4148, 3634, 4168, 4140, 398...</td>\n",
              "      <td>[-5031, -5031, -2756, -2756, -2658, -2632, -26...</td>\n",
              "      <td>50.892857</td>\n",
              "      <td>4.409133</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, False, Fa...</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>734</td>\n",
              "      <td>4467155</td>\n",
              "      <td>[529, 529, 529, 529, 529, 529, 529, 529, 529, ...</td>\n",
              "      <td>[4016, 4114, 4168, 3986, 4114, 4002, 4028, 403...</td>\n",
              "      <td>[-13030, -12982, -12982, -12939, -12939, -1261...</td>\n",
              "      <td>50.584885</td>\n",
              "      <td>4.622090</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, False, False, False, False,...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60ffc48-55fa-45a9-a914-b7694c2300d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d60ffc48-55fa-45a9-a914-b7694c2300d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d60ffc48-55fa-45a9-a914-b7694c2300d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4ff62f4-d575-4101-b81d-3c49410cce40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4ff62f4-d575-4101-b81d-3c49410cce40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4ff62f4-d575-4101-b81d-3c49410cce40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346,\n        \"min\": 51,\n        \"max\": 953,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          51,\n          734,\n          726\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69861,\n        \"min\": 4435123,\n        \"max\": 4609337,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4435123,\n          4467155,\n          4466907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576, 576]\",\n          \"[529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 529, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1060, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087, 1087]\",\n          \"[537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 537, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[4396, 1286, 4394, 1566, 1570, 4396, 2742, 4148, 2740, 4168, 4408, 4412, 4140, 3986, 4002, 2852, 4110, 2854, 4026, 2708, 2744, 4026, 4148, 4030, 4018, 4026, 4140, 4152, 4168, 4156, 3540, 2708, 2852, 2854, 3254, 3254, 3254, 4180, 4066, 4068, 4124, 3634, 2858, 2658, 2688, 4066, 4068, 2708, 4056, 3548, 4394, 4056, 2742, 4026, 4148, 2852, 2854, 3254, 3254, 3254, 4180, 2886, 3632, 4120, 2858, 2658, 2688, 2708, 2970, 4082, 4090, 4092, 4084, 4094, 4090, 3234, 3540, 2982, 4100, 2702, 4394, 1250, 4120, 4120, 4168, 4140, 2708, 3986, 2742, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4148, 4030, 4018, 4140, 4152, 4168, 4156, 3540, 2742, 4148, 4066, 4068, 3548, 4394, 4056, 2744, 4148, 4026, 2742, 4026, 4148, 2970, 4082, 4090, 4092, 3540, 2982, 4100, 2702, 4394, 1250, 2744, 4026, 4148, 3548, 4394, 3540, 2742, 4148, 4070, 4056, 2744, 4148, 4026]\",\n          \"[4016, 4114, 4168, 3986, 4114, 4002, 4028, 4032, 2852, 4026, 4110, 2854, 4026, 4016, 4020, 4026, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4394, 1566, 1570, 4068, 4066, 3256, 4026, 4016, 4026, 4020, 3256, 3008, 4082, 4092, 4094, 4068, 3364, 3354, 3658, 4394, 154, 152, 4068, 3658, 4066, 3658, 4066, 3658, 4068, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4394, 154, 152, 3354, 3364, 4068, 3658, 4068, 3658, 4066, 3658, 4066, 4026, 4016, 4026, 4020, 3658, 4066, 4114, 3986, 4004, 4032, 4028, 4026, 2852, 4110, 2854, 4026, 4016, 4020, 4140, 4152, 4168, 4156, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 4016, 4114, 4168, 4140, 3986, 4114, 4004, 4032, 4028, 4026, 2852, 4110, 2854, 2708, 2742, 4026, 4030, 4070, 4020, 4148, 4140, 4162, 4150, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4394, 4120, 2852, 2854, 4120, 2858, 2658, 2688, 2708, 4066, 4068, 3256, 3254, 3254, 4180, 3254, 4396, 1584, 4026, 4016, 4026, 4020, 3256, 3008, 4092, 4082, 4094, 4068, 3354, 4068, 4066, 4066, 4068, 4066, 4066, 4066, 4066, 3354, 4068, 4068, 4066, 4066, 2742, 4026, 2708, 4026, 4020, 2936, 3636, 4066, 2708, 2936, 2938, 2968, 4394, 4396, 3986, 4002, 4032, 4028, 4026, 2852, 4110, 2854, 2708, 2742, 4026, 4030, 4020, 4026, 4148, 4140, 2610, 4162, 4150, 4152, 4168, 4156, 4120, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4068, 2744, 4168, 4140, 3986, 4002, 4032, 2852, 4028, 4110, 4026, 2854, 4026, 4016, 4020, 4026, 4140, 4162, 4150, 4152, 2610, 4168, 4156, 4406, 4410, 4408, 4412, 4066, 4068, 3256, 2744, 4026, 2708, 4026, 4020, 4396, 4148, 3634, 2852, 2854, 4124, 4124, 2858, 2658, 2688, 2708, 3256, 3254, 3254, 3254, 4180, 3008, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 4090, 4090, 3236, 2974, 4100, 4124, 2686, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3354, 3636, 4394, 4396, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4124, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3008, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4124, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3982, 2956, 2956, 4394, 2956, 2956, 2956, 2956, 3354, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4124, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 4016, 4026, 4026, 4020, 4066, 3986, 4114, 4004, 4032, 2852, 4028, 4110, 4026, 2854, 4016, 4020, 4026, 2610, 4140, 4162, 4150, 4152, 4168, 4156, 2602, 4068, 4068, 4068, 4068, 4068, 4068]\",\n          \"[668, 2534, 2492, 2494, 4102, 4106, 2498, 3986, 4004, 4028, 4032, 2852, 4026, 4110, 2854, 4016, 4026, 4026, 4020, 4140, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4066, 4068, 148, 2744, 4026, 2708, 4026, 4020, 2970, 4092, 4082, 4090, 4094, 4084, 4090, 4090, 3236, 2974, 4100, 3634, 4124, 2956, 2956, 2956, 2686, 4124, 2956, 2708, 4026, 4016, 4026, 4020, 4050, 4032, 4026, 3520, 356, 2708, 2744, 4026, 2740, 4030, 4018, 4026, 3256, 4066, 2744, 2744, 3236, 2938, 982, 2744, 3548, 3256, 3548, 2744, 2744, 3528, 2742, 3520, 4050, 3520, 356, 4050, 2744, 3636, 3658, 4078, 4124, 2956, 2956, 4396, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4078, 3620, 2956, 2956, 2956, 4068, 3636, 3658, 4078, 2956, 4068, 3636, 3658, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 3636, 3658, 2742, 4070, 4120, 2956, 2956, 2956, 2956, 2956, 2708, 4120, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 668, 2534, 2492, 2494, 4102, 4106, 2498, 3986, 4004, 4032, 2852, 4028, 4110, 2854, 4026, 4092, 4094, 2742, 4148, 4026, 2708, 4394, 4030, 4026, 4020, 4140, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4066, 4068, 4120, 3490, 2858, 2650, 3620, 2658, 2688, 3254, 4180, 3254, 3254, 2852, 2854, 152, 4016, 4026, 4020, 4082, 4092, 4094, 2742, 2708, 4020, 3632, 4120, 2956, 2708, 4024, 3506, 2744, 4056, 4032, 2708, 4026, 4030, 2740, 4018, 4126, 2682, 4124, 2858, 2658, 2688, 3254, 4180, 3254, 3254, 2852, 2854, 2708, 4066, 4124, 3636, 3658, 4078, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4078, 2956, 4066, 3636, 3658, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2742, 4026]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[-13601, -13601, -7131, -7131, -7131, -7036, -2076, -2076, -2074, -2069, -2067, -2067, -2062, -2037, -1874, -1871, -1871, -1870, -1868, -1867, -1867, -1867, -1867, -1825, -1821, -1821, -1816, -1815, -1805, -1803, -1773, -1772, -1718, -1716, -1699, -1698, -1668, -1668, -1633, -1632, -1615, -1596, -1549, -1547, -1547, -1462, -1462, -1453, -1407, -1309, -1309, -1307, -1228, -1228, -1228, -1192, -1191, -1168, -1167, -1160, -1160, -1159, -1125, -1121, -1046, -1043, -1043, -819, -812, -776, -776, -776, -748, -748, -747, -690, -678, -677, -660, -658, -658, -658, -627, -608, -558, -552, -540, -525, -338, -338, -336, -336, -334, -334, -333, -333, -333, -296, -293, -289, -287, -279, -276, -239, -15, -15, -13, -13, 264, 264, 520, 525, 525, 526, 603, 603, 603, 637, 680, 680, 680, 709, 711, 725, 726, 726, 726, 964, 964, 964, 975, 975, 984, 1422, 1422, 1432, 2061, 2215, 2215, 2216]\",\n          \"[-13030, -12982, -12982, -12939, -12939, -12616, -12616, -12616, -12614, -12614, -12614, -12612, -12580, -12579, -12562, -12562, -12551, -12544, -12522, -12520, -12509, -12506, -12497, -12497, -12470, -12470, -12470, -12305, -12304, -12298, -11577, -11576, -11575, -11573, -11311, -11253, -11088, -11088, -11080, -9803, -7837, -7836, -7832, -7793, -7793, -7792, -7273, -7254, -7010, -6997, -6534, -6501, -6332, -6299, -5256, -5136, -4376, -4352, -3542, -3206, -2922, -2890, -2824, -2824, -2823, -2777, -2777, -2189, -2167, -1948, -1931, -1594, -1574, -1121, -442, -441, -440, -439, -37, 35, 684, 685, 905, 905, 906, 907, 908, 908, 909, 938, 939, 956, 1007, 1014, 1046, 1048, 1905, 1921, 2262, 2271, 2503, 2513, 3106, 3120, 3368, 3403, 3579, -13029, -12980, -12980, -12962, -12937, -12937, -12615, -12615, -12614, -12613, -12612, -12612, -12610, -12579, -12579, -12579, -12562, -12562, -12560, -12560, -12550, -12547, -12545, -12542, -12521, -12519, -12507, -12505, -12498, -12494, -12465, -12409, -12402, -12401, -12396, -12334, -12332, -12332, -12318, -12303, -12303, -12296, -12259, -12257, -12251, -12250, -12166, -12166, -11575, -11574, -11573, -11572, -11310, -11251, -11074, -11073, -11065, -9801, -7835, -7272, -7009, -6532, -6331, -5254, -4374, -3540, -2921, -2775, -2187, -1946, -1593, -1119, -441, -441, -439, -439, -438, -202, -35, 36, 215, 261, 261, 262, 262, 324, 686, 907, 907, 908, 909, 910, 910, 911, 940, 940, 940, 955, 958, 958, 978, 1008, 1011, 1011, 1013, 1015, 1047, 1050, 1252, 1441, 1466, 1479, 1495, 1503, 1531, 1554, 1581, 1599, 1617, 1648, 1655, 1671, 1701, 1741, 1768, 1805, 1806, 1819, 1835, 1851, 1869, 1906, 1923, 1967, 1979, 1986, 1992, 2012, 2034, 2057, 2078, 2116, 2140, 2156, 2196, 2217, 2222, 2230, 2264, 2273, 2355, 2375, 2415, 2474, 2505, 2515, 2591, 2615, 2630, 2644, 2647, 2659, 2690, 2699, 2730, 2740, 2748, 2785, 2797, 2837, 2852, 2859, 2899, 2901, 2910, 2950, 2952, 2971, 3009, 3040, 3054, 3072, 3081, 3108, 3122, 3170, 3172, 3175, 3178, 3198, 3207, 3213, 3222, 3224, 3278, 3298, 3322, 3331, 3339, 3370, 3405, 3581, -13032, -12982, -12964, -12939, -12617, -12617, -12614, -12614, -12614, -12613, -12612, -12579, -12578, -12560, -12560, -12550, -12546, -12543, -12540, -12527, -12521, -12518, -12507, -12505, -12495, -12495, -12303, -12303, -12296, -11575, -11575, -11573, -11573, -11572, -11558, -11517, -11514, -11421, -11419, -11418, -11414, -11351, -11350, -11350, -11315, -11310, -11266, -11264, -11256, -11256, -11254, -11187, -11144, -11144, -11143, -11115, -11115, -11114, -11086, -11073, -11017, -10853, -10841, -10551, -10483, -10230, -10076, -10074, -10070, -10027, -10010, -9989, -9980, -9958, -9947, -9946, -9923, -9917, -9915, -9853, -9846, -9801, -7835, -7830, -7789, -7773, -7689, -7653, -7648, -7621, -7617, -7613, -7593, -7587, -7585, -7580, -7555, -7547, -7541, -7493, -7402, -7384, -7376, -7332, -7321, -7272, -7252, -7204, -7198, -7175, -7172, -7157, -7153, -7134, -7130, -7125, -7112, -7108, -7050, -7035, -7008, -6995, -6953, -6932, -6907, -6905, -6884, -6881, -6877, -6846, -6840, -6824, -6818, -6800, -6769, -6764, -6760, -6743, -6727, -6714, -6700, -6692, -6689, -6680, -6677, -6670, -6655, -6647, -6645, -6639, -6600, -6572, -6566, -6562, -6532, -6499, -6426, -6376, -6331, -6297, -6225, -6178, -6147, -6144, -6117, -6087, -6057, -6036, -6032, -6019, -6001, -5988, -5981, -5968, -5956, -5940, -5919, -5917, -5874, -5866, -5833, -5825, -5823, -5786, -5778, -5776, -5735, -5726, -5702, -5699, -5694, -5691, -5682, -5649, -5640, -5612, -5601, -5576, -5569, -5567, -5548, -5534, -5525, -5501, -5499, -5485, -5477, -5469, -5467, -5434, -5419, -5408, -5404, -5311, -5306, -5289, -5275, -5254, -5134, -5100, -5072, -4991, -4980, -4964, -4964, -4938, -4936, -4925, -4904, -4901, -4899, -4890, -4883, -4847, -4827, -4789, -4766, -4764, -4745, -4720, -4701, -4657, -4644, -4641, -4627, -4593, -4585, -4573, -4549, -4540, -4522, -4504, -4496, -4473, -4460, -4451, -4442, -4409, -4401, -4387, -4374, -4350, -4304, -4278, -4267, -4257, -4255, -4245, -4205, -4197, -4158, -4149, -4147, -4111, -4102, -4097, -4048, -4046, -4003, -3999, -3989, -3962, -3956, -3946, -3939, -3906, -3887, -3841, -3839, -3786, -3783, -3712, -3709, -3685, -3668, -3603, -3593, -3540, -3204, -3186, -3170, -3153, -3132, -3124, -3105, -3097, -3031, -3030, -3018, -3011, -3000, -2977, -2972, -2969, -2955, -2920, -2888, -2853, -2846, -2825, -2821, -2817, -2812, -2797, -2785, -2775, -2770, -2748, -2733, -2726, -2685, -2675, -2648, -2628, -2614, -2592, -2567, -2546, -2543, -2541, -2531, -2505, -2493, -2491, -2457, -2437, -2281, -2261, -2235, -2220, -2187, -2165, -2123, -2076, -2046, -2030, -1946, -1929, -1891, -1883, -1879, -1862, -1824, -1809, -1784, -1748, -1730, -1710, -1687, -1662, -1653, -1630, -1592, -1572, -1529, -1504, -1491, -1483, -1472, -1469, -1457, -1442, -1424, -1405, -1399, -1395, -1358, -1356, -1319, -1318, -1304, -1282, -1248, -1224, -1190, -1183, -1171, -1164, -1133, -1119, -1111, -440, -440, -439, -438, 37, 686, 686, 903, 903, 906, 906, 906, 907, 908, 939, 956, 956, 994, 1007, 1010, 1013, 1013, 1046, 1048, 1259, 1905, 2262, 2503, 3106, 3369, 3579]\",\n          \"[-5858, -5737, -5556, -5256, -5240, -5240, -4956, -4945, -3102, -3102, -3102, -3100, -3100, -3100, -3098, -3046, -3046, -3037, -3036, -3035, -3022, -3022, -3012, -3010, -2997, -2993, -2986, -2984, -2977, -2977, -2977, -2638, -2638, -2636, -2636, -2635, -2606, -2575, -2574, -2574, -2546, -2545, -2545, -2516, -2439, -2314, -2297, -1424, -1413, -1283, -1221, -1155, -1036, -946, -924, -782, -604, -603, -602, -601, -315, -314, -310, -293, -285, -254, -254, -254, -249, -241, -240, -240, -237, -236, -197, -42, -15, 39, 41, 48, 61, 65, 81, 198, 230, 329, 336, 337, 404, 409, 409, 412, 482, 506, 506, 521, 539, 669, 673, 686, 689, 725, 736, 738, 792, 823, 842, 842, 876, 897, 908, 912, 923, 936, 950, 991, 1006, 1006, 1077, 1094, 1127, 1145, 1151, 1176, 1231, 1234, 1253, 1275, 1275, 1349, 1352, 1426, 1437, 1449, 1455, 1483, 1504, 1523, 1523, 1558, 1564, 1592, 1653, 1669, 1694, 1722, 1722, 1729, 1837, 1845, 1860, 1860, 1871, 1901, 1915, 1959, 1972, 2025, 2049, 2088, 2133, 2140, 2196, 2196, 2210, 2468, 2526, 2598, 2615, 2694, 2723, 2883, 3014, 3102, 3112, 3124, 3137, 3225, 3240, 3325, 3344, 3382, 3396, 3418, 3430, 3513, 3517, 3551, 3554, -5860, -5740, -5559, -5259, -5243, -5243, -4959, -4948, -3102, -3102, -3100, -3100, -3100, -3098, -3098, -3097, -3097, -3045, -3045, -3044, -3043, -3043, -3037, -3035, -3034, -3034, -3020, -3019, -3011, -3008, -2996, -2995, -2985, -2985, -2976, -2976, -2976, -2959, -2935, -2934, -2934, -2933, -2933, -2919, -2919, -2889, -2888, -2880, -2879, -2859, -2635, -2634, -2633, -2515, -2515, -2507, -602, -600, -600, -593, -580, -473, -400, -321, -319, -313, -313, -312, -308, -308, -304, -303, -303, -300, -298, -258, -193, -192, -192, -189, -189, -164, -162, -155, -153, -149, 497, 919, 1035, 1035, 1052, 1192, 1322, 1327, 1360, 1363, 1365, 1384, 1412, 1429, 1454, 1486, 1493, 1533, 1566, 1586, 1586, 1599, 1671, 1779, 1797, 1797, 1807, 1859, 1921, 1963, 1982, 2025, 2052, 2191, 2226, 2243, 2262, 2467, 2467]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1836680346546459,\n        \"min\": 50.445925482165606,\n        \"max\": 50.89285668588957,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          50.816996436428575,\n          50.58488492240216,\n          50.445925482165606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8236786404823616,\n        \"min\": 3.243952700714286,\n        \"max\": 5.451063699637682,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.243952700714286,\n          4.622089964237516,\n          3.898663960191083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\",\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.0, 0.0, 0.0, 82.0, 82.0, 82.5, 87.6, 87.7, 0.2, 0.0, 0.2, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.3, 0.0, 0.1, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.2, 0.2, 87.6, 0.2, 0.2, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 22.3, 31.9, 32.8, 34.4, 36.7, 48.4, 61.4, 69.8, 78.2, 77.3, 76.9, 84.1, 84.3, 80.4, 84.9, 85.0, 70.1, 69.0, 64.7, 44.7, 0.2, 0.0, 9.7, 37.6, 47.7, 51.4, 51.9, 50.3, 48.3, 49.3, 54.4, 57.4, 56.2, 51.0, 49.5, 52.2, 49.6, 0.1, 0.0, 55.3, 60.1, 60.1, 56.9, 0.0, 0.0, 6.8, 40.3, 55.5, 64.2, 65.5, 76.3, 79.8, 82.8, 86.8, 85.9, 85.0, 83.1, 81.7, 79.4, 79.6, 81.1, 79.4, 79.4, 78.9, 79.7, 80.2, 82.0, 77.9, 74.2, 73.3, 71.8, 53.4, 0.1, 0.0, 63.7, 68.2, 68.6, 67.7, 77.5, 73.9, 71.9, 69.5, 68.0, 40.1, 38.5, 27.9, 24.0, 21.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 26.9, 26.0, 25.4, 28.2, 33.4, 34.7, 35.9, 36.0, 32.3, 31.8, 30.3, 33.1, 35.3, 25.7, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.2, 27.7, 25.9, 26.2, 26.2, 34.6, 34.9, 34.7, 34.7, 29.8, 27.0, 25.0, 5.4, 0.0, 9.1, 12.7, 14.8, 14.9, 0.0, 0.0, 20.3, 31.2, 42.2, 41.7, 41.2, 41.3, 40.8, 40.4, 40.0, 37.4, 36.3, 30.3, 30.0, 0.0, 0.0, 10.2, 27.4, 38.2, 38.3, 41.4, 41.6, 42.0, 44.2, 46.4, 46.5, 44.9, 37.1, 38.8, 43.4, 46.4, 57.2, 74.2, 80.0, 88.0, 87.0, 86.9, 84.1, 82.4, 71.3, 52.2, 48.6, 47.6, 45.7, 44.4, 34.9, 35.2, 36.1, 0.1, 0.0, 25.2, 31.9, 0.0, 0.0, 19.0, 35.7, 36.2, 35.0, 52.0, 76.3, 91.3, 85.2, 84.1, 84.9, 81.3, 81.0, 80.0, 83.5, 84.9, 97.1, 116.6, 119.1, 125.2, 125.6, 127.4, 127.3, 126.8, 124.4, 124.9, 125.0, 126.8, 127.1, 126.6, 125.9, 126.1, 125.7, 125.8, 126.8, 126.5, 126.1, 127.4, 124.8, 125.5, 125.7, 127.2, 125.3, 125.7, 127.1, 124.9, 95.8, 78.9, 64.7, 65.3, 44.6, 40.6, 37.9, 36.8, 34.4, 33.5, 29.6, 20.7, 0.0, 0.0, 0.0, 29.8, 36.8, 39.4, 47.8, 48.2, 86.8, 89.5, 101.2, 116.2, 116.7, 117.2, 95.3, 80.4, 51.5, 50.7, 41.1, 49.1, 49.4, 54.0, 58.4, 52.6, 74.2, 86.7, 89.4, 103.0, 126.5, 122.5, 114.8, 124.3, 125.0, 127.9, 127.6, 122.1, 116.5, 115.1, 116.4, 105.3, 57.8, 52.8, 36.3, 0.1, 0.0, 29.9, 86.0, 97.0, 102.4, 102.7, 106.5, 121.8, 124.3, 111.2, 111.7, 112.3, 120.7, 118.0, 115.9, 122.4, 122.5, 122.2, 119.5, 107.3, 73.4, 70.4, 63.4, 59.1, 53.3, 65.9, 96.6, 97.2, 81.9, 80.4, 45.0, 44.9, 43.6, 45.4, 30.0, 21.3, 0.1, 0.0, 0.0, 6.4, 19.9, 31.5, 32.1, 32.8, 32.0, 54.5, 56.2, 58.2, 57.9, 59.4, 69.6, 69.8, 67.7, 46.9, 0.0, 0.0, 22.7, 40.6, 81.8, 82.7, 83.0, 84.0, 85.9, 86.7, 87.6, 87.9, 87.9, 87.9, 88.2, 88.5, 87.7, 87.7, 88.1, 88.2, 88.2, 88.1, 87.9, 88.1, 88.0, 87.9, 88.2, 88.1, 87.9, 52.0, 39.5, 0.0, 11.6, 35.1, 35.8, 0.2, 0.0, 38.1, 85.5, 84.5, 64.8, 0.1, 0.0, 35.9, 56.9, 59.0, 60.2, 57.8, 56.3, 53.7, 54.6, 57.2, 57.0, 43.7, 33.5, 33.6, 30.5, 0.0, 0.0, 27.2, 30.1, 58.5, 76.2, 83.3, 83.9, 85.0, 87.4, 88.0, 87.8, 88.0, 88.2, 87.8, 88.6, 88.1, 88.2, 87.8, 87.9, 60.4, 35.3, 35.7, 36.0, 36.7, 35.7, 15.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.1, 0.2, 0.1, 0.0]\",\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.6, 19.2, 21.0, 0.0, 0.0, 13.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.7, 54.2, 75.9, 80.7, 99.5, 97.9, 97.2, 54.2, 0.1, 0.0, 0.0, 27.8, 86.3, 94.1, 94.1, 92.1, 80.5, 69.4, 0.1, 0.0, 0.0, 65.2, 61.9, 58.8, 57.0, 52.1, 38.3, 35.1, 34.9, 0.0, 0.0, 0.0, 35.8, 36.2, 34.7, 41.7, 65.1, 65.1, 40.3, 0.1, 0.0, 0.0, 0.0, 0.0, 62.3, 84.9, 45.6, 0.0, 0.0, 0.0, 0.0, 25.1, 0.1, 0.0, 0.0, 0.0, 51.1, 89.1, 114.4, 115.8, 55.5, 37.8, 20.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.1, 65.8, 56.2, 53.0, 25.2, 0.0, 0.0, 0.0, 15.9, 53.2, 74.7, 73.7, 55.7, 55.5, 27.8, 26.8, 32.2, 33.4, 27.7, 27.9, 33.5, 34.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 26.4, 36.5, 37.4, 39.4, 67.5, 108.0, 123.3, 134.8, 134.5, 135.1, 66.9, 0.0, 0.0, 0.0, 0.0, 19.8, 0.1, 0.0, 0.0, 0.0, 47.3, 112.9, 121.7, 85.2, 45.3, 34.1, 22.5, 10.1, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True]\",\n          \"[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 2,\n        \"max\": 99,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          99,\n          2,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in [\"dj_dc_state_sequence\", \"dj_ac_state_sequence\"]:\n",
        "  flags = []\n",
        "  for values in df[column]:\n",
        "    flags.append(np.unique(values))\n",
        "  df[column] = flags"
      ],
      "metadata": {
        "id": "_5AOdzusHxn8"
      },
      "id": "_5AOdzusHxn8",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flags"
      ],
      "metadata": {
        "id": "xsfxmoy-OptQ",
        "outputId": "e353667b-e58f-4e61-a4cb-eb0ed7973686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "id": "xsfxmoy-OptQ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'flags' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1ca48caf0ae0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'flags' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1tIm6bNAM1fJ",
        "outputId": "f92feebe-5f9c-46ed-99f2-aeffe57b352a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "id": "1tIm6bNAM1fJ",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  incident_id                                  vehicles_sequence  \\\n",
              "0           0      4432881  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n",
              "1           1      4432943  [526, 526, 526, 526, 526, 526, 526, 526, 526, ...   \n",
              "2           2      4432955  [592, 592, 592, 592, 592, 592, 592, 592, 592, ...   \n",
              "3           3      4433021  [576, 576, 576, 576, 576, 576, 576, 576, 576, ...   \n",
              "4           4      4433129  [634, 634, 634, 634, 634, 634, 634, 634, 634, ...   \n",
              "\n",
              "                                     events_sequence  \\\n",
              "0  [2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...   \n",
              "1  [2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...   \n",
              "2  [4394, 1566, 1570, 4114, 4168, 4168, 4156, 406...   \n",
              "3  [4066, 4066, 4066, 4066, 4068, 2742, 4026, 270...   \n",
              "4  [4002, 4032, 4028, 2852, 4026, 4110, 2742, 285...   \n",
              "\n",
              "                        seconds_to_incident_sequence  approx_lat  approx_lon  \\\n",
              "0  [-5510, -5510, -5507, -5507, -5506, -5506, -55...   50.876601    4.718143   \n",
              "1  [-8573, -8573, -8032, -8032, -8032, -7859, -61...   51.037435    4.431218   \n",
              "2  [-12291, -12291, -12291, -10932, -10932, -1091...   50.864083    4.162115   \n",
              "3  [-14351, -14204, -13890, -13383, -12739, -1243...   51.183220    4.276025   \n",
              "4  [-224, -224, -223, -222, -222, -222, -220, -22...   50.818727    3.253601   \n",
              "\n",
              "                                  train_kph_sequence  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                dj_ac_state_sequence  \\\n",
              "0  [[False, False, False, False, False, False, Fa...   \n",
              "1  [[False, False, False, False, False, False, Fa...   \n",
              "2  [[False, False, False, False, False, False, Fa...   \n",
              "3  [[False, False, False, False, False, False, Fa...   \n",
              "4  [[False, False, False, False, False, False, Fa...   \n",
              "\n",
              "                                dj_dc_state_sequence  incident_type  \n",
              "0  [[False, False, False, False, False, False, Fa...              4  \n",
              "1  [[False, False, False, False, False, False, Fa...             13  \n",
              "2  [[False, False, False, False, False, False, Fa...             14  \n",
              "3  [[False, False, False, False, False, False, Fa...              2  \n",
              "4  [[False, False, False, False, False, False, Fa...             14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e977259-5adb-4278-a723-4d30a1b5b972\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4432881</td>\n",
              "      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n",
              "      <td>[2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...</td>\n",
              "      <td>[-5510, -5510, -5507, -5507, -5506, -5506, -55...</td>\n",
              "      <td>50.876601</td>\n",
              "      <td>4.718143</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4432943</td>\n",
              "      <td>[526, 526, 526, 526, 526, 526, 526, 526, 526, ...</td>\n",
              "      <td>[2744, 4148, 4394, 1566, 1570, 4396, 3634, 412...</td>\n",
              "      <td>[-8573, -8573, -8032, -8032, -8032, -7859, -61...</td>\n",
              "      <td>51.037435</td>\n",
              "      <td>4.431218</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1,...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4432955</td>\n",
              "      <td>[592, 592, 592, 592, 592, 592, 592, 592, 592, ...</td>\n",
              "      <td>[4394, 1566, 1570, 4114, 4168, 4168, 4156, 406...</td>\n",
              "      <td>[-12291, -12291, -12291, -10932, -10932, -1091...</td>\n",
              "      <td>50.864083</td>\n",
              "      <td>4.162115</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4433021</td>\n",
              "      <td>[576, 576, 576, 576, 576, 576, 576, 576, 576, ...</td>\n",
              "      <td>[4066, 4066, 4066, 4066, 4068, 2742, 4026, 270...</td>\n",
              "      <td>[-14351, -14204, -13890, -13383, -12739, -1243...</td>\n",
              "      <td>51.183220</td>\n",
              "      <td>4.276025</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4433129</td>\n",
              "      <td>[634, 634, 634, 634, 634, 634, 634, 634, 634, ...</td>\n",
              "      <td>[4002, 4032, 4028, 2852, 4026, 4110, 2742, 285...</td>\n",
              "      <td>[-224, -224, -223, -222, -222, -222, -220, -22...</td>\n",
              "      <td>50.818727</td>\n",
              "      <td>3.253601</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>[[False, False, False, False, False, False, Fa...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e977259-5adb-4278-a723-4d30a1b5b972')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e977259-5adb-4278-a723-4d30a1b5b972 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e977259-5adb-4278-a723-4d30a1b5b972');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16f7a7dd-b27b-4e93-9376-89e6bd80f9a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16f7a7dd-b27b-4e93-9376-89e6bd80f9a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16f7a7dd-b27b-4e93-9376-89e6bd80f9a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1011,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 291,\n        \"min\": 0,\n        \"max\": 1010,\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          630,\n          633,\n          685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1251746,\n        \"min\": 4432881,\n        \"max\": 44233933,\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          4461927,\n          4461987,\n          4465121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          \"[526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 526, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696, 696]\",\n          \"[707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070, 1070]\",\n          \"[1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1030, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032, 1032]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          \"[4028, 4028, 4026, 2492, 4396, 494, 4028, 4106, 4108, 4004, 4032, 4028, 2852, 4110, 2854, 2910, 4028, 2930, 4028, 4106, 4108, 4002, 4028, 4032, 2852, 4026, 4110, 2854, 4028, 4026, 4028, 4028, 4026, 2492, 494, 524, 4396, 3380, 4004, 4032, 4026, 4028, 2852, 4110, 2854, 4028, 4002, 4032, 4026, 4028, 2852, 4110, 2854, 4028, 2930, 4026, 4016, 4020, 4026, 4140, 4140, 4168, 4066, 4068, 4026, 4024, 4024, 4168, 4028, 4004, 4032, 4028, 2852, 4026, 4110, 2854, 4026, 4016, 4028, 4026, 2930, 4020, 4026, 4140, 4026, 4140, 4066, 4140, 4020, 4026, 4140, 4140, 3238, 3512, 4028, 4392, 2752, 4032, 4026, 3520, 356, 4032, 4002, 4028, 4032, 4026, 2852, 4110, 2854, 4092, 4094, 4028, 2930, 4028, 4032, 4026, 3238, 3260, 3512, 3520, 356, 4392, 4004, 4032, 4028, 4016, 4026, 2852, 4110, 2854, 4140, 4152, 4020, 4168, 4156, 3984, 4106, 4108, 4406, 4408, 4410, 4412, 4396, 4394, 152, 3256, 4022, 3506, 4050, 3506, 4066, 4066, 4024, 3506, 2744, 4056, 4032, 2708, 4026, 2740, 4030, 4018, 4126, 3620, 3634, 4126, 2708, 2744, 2742, 4148, 4120, 2858, 2658, 2688, 2852, 2854, 3254, 4180, 3008, 3254, 3254, 2886, 2744, 4026, 4124, 4066, 4068, 3986, 4004, 4028, 4032, 2852, 3492, 4110, 4396, 2854, 2674, 4394, 1566, 1570, 4028, 4026, 2492, 494, 524, 4396, 3986, 4002, 4032, 4110, 4028, 2852, 4026, 2854, 4028, 4026, 1566, 1570, 4394, 4028, 2492, 4396, 494, 524, 4028, 4026, 4028, 4026, 3986, 4004, 4032, 4028, 2852, 4026, 4110, 2854, 4026, 3860, 3868, 1102, 4394, 1102, 1002, 1052, 1002, 1052, 4002, 4032, 4110, 4028, 2852, 4026, 2854, 4028, 4026, 2930, 2910, 4026, 4394, 1102, 1002, 1002, 1002, 4004, 4032, 4028, 2852, 4026, 4110, 2854, 1056, 2930, 4028, 2910, 2742, 4026, 4148, 2708, 4394, 4030, 4140, 4020, 4026, 4140, 4128, 4152, 4168, 4156, 4068, 4066, 4026, 2740, 4070, 1102, 1102, 1002, 390, 4296, 4130, 4070, 4168, 1210, 2708, 4028, 4396, 2708, 4026, 2740, 4030, 4020, 4394, 152, 992, 3984, 4168, 4024, 2742, 4148, 4168, 2540, 3986, 4002, 4032, 4110, 4026, 4028, 2852, 2854, 2708, 2742, 4026, 4148, 2708, 4028, 4026, 4394, 4030, 4026, 4020, 4140, 2708, 4026, 2740, 4296, 4140, 4068, 1210, 4140, 4030, 4026, 4020, 1218, 3258, 3260, 4082, 4090, 4092, 4392, 4140, 2534, 4140, 2708, 4028, 2752, 4026, 4032, 2740, 4392, 2708, 4026, 4030, 4020, 4140, 3256, 2492, 3984, 4140, 4168, 2540, 4140, 2742, 4148, 3986, 4004, 4032, 2852, 4110, 2854, 4028, 4026, 4028, 4028, 4026, 2938, 2742, 4002, 4032, 4110, 2852, 2854, 4148, 2708, 4026, 2752, 2930, 4028, 2910, 4026, 4392, 4140, 4152, 4030, 4020, 4168, 4156, 1102, 1102, 1102, 1002, 1002, 3984, 1052, 1052, 390, 4070, 4408, 4410, 4412, 4406, 4068, 4394, 4396, 4394, 3256, 3632, 4120, 3620, 4068, 2708, 3632, 4120, 3632, 4068, 2708, 4056, 4032, 2708, 4026, 2740, 4030, 4018, 4026, 2852, 2854, 4120, 2852, 2854, 2886, 4120, 3632, 2858, 2658, 2688, 3254, 4180, 3254, 3254, 2970, 4082, 4090, 4092, 4084, 4094, 4090, 3234, 2974, 4100, 4100, 4100, 2744, 4148, 4026, 2852, 2854, 4124, 2896, 2858, 2658, 2688, 2684, 3254, 4180, 3254, 3254, 3254, 4180, 4068, 2742, 4148, 4026, 4120, 3632, 2686, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 4120, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956]\",\n          \"[2744, 4026, 2708, 4026, 4020, 4168, 4140, 3986, 4002, 4032, 2852, 4028, 4110, 2854, 4026, 2158, 4016, 4020, 4026, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 4066, 2744, 4026, 2708, 4020, 4026, 4124, 2858, 2658, 3620, 2688, 3634, 2852, 2854, 3254, 3254, 3254, 2970, 4082, 4090, 4092, 4084, 4090, 4094, 4090, 3236, 2974, 4100, 4124, 2686, 4124, 2956, 2956, 2682, 2686, 2708, 4394, 1566, 1570, 4322, 194, 4396, 4026, 4016, 4026, 4020, 4068, 4066, 4066, 4066, 4066, 4066, 4066, 4066, 4066, 4068, 4068, 4066, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4016, 4068, 4068, 2744, 4026, 2708, 4026, 4020, 4394, 4148, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 4016, 4026, 4020, 4114, 4168, 4140, 3986, 4114, 4004, 4028, 4032, 2852, 4026, 4110, 2854, 2744, 4148, 2708, 4026, 4396, 4030, 4020, 4140, 4162, 4150, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 2896, 3008, 4124, 2858, 2658, 2688, 4068, 2852, 2854, 3254, 3254, 3254, 4072, 4016, 4026, 4026, 4020, 4082, 4092, 4094, 1566, 1570, 4394, 4396, 2744, 4026, 2708, 4020, 4026, 4066, 4148, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4394, 952, 958, 962, 4124, 2708, 2744, 4148, 4124, 2950, 2958, 4124, 2956, 2956, 2956, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 4016, 4026, 4020, 952, 4068, 4068, 3658, 4068, 3658, 4066, 3658, 4068, 3658, 4068, 3658]\",\n          \"[3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4408, 2956, 4168, 2956, 2956, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4412, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 4068, 2708, 2744, 4026, 3636, 3658, 4124, 2956, 2956, 4168, 2956, 4140, 4140, 2956, 4140, 4158, 2956, 4140, 4140, 4162, 4160, 4168, 4166, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 4396, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2742, 4026, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 2956, 4168, 2956, 2956, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3984, 4068, 3636, 3658, 2684, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 4396, 3224, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4168, 2956, 4166, 2956, 2956, 2956, 4068, 3636, 3658, 3984, 2708, 2744, 4158, 4026, 4068, 3636, 3658, 4124, 2956, 2956, 4168, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 2956, 4168, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 3236, 3236, 2742, 4026, 3234, 3984, 3636, 3658, 2744, 4026, 4158, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4140, 2708, 3986, 4002, 2852, 4110, 2854, 4026, 2492, 2494, 4102, 4106, 2498, 3986, 2744, 4004, 2852, 4110, 2854, 2708, 4026, 4158, 4140, 4162, 4160, 4168, 2584, 2556, 2740, 4168, 4166, 4414, 4416, 4418, 4420, 4406, 4410, 4408, 4412, 4066, 4068, 2684, 3620, 2684, 2684, 4168, 4140, 3634, 2742, 4004, 4396, 1266, 2852, 4110, 2854, 4158, 2708, 4026, 4026, 4030, 4018, 4140, 4162, 4160, 4168, 2584, 2556, 4168, 4168, 4166, 4406, 4410, 4408, 4412, 3254, 3254, 2970, 3234, 4082, 4090, 4092, 4084, 4090, 4094, 3234, 3144, 2974, 4100, 3242, 3244, 3632, 4120, 2708, 3640, 3648, 2744, 4026, 4158, 3254, 4180, 4066, 4068, 3248, 3246, 2684, 3620, 2742, 4026, 4158, 4168, 4140, 3986, 4002, 2852, 4110, 2854, 4026, 2708, 2742, 4158, 4030, 4018, 4140, 4162, 4160, 4168, 4166, 3800, 3808, 4066, 4068, 2852, 2854, 4120, 2858, 2658, 2688, 3620, 3254, 3254, 2886, 3254, 4180, 2744, 4026, 4158, 2852, 2854, 4124, 2858, 2658, 2688, 3254, 3254, 3254, 4180, 2970, 4082, 4090, 4092, 4094, 4084, 4090, 3236, 2974, 4100, 4124, 2956, 2708, 2742, 4026, 4158, 4120, 2956, 2708, 4066, 2742, 4158, 4120, 3620, 3632, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2708, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 4168, 4168, 2956, 2956, 2956, 4166, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2686, 3636, 3658, 4120, 4120, 2956, 2956, 2956, 2956]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          \"[-14390, -14361, -14360, -14208, -14206, -14206, -14124, -14123, -14123, -13490, -13490, -13488, -13487, -13487, -13486, -13462, -13460, -13452, -13223, -13223, -13223, -13149, -13149, -13149, -13147, -13147, -13147, -13145, -13120, -13119, -12993, -12964, -12929, -12852, -12850, -12850, -12849, -12726, -12155, -12155, -12153, -12153, -12152, -12152, -12151, -12134, -4037, -4037, -4036, -4036, -4035, -4035, -4033, -4008, -3997, -3983, -3982, -3968, -3968, -3967, -3940, -3919, -3911, -3909, -3902, -3855, -3844, -3815, -3799, -2841, -2841, -2840, -2839, -2839, -2839, -2837, -2823, -2822, -2812, -2811, -2801, -2800, -2800, -2778, -2775, -2727, -2715, -2700, -2691, -2691, -2672, -2643, -2617, -2617, -2617, -2617, -2616, -2616, -2615, -2612, -2612, -2612, -2028, -2028, -2028, -2027, -2026, -2026, -2024, -2023, -2023, -2006, -1989, -1921, -1915, -1914, -1903, -1903, -1903, -1903, -1903, -1903, -1330, -1330, -1329, -1328, -1328, -1327, -1327, -1326, -1303, -1301, -1299, -1284, -1281, -1256, -1232, -1232, -1209, -1209, -1209, -1209, -1204, -1131, -1131, -570, -540, -539, -533, -515, -372, -304, -87, -76, -70, -70, -69, -65, -65, -60, -55, -54, 17, 19, 29, 37, 95, 104, 191, 191, 255, 318, 322, 322, 384, 385, 398, 398, 399, 434, 435, 459, 556, 557, 633, 822, 823, -14398, -14363, -14363, -14363, -14361, -14361, -14361, -14361, -14359, -14348, -14223, -14223, -14223, -14125, -14101, -14066, -14064, -14064, -14063, -13873, -13491, -13491, -13491, -13490, -13489, -13489, -13487, -13462, -13461, -13351, -13351, -13350, -13225, -13195, -13191, -13191, -13191, -13152, -13150, -13123, -13122, -13001, -12966, -12966, -12965, -12964, -12964, -12964, -12962, -12931, -12841, -12841, -12777, -12776, -12776, -12772, -12771, -12770, -12769, -12156, -12156, -12156, -12155, -12154, -12154, -12152, -12135, -12134, -12131, -12126, -12092, -12005, -12005, -11986, -11985, -11984, -4039, -4039, -4038, -4037, -4037, -4037, -4035, -4034, -4014, -4010, -4008, -3984, -3984, -3984, -3983, -3978, -3972, -3970, -3969, -3969, -3942, -3935, -3934, -3921, -3918, -3913, -3910, -3903, -3902, -3902, -3900, -3899, -3892, -3888, -3861, -3828, -3820, -3816, -3807, -3801, -3801, -3801, -3795, -3795, -3790, -3782, -3781, -3769, -3769, -3735, -3568, -3544, -3330, -3170, -3170, -3168, -3167, -3154, -2843, -2843, -2842, -2841, -2841, -2840, -2838, -2824, -2824, -2824, -2824, -2813, -2813, -2812, -2805, -2804, -2802, -2801, -2780, -2777, -2777, -2750, -2745, -2729, -2717, -2709, -2702, -2694, -2693, -2692, -2690, -2689, -2689, -2689, -2689, -2689, -2689, -2674, -2667, -2645, -2619, -2619, -2617, -2617, -2617, -2614, -2605, -2599, -2599, -2599, -2598, -2594, -2574, -2547, -2540, -2533, -2501, -2500, -2500, -2496, -2496, -2473, -2037, -2037, -2034, -2034, -2033, -2029, -2028, -2007, -1922, -1916, -1792, -1360, -1360, -1360, -1359, -1357, -1356, -1355, -1354, -1354, -1344, -1334, -1330, -1329, -1329, -1323, -1305, -1304, -1301, -1300, -1286, -1283, -1280, -1279, -1278, -1274, -1271, -1258, -1254, -1253, -1252, -1252, -1211, -1211, -1211, -1210, -1209, -1204, -1203, -1130, -569, -395, -392, -390, -374, -368, -336, -333, -330, -305, -300, -72, -71, -67, -67, -62, -62, -61, -61, -48, -46, -20, 11, 12, 12, 14, 18, 79, 80, 80, 86, 86, 116, 117, 128, 157, 157, 157, 186, 186, 187, 239, 333, 334, 335, 337, 418, 418, 419, 462, 463, 464, 466, 523, 524, 524, 525, 530, 530, 561, 562, 566, 566, 681, 873, 873, 874, 1075, 1078, 1203, 1204, 1296, 1298, 1301, 1360, 1388, 1391, 1414, 1417, 1453, 1506, 1537, 1696, 1856, 1876, 1876, 1975, 1979, 2007, 2010, 2013, 2029, 2035, 2037, 2043, 2066, 2072, 2076, 2097, 2102, 2105, 2121, 2126, 2151, 2179, 2179, 2220, 2224, 2246, 2250, 2265, 2269, 2288, 2292, 2297, 2311, 2315, 2367, 2381, 2394, 2544, 2544, 2601, 2618, 2650, 2653, 2679, 2681, 2686, 2719, 2726, 2741, 2747, 2795, 2799, 2803, 2814, 2826, 2840, 2857, 2866, 2870, 2883, 2884, 2887, 2897, 2916, 2925, 2927, 2933, 2968, 2992, 2997, 3001, 3019, 3036, 3036, 3081, 3124, 3159, 3310, 3310, 3378, 3425, 3453, 3456, 3473, 3497, 3528, 3550, 3555, 3566, 3583, 3595]\",\n          \"[-12761, -12761, -12759, -12759, -12758, -12745, -12740, -12721, -12501, -12501, -12498, -12498, -12498, -12497, -12497, -12476, -12424, -12403, -12403, -12395, -12387, -12379, -12376, -12364, -12362, -12352, -12350, -12243, -11946, -11946, -11944, -11944, -11944, -11920, -11854, -11853, -11853, -11852, -11850, -11839, -11838, -11828, -11827, -11821, -11767, -11737, -11737, -11737, -11708, -11708, -11708, -11680, -11636, -11520, -11515, -11483, -11380, -11240, -11210, -11156, -11104, -11103, -11096, -8991, -8991, -8991, -8960, -8960, -8862, -5827, -5826, -5826, -5825, -5804, -4472, -4223, -4027, -3794, -3582, -3386, -3185, -2998, -2699, -2444, -2040, -1786, -1325, -1126, -917, -753, -566, -267, -84, 114, 1011, 1551, 1680, 1680, 1682, 1682, 1683, 1691, 1732, 1762, 1762, 2177, 2296, 2323, 2351, 2406, 2413, 2441, 2449, 2458, 2468, 2480, 2510, 2532, 2532, 2584, 2597, 2632, 2636, 2667, 2683, 2692, 2714, 2747, 2780, 2791, 2814, 2850, 2851, 2882, 2890, 2914, 2939, 2955, 2993, 3002, 3051, 3060, 3075, 3139, 3144, 3165, 3184, 3209, 3230, 3236, 3261, 3262, 3272, 3273, 3301, 3314, 3329, 3334, 3349, 3405, 3423, 3460, 3489, 3505, 3536, 3568, 3579, -12760, -12759, -12758, -12745, -12745, -12740, -12721, -12721, -12498, -12498, -12498, -12496, -12496, -12496, -12494, -12425, -12425, -12424, -12424, -12422, -12404, -12402, -12394, -12391, -12389, -12385, -12378, -12375, -12363, -12362, -12351, -12351, -12324, -12315, -12308, -12246, -12245, -12245, -12242, -12232, -12230, -12222, -12221, -12211, -12188, -11945, -11945, -11943, -11942, -11680, -11680, -11671, -8992, -8992, -8991, -8908, -5827, -5826, -5825, -5825, -5825, -5803, -5118, -4778, -4778, -4756, -4671, -4656, -4653, -4642, -4620, -4615, -4611, -4601, -4598, -4577, -4572, -4559, -4558, -4545, -4514, -4509, -4496, -4471, -4422, -4422, -4390, -4371, -4345, -4317, -4315, -4305, -4282, -4271, -4261, -4223, -4208, -4208, -4111, -4109, -4070, -4057, -4026, -3996, -3996, -3959, -3940, -3890, -3879, -3859, -3849, -3838, -3826, -3793, -3751, -3751, -3734, -3693, -3678, -3661, -3650, -3630, -3620, -3600, -3581, -3564, -3564, -3546, -3508, -3497, -3482, -3470, -3459, -3448, -3442, -3422, -3395, -3385, -3342, -3342, -3287, -3257, -3248, -3237, -3211, -3202, -3184, -3159, -3159, -3143, -3109, -3095, -3047, -3043, -3036, -3031, -3004, -2997, -2971, -2971, -2950, -2909, -2902, -2891, -2888, -2855, -2838, -2834, -2831, -2827, -2821, -2743, -2739, -2736, -2698, -2675, -2675, -2643, -2626, -2620, -2590, -2583, -2575, -2567, -2558, -2538, -2534, -2527, -2511, -2487, -2484, -2449, -2443, -2261, -2261, -2233, -2208, -2159, -2154, -2137, -2135, -2133, -2117, -2113, -2094, -2091, -2088, -2075, -2071, -2039, -2022, -2022, -1958, -1953, -1935, -1931, -1921, -1917, -1903, -1899, -1896, -1883, -1879, -1855, -1851, -1848, -1822, -1820, -1785, -1601, -1601, -1577, -1538, -1484, -1481, -1459, -1457, -1433, -1432, -1421, -1418, -1394, -1391, -1380, -1352, -1350, -1325, -1301, -1301, -1233, -1169, -1163, -1157, -1145, -1125, -1107, -1107, -1010, -1008, -974, -964, -942, -916, -899, -899, -873, -850, -817, -806, -787, -752, -731, -731, -687, -669, -642, -636, -635, -625, -624, -602, -597, -580, -565, -460, -460, -418, -404, -349, -342, -339, -333, -295, -291, -266, -252, -252, -217, -176, -166, -151, -140, -139, -115, -83, -40, -40, -36, -36, -32, -32, -16, 108, 113, 113, 229, 289, 409, 487, 515, 588, 633, 682, 739, 837, 848, 942, 966, 1011, 1025, 1025, 1070, 1089, 1090, 1112, 1137, 1159, 1251, 1273, 1375, 1397, 1422, 1517, 1552, 1560, 1682, 1683, 1684, 2071, 2511, 2748, 2780, 2940, 2956, 3166, 3185, 3335, 3350, 3490, 3506]\",\n          \"[-14136, -14136, -14099, -14033, -14030, -14026, -13970, -13968, -13942, -13935, -13917, -13916, -13898, -13876, -13864, -13864, -13814, -13804, -13792, -13761, -13744, -13730, -13730, -13692, -13673, -13664, -13650, -13640, -13617, -13613, -13606, -13595, -13595, -13594, -13592, -13592, -13571, -13547, -13540, -13513, -13487, -13485, -13442, -13422, -13398, -13387, -13384, -13383, -13341, -13324, -13324, -13278, -13277, -13265, -13237, -13225, -13223, -13190, -13185, -13165, -13143, -13138, -13134, -13126, -13072, -13070, -13053, -13049, -13033, -13033, -12986, -12981, -12979, -12978, -12949, -12938, -12905, -12904, -12898, -12891, -12870, -12844, -12827, -12792, -12777, -12753, -12746, -12745, -12731, -12723, -12697, -12683, -12652, -12634, -12607, -12593, -12569, -12567, -12556, -12528, -12474, -12461, -12461, -12408, -12397, -12395, -12393, -12371, -12369, -12361, -12348, -12314, -12308, -12305, -12300, -12289, -12276, -12264, -12263, -12261, -12254, -12249, -12239, -12231, -12204, -12202, -12199, -12180, -12161, -12054, -12028, -12020, -11788, -11788, -9573, -9573, -9547, -9407, -9396, -9387, -9382, -9377, -9356, -9352, -9352, -9352, -9351, -9351, -9349, -9348, -9346, -9341, -9339, -9331, -9328, -9325, -9316, -9299, -9287, -9278, -9273, -9271, -9265, -9234, -9222, -9215, -9214, -9212, -9189, -9188, -9174, -9141, -9124, -9124, -9061, -9034, -9033, -8993, -8976, -8944, -8924, -8890, -8875, -8848, -8841, -8840, -8826, -8818, -8793, -8784, -8747, -8730, -8703, -8676, -8670, -8637, -8630, -8628, -8604, -8603, -8591, -8584, -8561, -8544, -8544, -8507, -8505, -8503, -8450, -8445, -8441, -8418, -8397, -8390, -8350, -8337, -8304, -8293, -8290, -8289, -8258, -8240, -8240, -8188, -8176, -8169, -8156, -8139, -8138, -8101, -8100, -8079, -8058, -8053, -8036, -8026, -8018, -8004, -8002, -7998, -7976, -7968, -7966, -7954, -7944, -7923, -7886, -7839, -7839, -7796, -7790, -7752, -7750, -7733, -7721, -7703, -7703, -7689, -7676, -7676, -7628, -7609, -7607, -7584, -7562, -7559, -7506, -7503, -7502, -7497, -7450, -7439, -7151, -7150, -6913, -6913, -6882, -6836, -6834, -6830, -6773, -6771, -6770, -6746, -6740, -6724, -6722, -6705, -6683, -6658, -6658, -6613, -6605, -6594, -6592, -6564, -6546, -6536, -6536, -6484, -6464, -6455, -6442, -6434, -6414, -6411, -6395, -6394, -6393, -6392, -6391, -6374, -6354, -6349, -6326, -6304, -6303, -6269, -6254, -6233, -6222, -6220, -6219, -6171, -6171, -6162, -6162, -6122, -6121, -6090, -6089, -6076, -6048, -6037, -6035, -6001, -5994, -5975, -5960, -5960, -5953, -5953, -5951, -5947, -5942, -5935, -5883, -5880, -5879, -5859, -5855, -5837, -5837, -5822, -5787, -5783, -5781, -5755, -5745, -5713, -5712, -5705, -5699, -5678, -5653, -5638, -5606, -5594, -5571, -5564, -5563, -5550, -5542, -5517, -5503, -5471, -5452, -5424, -5410, -5383, -5374, -5349, -5298, -5284, -5284, -5238, -5228, -5226, -5225, -5203, -5202, -5194, -5182, -5149, -5142, -5140, -5134, -5123, -5111, -5099, -5098, -5096, -5089, -5084, -5067, -5065, -5041, -5039, -5038, -5022, -5004, -4892, -4862, -4844, -4844, -4808, -4770, -3697, -3697, -3696, -3695, -2330, -2330, -2318, -2177, -2166, -2156, -2152, -2135, -2132, -2122, -2120, -2101, -2096, -2088, -2073, -2062, -2053, -2048, -2046, -2041, -2010, -2000, -1993, -1991, -1973, -1971, -1959, -1930, -1902, -1902, -1890, -1847, -1824, -1822, -1790, -1777, -1750, -1732, -1701, -1687, -1663, -1657, -1656, -1644, -1636, -1614, -1605, -1571, -1554, -1528, -1501, -1494, -1458, -1450, -1448, -1424, -1423, -1413, -1405, -1382, -1350, -1350, -1326, -1306, -1305, -1303, -1254, -1249, -1245, -1225, -1207, -1201, -1166, -1155, -1128, -1117, -1115, -1114, -1082, -1041, -1041, -1024, -989, -977, -957, -943, -941, -911, -909, -889, -867, -862, -844, -832, -825, -811, -808, -805, -782, -773, -771, -759, -748, -724, -680, -638, -638, -617, -601, -597, -569, -568, -554, -544, -508, -486, -486, -469, -452, -435, -417, -397, -395, -392, -336, -332, -331, -306, -274, -263, -256, -250, -102, -102, -60, 70, 681, 681, 1184, 1184, 1198, 1223, 1244, 1246, 1256, 1368, 1398, 1402, 1443, 1453, 1463, 1482, 1728, 1730, 1730, 1732, 1734, 2026, 2326, 2342, 2342, 2626, 2636, 2681, 2681, 2683, 2683, 2685, 2686, 2686, 2686, 2708, 2712, 2714, 2724, 2726, 2727, 2739, 2754, 2757, 2767, 2767, 2767, 2767, 2777, 2782, 2786, 2789, 2799, 2799, 3344, 3344, 3349, 3377, 3522, 3530, 3540, -13301, -13301, -13300, -13300, -13299, -13299, -13297, -13296, -13295, -13295, -13268, -13268, -13267, -13266, -13263, -13260, -13257, -13255, -13253, -13250, -13244, -13241, -13128, -13128, -13127, -13127, -12741, -12740, -12728, -12711, -12620, -12620, -12620, -12591, -12591, -12591, -12496, -12454, -12349, -12310, -12257, -12238, -12223, -12216, -12205, -12132, -12132, -12020, -12020, -12020, -11995, -11995, -11978, -11978, -11874, -11855, -11848, -11848, -10096, -10096, -10096, -10088, -10079, -10056, -9907, -9905, -9905, -9903, -9902, -9869, -9869, -9869, -9855, -9854, -9852, -9849, -9846, -9834, -9832, -9820, -9820, -9797, -9796, -9756, -9755, -9754, -9685, -9680, -9680, -9680, -9598, -9597, -9596, -9587, -9587, -9380, -9380, -9380, -9259, -9257, -9257, -9192, -9191, -9191, -9107, -9106, -9093, -9093, -9044, -9012, -9012, -9012, -8984, -8983, -8983, -8897, -8795, -8791, -8463, -8342, -8273, -8198, -8198, -8198, -8135, -8067, -7990, -7987, 1675, 1675, 1724, 1727, 1731, 1736, 1754, 1756, 1763, 1792, 1872, 1875, 1912, 2137, 2451, 2451, 2480, 2524, 2568, 2571, 2577, 2629, 2631, 2632, 2653, 2656, 2669, 2670, 2684, 2706, 2731, 2731, 2743, 2773, 2782, 2793, 2821, 2839, 2846, 2846, 2862, 2891, 2911, 2920, 2933, 2942, 2962, 2962, 2982, 2983, 2984, 2985, 2985, 3005, 3026, 3032, 3055, 3076, 3077, 3110, 3123, 3140, 3147, 3149, 3187, 3203, 3203, 3215, 3246, 3247, 3259, 3285, 3296, 3298, 3330, 3336, 3355, 3376, 3380, 3385, 3392, 3441, 3443, 3445, 3457, 3460, 3461, 3469, 3469, 3486, 3539, 3563, 3568, 3570, 3594]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0900724002141375,\n        \"min\": 0.0,\n        \"max\": 51.46560101831832,\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          50.82002199835255,\n          50.81355016698292,\n          49.73857405933413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6400198534186312,\n        \"min\": 0.0,\n        \"max\": 6.028507315864528,\n        \"num_unique_values\": 1011,\n        \"samples\": [\n          4.319675224876442,\n          4.4253961085389,\n          5.650003868846611\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1004,\n        \"samples\": [\n          \"[0.0, 0.0, 0.0, 0.0, 28.5, 28.3, 30.9, 10.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.9, 6.9, 0.0, 0.0, 0.0, 0.0, 16.7, 36.6, 67.8, 78.8, 92.4, 112.5, 112.0, 114.8, 118.0, 113.8, 114.6, 115.2, 118.2, 121.0, 124.7, 124.8, 124.5, 126.5, 127.1, 122.5, 122.2, 122.3, 122.7, 123.0, 123.8, 124.4, 122.7, 122.3, 122.8, 123.4, 124.8, 126.1, 125.5, 125.2, 121.9, 116.3, 115.5, 115.6, 114.8, 114.8, 112.5, 102.5, 95.8, 67.1, 37.0, 36.1, 35.5, 34.8, 33.7, 69.8, 73.3, 80.1, 80.8, 80.9, 72.9, 49.0, 34.9, 0.0, 0.0, 0.0, 41.9, 56.7, 96.9, 99.4, 108.0, 117.0, 113.9, 113.3, 113.8, 112.1, 113.5, 114.1, 88.7, 82.7, 86.5, 79.4, 74.5, 33.2, 30.8, 36.7, 36.0, 25.7, 25.2, 36.6, 82.5, 94.7, 97.0, 79.7, 76.1, 32.9, 47.8, 25.3, 38.4, 87.8, 80.8, 80.7, 75.0, 65.9, 64.6, 65.8, 61.8, 41.0, 36.6, 0.0, 0.0, 0.0, 41.8, 46.4, 56.6, 49.4, 42.0, 35.4, 33.8, 32.6, 32.7, 50.1, 49.8, 34.2, 19.9, 15.5, 0.0, 0.0, 0.0, 39.4, 52.7, 53.1, 64.2, 73.0, 76.6, 76.7, 82.8, 99.5, 105.7, 111.0, 115.1, 114.1, 114.0, 117.6, 117.1, 115.9, 115.6, 116.0, 110.1, 83.7, 84.0, 85.8, 85.1, 83.6, 84.6, 85.9, 85.0, 85.8, 87.1, 86.2, 90.5, 102.5, 107.5, 114.8, 117.0, 114.7, 114.1, 116.7, 115.8, 115.1, 114.2, 64.7, 57.4, 0.0, 0.0, 0.0, 16.7, 32.8, 85.1, 91.3, 95.8, 95.3, 94.7, 93.6, 96.8, 95.8, 95.4, 94.8, 94.3, 91.7, 91.3, 93.6, 93.3, 93.9, 95.2, 94.3, 94.4, 94.7, 96.7, 96.8, 95.8, 95.6, 95.8, 96.3, 97.0, 96.6, 90.0, 77.3, 77.8, 77.3, 76.4, 76.5, 75.9, 74.9, 75.4, 75.6, 75.4, 75.6, 72.7, 72.5, 64.7, 63.7, 62.9, 62.7, 62.0, 60.4, 47.6, 42.2, 34.9, 16.3, 38.8, 10.0, 20.7, 45.2, 34.9, 7.0, 15.0, 26.0, 24.8, 22.8, 0.0, 0.0, 0.0, 0.0, 22.5, 24.8, 25.6, 37.9, 39.2, 69.3, 75.5, 80.7, 83.6, 95.5, 108.7, 111.8, 112.8, 113.3, 113.6, 113.3, 113.4, 113.4, 113.5, 113.6, 114.1, 114.5, 113.9, 115.4, 116.2, 117.5, 117.1, 115.7, 115.1, 115.2, 115.7, 116.0, 115.4, 115.0, 115.2, 115.5, 114.1, 114.1, 114.1, 114.2, 115.3, 114.0, 113.7, 113.9, 113.6, 114.4, 115.6, 114.0, 114.3, 115.7, 113.4, 113.1, 115.1, 114.1, 114.0, 113.4, 108.7, 106.9, 100.8, 89.4, 84.2, 83.9, 54.0, 0.0, 0.0, 0.0, 60.3, 71.4, 84.2, 105.0, 115.2, 115.8, 117.7, 117.3, 115.6, 114.2, 113.7, 114.6, 116.5, 115.5, 114.7, 116.5, 116.8, 91.7, 86.8, 86.5, 86.2, 82.1, 82.1, 80.2, 80.1, 47.5, 42.0, 39.7, 0.0, 0.0, 0.0, 0.0, 0.0, 47.5, 50.4, 74.0, 77.2, 96.8, 98.8, 108.6, 115.6, 116.9, 114.2, 115.5, 116.8, 117.5, 117.9, 116.0, 115.5, 115.7, 115.1, 115.0, 114.2, 114.3, 114.2, 114.1, 115.1, 115.9, 116.8, 118.1, 117.8, 117.5, 116.9, 117.0, 117.0, 117.0, 116.3, 116.1, 116.0, 116.0, 115.8, 116.5, 118.1, 117.6, 117.1, 114.4, 114.6, 117.9, 118.2, 118.1, 116.7, 115.2, 93.1, 92.8, 91.5, 88.2, 87.3, 45.3, 36.7, 32.5, 33.0, 0.0, 0.0, 0.0, 27.2, 32.9, 40.2, 43.4, 61.3, 70.1, 71.7, 83.3, 83.2, 83.0, 80.8, 86.7, 89.1, 99.2, 106.3, 110.6, 112.9, 116.5, 117.2, 118.2, 117.8, 118.6, 118.4, 116.4, 116.5, 115.6, 115.1, 112.4, 112.0, 109.2, 108.0, 108.0, 106.9, 106.2, 102.2, 94.8, 93.4, 88.5, 79.4, 76.3, 70.5, 58.2, 54.7, 46.1, 44.1, 42.0, 42.2, 39.0, 37.3, 33.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\",\n          \"[67.2, 62.3, 52.8, 51.2, 38.3, 38.7, 26.4, 18.6, 13.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.5, 13.9, 36.5, 43.9, 78.3, 77.9, 76.2, 75.9, 73.2, 72.2, 73.4, 79.0, 79.9, 79.6, 71.5, 0.0, 0.0, 0.0, 0.0, 35.2, 38.4, 41.2, 41.3, 43.9, 45.8, 46.1, 46.0, 46.1, 44.8, 40.0, 38.6, 28.0, 26.6, 21.3, 33.5, 42.5, 44.4, 45.1, 83.8, 90.3, 101.1, 104.3, 112.3, 115.3, 119.5, 119.6, 114.6, 112.4, 110.0, 68.1, 44.3, 40.9, 35.3, 34.6, 26.7, 26.5, 26.3, 25.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 20.4, 23.2, 28.9, 28.6, 28.4, 37.4, 52.1, 98.4, 104.2, 104.3, 105.2, 96.0, 81.0, 52.5, 51.5, 49.8, 47.8, 39.6, 39.3, 41.4, 46.2, 47.1, 48.3, 48.9, 46.7, 48.3, 44.5, 48.3, 48.5, 40.7, 40.3, 40.8, 43.4, 49.4, 42.0, 44.0, 45.0, 45.3, 41.6, 0.1, 0.0, 0.0, 0.0, 0.0, 73.5, 85.4, 86.3, 84.9, 68.6, 63.5, 60.7, 54.8, 53.5, 41.6, 40.1, 27.8, 19.0, 13.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 18.9, 26.3, 31.2, 53.5, 55.0, 67.0, 70.3, 75.9, 83.6, 82.6, 81.6, 74.4, 0.2, 0.0, 0.0, 0.0, 0.0, 30.6, 42.3, 47.2, 47.1, 47.8, 47.9, 48.1, 48.0, 48.0, 48.3, 46.5, 45.3, 37.4, 36.4, 31.2, 47.4, 42.2, 40.8, 44.4, 82.9, 89.7, 100.5, 103.7, 111.8, 115.0, 120.5, 119.3, 118.0, 118.4, 117.2, 68.9, 38.4, 34.5, 30.5, 30.5, 26.7, 26.6, 26.3, 23.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 26.9, 29.2, 37.1, 37.3, 37.5, 66.1, 79.7, 116.7, 120.4, 120.5, 121.2, 119.5, 100.5, 63.5, 53.2, 50.1, 35.2, 36.1, 55.1, 46.4, 45.7, 45.0, 47.3, 46.2, 47.9, 47.3, 48.2, 47.9, 41.3, 20.7, 13.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 23.2, 27.8, 27.9, 29.9, 30.8, 30.8, 41.7, 44.4, 41.8, 41.8, 41.8, 43.2, 43.8, 45.0, 39.4, 42.0, 40.8, 42.2, 45.8, 46.1, 42.0, 40.4, 39.2, 38.5, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.9, 7.8, 7.9, 9.7, 10.4, 9.4, 10.3, 10.3, 10.6, 10.8, 10.8, 11.5, 11.5, 11.5, 11.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.1, 9.2, 11.3, 5.1, 7.4, 12.0, 12.6, 10.6, 9.6, 9.3, 8.8, 10.6, 10.7, 12.0, 10.2, 8.5, 8.0, 6.4, 6.4, 5.3, 0.0, 0.0, 0.0, 0.0]\",\n          \"[0.0, 0.0, 0.0, 21.3, 22.1, 24.4, 37.7, 38.2, 42.5, 49.0, 64.2, 63.8, 49.6, 1.1, 0.0, 0.0, 71.4, 88.9, 87.0, 34.8, 2.0, 0.0, 0.0, 71.0, 109.6, 119.1, 117.4, 115.3, 134.1, 138.9, 136.8, 131.6, 131.6, 130.5, 129.9, 130.2, 123.1, 113.0, 115.5, 122.2, 124.3, 124.1, 111.3, 106.4, 89.5, 73.5, 69.2, 68.3, 1.9, 0.0, 0.0, 70.7, 74.1, 101.3, 131.0, 145.9, 148.4, 155.9, 156.0, 146.2, 118.0, 113.5, 110.1, 102.5, 49.4, 41.7, 7.9, 0.9, 0.0, 0.0, 61.0, 66.2, 67.6, 69.1, 97.9, 111.0, 114.2, 114.2, 115.7, 113.4, 121.9, 128.7, 126.3, 113.7, 114.1, 133.7, 132.8, 132.8, 133.6, 137.8, 144.0, 145.2, 143.8, 140.0, 136.5, 131.3, 112.9, 107.0, 100.3, 75.2, 0.0, 0.0, 0.0, 66.2, 84.3, 87.0, 89.0, 111.9, 112.8, 118.2, 123.8, 131.6, 132.7, 131.4, 129.2, 129.0, 139.0, 138.6, 138.5, 139.0, 140.3, 139.9, 133.5, 132.3, 108.0, 105.8, 103.9, 71.9, 39.0, 32.4, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 84.8, 106.9, 123.7, 126.2, 126.4, 120.9, 117.8, 117.7, 118.1, 117.0, 117.0, 116.1, 115.1, 114.5, 112.7, 113.1, 114.8, 116.0, 116.6, 121.2, 134.5, 140.0, 141.6, 143.8, 144.2, 143.8, 135.8, 125.4, 114.0, 112.6, 110.4, 88.7, 87.2, 66.1, 0.0, 0.0, 0.0, 82.0, 98.8, 99.2, 110.8, 108.5, 123.6, 129.6, 134.6, 134.8, 129.1, 129.5, 129.7, 131.9, 129.8, 127.2, 126.7, 123.8, 120.6, 122.8, 118.6, 118.3, 115.3, 116.0, 116.1, 79.1, 76.7, 55.7, 40.1, 0.1, 0.0, 0.0, 29.9, 34.9, 42.2, 117.2, 118.6, 121.9, 138.1, 138.2, 139.7, 129.4, 121.3, 84.8, 73.3, 71.1, 69.7, 0.1, 0.0, 0.0, 86.7, 110.0, 120.4, 126.5, 127.3, 127.2, 148.6, 151.0, 157.5, 157.7, 158.7, 159.1, 158.9, 157.8, 152.8, 151.5, 149.5, 130.6, 125.1, 123.2, 114.1, 102.5, 65.2, 0.0, 0.0, 0.0, 12.1, 22.6, 67.0, 66.5, 60.3, 57.9, 28.8, 28.8, 1.1, 0.0, 0.0, 38.0, 61.6, 61.3, 60.1, 36.5, 36.7, 31.0, 30.0, 29.2, 28.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.2, 23.1, 24.6, 40.2, 40.7, 40.9, 47.4, 55.7, 64.3, 63.5, 54.0, 1.1, 0.0, 0.0, 72.7, 91.7, 96.4, 95.2, 40.3, 1.8, 0.0, 0.0, 67.6, 108.4, 121.8, 131.0, 138.7, 152.7, 155.6, 150.4, 149.7, 149.1, 148.6, 148.2, 141.9, 144.7, 143.4, 144.3, 154.4, 155.0, 142.2, 138.4, 97.5, 79.0, 73.6, 70.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.6, 66.9, 95.3, 139.5, 146.3, 146.6, 154.1, 152.7, 140.2, 125.4, 125.4, 120.7, 120.7, 119.1, 115.4, 111.7, 101.8, 43.5, 36.5, 33.0, 5.4, 0.0, 0.0, 0.0, 0.0, 63.0, 74.6, 78.6, 108.8, 116.1, 114.9, 114.9, 113.9, 114.2, 128.6, 134.1, 132.9, 135.6, 134.8, 131.0, 136.2, 137.3, 138.5, 141.3, 144.2, 144.8, 137.5, 134.7, 132.9, 130.9, 118.0, 113.0, 85.6, 0.0, 0.0, 0.0, 73.9, 91.5, 93.8, 96.0, 116.5, 117.2, 123.2, 131.2, 134.0, 132.6, 130.7, 129.9, 133.4, 136.3, 138.5, 139.3, 141.1, 143.9, 139.7, 141.4, 141.9, 123.6, 121.7, 120.6, 85.1, 37.1, 33.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.1, 108.3, 124.5, 124.9, 123.9, 123.1, 116.1, 115.1, 123.5, 132.9, 143.2, 148.5, 146.6, 146.0, 148.1, 147.9, 147.9, 146.5, 146.6, 144.0, 141.4, 100.7, 97.9, 73.2, 0.1, 0.0, 0.0, 0.0, 93.3, 116.1, 117.3, 141.7, 139.8, 141.2, 144.9, 147.1, 148.4, 147.6, 148.7, 148.4, 148.4, 142.1, 137.9, 136.8, 132.5, 128.6, 121.7, 115.7, 113.7, 101.1, 102.7, 103.2, 82.4, 80.3, 59.0, 42.7, 0.0, 0.0, 0.0, 0.0, 34.4, 40.7, 48.2, 130.5, 134.9, 140.5, 157.2, 157.7, 157.4, 153.1, 150.9, 95.6, 73.8, 68.6, 66.0, 0.0, 0.0, 0.0, 0.0, 88.7, 111.2, 134.8, 149.4, 150.5, 158.5, 158.8, 156.8, 149.6, 150.0, 153.5, 153.2, 153.0, 151.2, 149.9, 146.4, 122.5, 120.8, 120.6, 107.9, 94.8, 56.5, 0.0, 0.0, 0.0, 0.0, 19.4, 32.7, 78.9, 79.1, 74.0, 61.9, 0.0, 0.0, 0.0, 0.0, 40.1, 83.1, 69.2, 34.5, 33.3, 32.1, 29.0, 27.8, 27.1, 22.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.8, 5.8, 5.6, 12.6, 11.2, 10.9, 5.9, 1.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.4, 0.0, 0.0, 0.0, 0.0, 0.0, 25.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.4, 5.6, 8.9, 13.1, 15.0, 15.2, 0.0, 0.0, 0.0, 0.0, 0.0, 7.2, 15.1, 16.1, 21.8, 42.3, 42.0, 39.8, 73.6, 82.6, 86.8, 86.2, 54.3, 0.1, 0.0, 0.0, 0.0, 73.4, 93.4, 101.4, 40.8, 0.0, 0.0, 0.0, 0.0, 66.2, 107.6, 120.7, 134.9, 137.1, 149.1, 149.1, 142.0, 141.5, 140.6, 139.8, 140.5, 129.5, 137.6, 140.1, 146.5, 153.6, 152.9, 154.1, 153.6, 138.7, 108.7, 102.2, 0.2, 0.0, 0.0, 0.0, 74.9, 78.2, 104.1, 145.8, 156.5, 155.9, 158.4, 157.2, 158.8, 122.8, 114.0, 113.3, 111.3, 48.5, 45.2, 41.8, 13.2, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 66.2, 77.0, 81.0, 115.4]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 2,\n        \"max\": 99,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          6,\n          16,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a6f6f454",
      "metadata": {
        "id": "a6f6f454"
      },
      "outputs": [],
      "source": [
        "class SCNB:\n",
        "    def __init__(self):\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier()\n",
        "        }\n",
        "        self.models = {}\n",
        "        self.embedding_methods = {}\n",
        "        self.ensemble_model = None\n",
        "        self.hmm_model = None\n",
        "\n",
        "    def train_classifiers(self, X, y):\n",
        "        \"\"\"Entrena cada clasificador popular junto con XGBoost.\"\"\"\n",
        "        for name, clf in self.classifiers.items():\n",
        "            clf.fit(X, y)\n",
        "            self.models[name] = clf\n",
        "        print(\"All classifiers trained successfully.\")\n",
        "\n",
        "    def generate_embeddings(self, words_list):\n",
        "        \"\"\"Genera embeddings para una lista de palabras usando distintos encoders.\"\"\"\n",
        "        encoders = {\n",
        "            'CountVectorizer': CountVectorizer(),\n",
        "            'OneHotEncoder': OneHotEncoder(sparse=False),\n",
        "            'TfidfVectorizer': TfidfVectorizer()\n",
        "        }\n",
        "\n",
        "        for name, encoder in encoders.items():\n",
        "            self.embedding_methods[name] = encoder.fit_transform(words_list).toarray()\n",
        "\n",
        "        word2vec_model = Word2Vec(sentences=[words_list], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        self.embedding_methods['Word2Vec'] = [word2vec_model.wv[word] for word in words_list if word in word2vec_model.wv]\n",
        "        print(\"Embeddings generated successfully.\")\n",
        "\n",
        "    def evaluate_models(self, X, y):\n",
        "        \"\"\"Evalúa cada modelo entrenado usando StratifiedKFold y genera una tabla con métricas.\"\"\"\n",
        "        results = []\n",
        "        skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            accuracies, recalls, precisions = [], [], []\n",
        "            for train_index, test_index in skf.split(X, y):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "                accuracies.append(accuracy_score(y_test, y_pred))\n",
        "                recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "                precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "            results.append({\n",
        "                'Model': name,\n",
        "                'Accuracy Mean': np.mean(accuracies),\n",
        "                'Accuracy Std': np.std(accuracies),\n",
        "                'Accuracy Median': np.median(accuracies),\n",
        "                'Recall Mean': np.mean(recalls),\n",
        "                'Recall Std': np.std(recalls),\n",
        "                'Recall Median': np.median(recalls),\n",
        "                'Precision Mean': np.mean(precisions),\n",
        "                'Precision Std': np.std(precisions),\n",
        "                'Precision Median': np.median(precisions),\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"Evaluation complete.\")\n",
        "        return results_df\n",
        "\n",
        "    def train_ensemble_model(self, weights=None):\n",
        "        \"\"\"Crea y entrena un modelo de ensamblaje usando los mejores modelos entrenados.\"\"\"\n",
        "        estimators = [(name, model) for name, model in self.models.items()]\n",
        "        self.ensemble_model = VotingClassifier(estimators=estimators, voting='soft', weights=weights)\n",
        "        print(\"Ensemble model created successfully.\")\n",
        "\n",
        "    def train_hidden_markov_model(self, X, n_components=2):\n",
        "        \"\"\"Entrena un modelo Hidden Markov.\"\"\"\n",
        "        self.hmm_model = hmm.GaussianHMM(n_components=n_components)\n",
        "        self.hmm_model.fit(X)\n",
        "        print(\"Hidden Markov Model trained successfully.\")\n",
        "\n",
        "    def analyze_hmm(self):\n",
        "        \"\"\"Analiza el modelo Hidden Markov mostrando matrices de transición y demás estadísticas.\"\"\"\n",
        "        if self.hmm_model:\n",
        "            print(\"Transition matrix:\", self.hmm_model.transmat_)\n",
        "            print(\"Means:\", self.hmm_model.means_)\n",
        "            print(\"Covars:\", self.hmm_model.covars_)\n",
        "        else:\n",
        "            print(\"HMM model not trained yet.\")\n",
        "\n",
        "    def dimensionality_reduction_with_umap(self, X, y, min_dist_values=[0.1, 0.5], n_neighbors_values=[5, 10]):\n",
        "        \"\"\"Aplica reducción de dimensionalidad usando UMAP y muestra scatter plots.\"\"\"\n",
        "        for min_dist in min_dist_values:\n",
        "            for n_neighbors in n_neighbors_values:\n",
        "                umap_model = umap.UMAP(min_dist=min_dist, n_neighbors=n_neighbors)\n",
        "                X_umap = umap_model.fit_transform(X)\n",
        "\n",
        "                scatter_matrix(pd.DataFrame(X_umap), alpha=0.2, figsize=(10, 10), diagonal='kde', c=y)\n",
        "                plt.title(f\"UMAP Clustering (min_dist={min_dist}, n_neighbors={n_neighbors})\")\n",
        "                plt.show()\n",
        "\n",
        "        print(\"Dimensionality reduction with UMAP completed.\")\n",
        "\n",
        "    def clustering_with_algorithms(self, X, y):\n",
        "        \"\"\"Realiza clustering usando algoritmos populares y muestra scatter plots.\"\"\"\n",
        "        clusterers = {\n",
        "            'KMeans': KMeans(n_clusters=len(np.unique(y))),\n",
        "            'Agglomerative': AgglomerativeClustering(n_clusters=len(np.unique(y))),\n",
        "            'DBSCAN': DBSCAN()\n",
        "        }\n",
        "\n",
        "        for name, clusterer in clusterers.items():\n",
        "            clusters = clusterer.fit_predict(X)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            scatter_matrix(pd.DataFrame(X), alpha=0.2, figsize=(10, 10), diagonal='kde', c=clusters)\n",
        "            plt.title(f\"Clustering with {name}\")\n",
        "            plt.show()\n",
        "\n",
        "        print(\"Clustering with various algorithms completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67650822",
      "metadata": {
        "id": "67650822"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "# Supongamos que tienes un DataFrame `df` con variables `X` y `y` definidas.\n",
        "\n",
        "# Crear instancia de SCNB\n",
        "scnb = SCNB()\n",
        "\n",
        "# Entrenar clasificadores\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "scnb.train_classifiers(X, y)\n",
        "\n",
        "# Generar embeddings para una lista de palabras\n",
        "words_list = [\"gato\", \"perro\", \"pez\", \"pájaro\"]\n",
        "scnb.generate_embeddings(words_list)\n",
        "\n",
        "# Evaluar modelos\n",
        "results_df = scnb.evaluate_models(X, y)\n",
        "print(results_df)\n",
        "\n",
        "# Entrenar modelo de ensamblaje\n",
        "scnb.train_ensemble_model()\n",
        "\n",
        "# Entrenar y analizar un modelo HMM\n",
        "scnb.train_hidden_markov_model(X)\n",
        "scnb.analyze_hmm()\n",
        "\n",
        "# Red\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}