{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee",
      "metadata": {
        "id": "922f85b5-bc81-4059-afe8-a86d8ec6d0ee"
      },
      "source": [
        "# Text classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "\n",
        "#from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58",
      "metadata": {
        "id": "6aba5d7c-c622-4044-a1f9-b01a88659d58"
      },
      "source": [
        "Manually remove the first ';' from the first row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "cf3654cd-833c-4499-8ea0-22199d0da097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "548      4458317  [1036, 1036, 1036, 1036, 1036, 1036, 1036, 103...   \n",
              "302      4447815  [520, 520, 520, 520, 520, 520, 520, 520, 520, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "548  [4120, 2956, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "302  [3636, 3658, 2956, 2956, 2956, 2956, 2956, 295...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "548  [-14370, -14345, -14260, -14257, -14234, -1422...   50.455203   \n",
              "302  [-14384, -14384, -14347, -14338, -14314, -1430...   50.844558   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "548    4.827367  [0.0, 15.0, 34.5, 34.4, 56.9, 45.5, 38.0, 36.7...   \n",
              "302    4.408042  [0.0, 0.0, 9.1, 26.0, 36.8, 39.4, 41.7, 41.0, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "548  [False, False, False, False, False, False, Fal...   \n",
              "302  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "548  [True, True, True, True, True, True, True, Tru...             13  \n",
              "302  [True, True, True, True, True, True, True, Tru...              2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-558d6dfb-5f59-4cb1-8eb8-d89d242bab62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>4458317</td>\n",
              "      <td>[1036, 1036, 1036, 1036, 1036, 1036, 1036, 103...</td>\n",
              "      <td>[4120, 2956, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14370, -14345, -14260, -14257, -14234, -1422...</td>\n",
              "      <td>50.455203</td>\n",
              "      <td>4.827367</td>\n",
              "      <td>[0.0, 15.0, 34.5, 34.4, 56.9, 45.5, 38.0, 36.7...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>4447815</td>\n",
              "      <td>[520, 520, 520, 520, 520, 520, 520, 520, 520, ...</td>\n",
              "      <td>[3636, 3658, 2956, 2956, 2956, 2956, 2956, 295...</td>\n",
              "      <td>[-14384, -14384, -14347, -14338, -14314, -1430...</td>\n",
              "      <td>50.844558</td>\n",
              "      <td>4.408042</td>\n",
              "      <td>[0.0, 0.0, 9.1, 26.0, 36.8, 39.4, 41.7, 41.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-558d6dfb-5f59-4cb1-8eb8-d89d242bab62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-558d6dfb-5f59-4cb1-8eb8-d89d242bab62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-558d6dfb-5f59-4cb1-8eb8-d89d242bab62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f877dd95-adef-492b-bc48-648b945c7cc3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f877dd95-adef-492b-bc48-648b945c7cc3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f877dd95-adef-492b-bc48-648b945c7cc3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7426,\n        \"min\": 4447815,\n        \"max\": 4458317,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4447815,\n          4458317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062, 1062]\",\n          \"[1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036, 1036]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 4396, 3236, 3636, 3658, 4396, 4396, 4026, 4016, 4020, 4066, 3658, 4068, 3658, 4068, 3658, 4068, 4066, 4068, 4066, 3658, 4068, 3658, 4066, 3658, 4066, 3658, 4068, 3658, 4068, 4066, 3354, 4068, 2744, 4148, 2708, 4026, 4020, 3636, 3658, 4124, 4068, 2708, 4016, 4026, 4026, 4020, 4028, 2708, 2744, 4026, 4148, 2740, 4030, 4020, 4026, 4030, 4026, 3670, 3634, 3634, 4394, 4396, 2972, 3236, 2976, 4100, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 2956, 2956, 2956, 3008, 4066, 3636, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4124, 2956, 2956, 2956, 4394, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4068, 3658, 4066, 3658, 4066, 4066, 4066, 3490, 4396, 3490, 4396, 3490, 4396, 2742, 4026, 4148, 2708, 4020, 4026, 4066, 3490, 4396, 3490, 4396, 3490, 4396, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3490, 3636, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3490, 4396, 4120, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3490, 4396, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4078, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3490, 4396, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4078, 4120, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2940, 2956, 2956, 2956, 2956, 2956, 4120, 2956, 2956, 2956, 3490, 2956, 4396, 2956, 2956, 2956, 4066, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4078, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 3364, 2956, 3354, 2956, 2956, 2956, 2956, 3490, 4396, 2956, 2956, 2956, 4068, 2708, 4026, 4016, 4020, 4068, 2742, 4026, 2708, 4026, 4020, 4148, 2882, 4048, 2736, 4020, 4026, 4028, 3658, 4026, 4016, 4020, 4026, 4068, 3490, 4396, 4066, 4408, 4394, 154, 152, 4066]\",\n          \"[4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4068, 4070, 2708, 2744, 4026, 4148, 4168, 4140, 3986, 2742, 4002, 2852, 4110, 2854, 4148, 2708, 4026, 4030, 4018, 4026, 4140, 4162, 4150, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 2852, 3008, 2854, 4120, 2858, 2658, 2688, 2886, 3254, 3254, 2708, 2742, 4148, 3254, 2958, 2742, 4148, 2942, 2742, 4148, 3254, 2744, 4026, 4148, 2970, 4082, 4092, 4090, 4094, 4084, 4090, 3236, 2974, 4100, 2852, 2854, 4124, 2858, 2658, 2688, 2688, 2684, 3254, 3254, 3254, 2944, 2708, 2744, 4148, 2744, 4148, 3254, 4066, 4068, 2744, 3254]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-14384, -14384, -14347, -14338, -14314, -14309, -14297, -14293, -14276, -14272, -14269, -14253, -14248, -14225, -14222, -14219, -14186, -14183, -14145, -14106, -14106, -14036, -14002, -13977, -13960, -13953, -13937, -13931, -13910, -13897, -13882, -13870, -13864, -13840, -13828, -13795, -13789, -13785, -13762, -13752, -13738, -13731, -13721, -13701, -13698, -13692, -13689, -13659, -13652, -13649, -13643, -13620, -13612, -13595, -13586, -13566, -13565, -13540, -13510, -13501, -13439, -13435, -13433, -13357, -13353, -13335, -13318, -13286, -13270, -13253, -13249, -13221, -13209, -13171, -13151, -13120, -13111, -13085, -13076, -13067, -13045, -13042, -13035, -13027, -13023, -12923, -12921, -12883, -12868, -12864, -12767, -12764, -12735, -12580, -12535, -12526, -12456, -12454, -12439, -12404, -12393, -12392, -12348, -12345, -12317, -12309, -12298, -12290, -12272, -12263, -12259, -12258, -12220, -12179, -12157, -12152, -12140, -12116, -12089, -12081, -12047, -12047, -11981, -11960, -11941, -11930, -11907, -11900, -11860, -11858, -11827, -11818, -11808, -11797, -11783, -11750, -11734, -11725, -11724, -11707, -11697, -11686, -11664, -11662, -11645, -11618, -11608, -11547, -11467, -11467, -11392, -11383, -11335, -11327, -11317, -11313, -11297, -11263, -11260, -11235, -11231, -11137, -11112, -11101, -11077, -11068, -11066, -11060, -10958, -10958, -9974, -9443, -7972, -7971, -7970, -7947, -7049, -6761, -6727, -6225, -6036, -5562, -4995, -4120, -3481, -3438, -3213, -3158, -2659, -2555, -1900, -1863, -1664, -1644, -958, -721, -558, -425, -189, -189, -188, -188, -187, 374, 374, 462, 571, 580, 703, 703, 704, 705, 753, 915, 915, 915, 915, 920, 923, 926, 926, 926, 927, 939, 1011, 1058, 1091, 1098, 1105, 1142, 1292, 1295, 1333, 1370, 1407, 1411, 1441, 1444, 1459, 1463, 1477, 1481, 1510, 1513, 1515, 1551, 1580, 1593, 1625, 1631, 1636, 1652, 1657, 1667, 1670, 1689, 1693, 1694, 1698, 1703, 1705, 1719, 1728, 1736, 1791, 1797, 1814, 1827, 1878, 1893, 1919, 1928, 1943, 1968, 1983, 1990, 2020, 2027, 2041, 2046, 2052, 2055, 2058, 2063, 2073, 2078, 2083, 2088, 2091, 2100, 2109, 2135, 2147, 2175, 2184, 2197, 2262, 2996, 3015, 3068, 3075, 3080, 3104, 3118, 3126, 3138, 3150, 3193, 3217, 3248, 3258, 3262, 3281, 3298, 3302, 3306, 3322, 3356, 3395, 3407, 3436, 3444, 3474, 3481, 3484, 3513, 3560, 3568, 3593, -14146, -13250, -13223, -12736, -12582, -12082, -11548, -11078, -11070, -11069, -9978, -9977, -9446, -9445, -7973, -7973, -7973, -7972, -7972, -7972, -7948, -7933, -7932, -7569, -7568, -7373, -7372, -7049, -7048, -6888, -6887, -6875, -6865, -6858, -6847, -6843, -6836, -6834, -6824, -6787, -6783, -6779, -6762, -6729, -6728, -6728, -6666, -6618, -6588, -6579, -6550, -6547, -6538, -6520, -6519, -6510, -6505, -6492, -6457, -6455, -6428, -6417, -6387, -6344, -6312, -6310, -6295, -6271, -6252, -6247, -6225, -6057, -6056, -6045, -6036, -5987, -5966, -5956, -5930, -5928, -5927, -5899, -5891, -5853, -5841, -5823, -5814, -5803, -5795, -5766, -5765, -5763, -5761, -5721, -5704, -5660, -5642, -5595, -5584, -5577, -5563, -5500, -5500, -5450, -5445, -5348, -5344, -5330, -5292, -5290, -5222, -5216, -5215, -5213, -5171, -5147, -5142, -5133, -5108, -5096, -5070, -5054, -5033, -5018, -4996, -4898, -4898, -4888, -4856, -4830, -4817, -4804, -4802, -4759, -4750, -4748, -4745, -4716, -4682, -4673, -4635, -4626, -4580, -4570, -4565, -4547, -4539, -4537, -4530, -4502, -4499, -4493, -4490, -4471, -4466, -4462, -4457, -4441, -4422, -4413, -4411, -4384, -4373, -4371, -4330, -4328, -4295, -4282, -4257, -4238, -4234, -4228, -4210, -4158, -4121, -3760, -3759, -3732, -3732, -3704, -3669, -3663, -3628, -3625, -3622, -3603, -3599, -3597, -3593, -3570, -3566, -3562, -3558, -3541, -3537, -3533, -3531, -3517, -3513, -3482, -3439, -3414, -3389, -3385, -3364, -3361, -3347, -3344, -3326, -3322, -3320, -3304, -3299, -3248, -3244, -3239, -3214, -3159, -3132, -3106, -3100, -3062, -3057, -3042, -3022, -3016, -3011, -3008, -3007, -3003, -2979, -2976, -2967, -2965, -2927, -2925, -2921, -2919, -2915, -2910, -2909, -2882, -2846, -2816, -2807, -2774, -2759, -2711, -2694, -2688, -2660, -2555, -2546, -2536, -2503, -2455, -2448, -2444, -2436, -2407, -2401, -2392, -2360, -2343, -2317, -2310, -2300, -2271, -2261, -2241, -2225, -2183, -2182, -2181, -2175, -2169, -2165, -2124, -2037, -2027, -2020, -1976, -1967, -1966, -1966, -1949, -1936, -1925, -1901, -1864, -1836, -1811, -1800, -1752, -1743, -1725, -1722, -1716, -1696, -1693, -1665, -1645, -1597, -1579, -1566, -1565, -1561, -1550, -1536, -1532, -1523, -1506, -1495, -1480, -1472, -1460, -1431, -1419, -1400, -1383, -1376, -1365, -1349, -1306, -1295, -1259, -1247, -1232, -1221, -1212, -1203, -1196, -1194, -1187, -1181, -1176, -1174, -1165, -1164, -1157, -1150, -1137, -1115, -1107, -1091, -1074, -1064, -1047, -1024, -1016, -1004, -959, -937, -937, -926, -924, -869, -856, -847, -821, -817, -812, -788, -786, -776, -773, -758, -756, -726, -722, -683, -683, -658, -641, -636, -587, -579, -563, -560, -559, -559, -545, -542, -517, -513, -511, -510, -490, -476, -450, -426, -415, -190, -189, -188, 570, 701, 702, 703, 703, 704, 707, 722, 738, 739, 751, 752, 752, 804, 914, 915, 925, 926, 1550, 1702, 1703, 1796, 2375, 3077, 3077, 3078, 3355]\",\n          \"[-14370, -14345, -14260, -14257, -14234, -14227, -14203, -14186, -14177, -14146, -14144, -14114, -14096, -14086, -14042, -13965, -13842, -13842, -13834, -13822, -2397, -2397, -2396, -2371, -2352, -2327, -1903, -1903, -1900, -1900, -1899, -1898, -1897, -1897, -1859, -1858, -1858, -1845, -1842, -1840, -1835, -1826, -1824, -1810, -1810, -1801, -1801, -1784, -1784, -1782, -1781, -1716, -1715, -1715, -1691, -1671, -1662, -1603, -1589, -1589, -1574, -1521, -1494, -1494, -1443, -1400, -1400, -1372, -1232, -1232, -1232, -1214, -1185, -1185, -1184, -1157, -1156, -1156, -1102, -1004, -991, -947, -946, -945, -873, -872, -872, -868, -866, -831, -830, -814, -748, -738, -712, -712, -668, -668, -654, -602, -602, 2230, 2244]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27531541262125386,\n        \"min\": 50.45520323883495,\n        \"max\": 50.84455802929427,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.84455802929427,\n          50.45520323883495\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29650759811701405,\n        \"min\": 4.40804176737683,\n        \"max\": 4.827366833980583,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.40804176737683,\n          4.827366833980583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[0.0, 0.0, 9.1, 26.0, 36.8, 39.4, 41.7, 41.0, 37.0, 36.3, 36.0, 36.7, 37.3, 35.5, 35.3, 34.6, 28.1, 26.7, 0.1, 0.0, 0.0, 20.5, 39.2, 41.7, 46.1, 44.8, 53.7, 60.3, 80.1, 91.1, 91.3, 87.5, 87.7, 95.1, 89.1, 106.4, 109.8, 111.6, 114.9, 108.8, 100.8, 98.0, 97.5, 113.8, 115.8, 113.5, 111.8, 113.3, 116.0, 116.2, 119.2, 118.3, 118.1, 117.0, 115.0, 108.6, 108.1, 102.9, 120.8, 116.4, 98.3, 97.2, 95.1, 66.2, 66.5, 68.6, 53.6, 46.5, 33.7, 7.5, 0.1, 0.0, 0.0, 51.3, 82.0, 111.3, 109.1, 111.6, 112.9, 111.2, 105.5, 107.2, 111.0, 113.8, 115.1, 96.1, 96.5, 57.1, 55.0, 55.4, 50.5, 47.5, 0.1, 0.0, 12.5, 20.2, 57.2, 60.2, 78.7, 104.5, 110.5, 111.2, 130.8, 133.6, 133.3, 132.2, 131.0, 131.0, 129.1, 128.3, 127.8, 127.5, 124.8, 113.7, 111.4, 99.0, 68.5, 49.7, 14.1, 0.0, 0.0, 0.0, 22.8, 64.2, 88.0, 99.2, 112.9, 111.8, 116.1, 115.6, 109.2, 93.7, 68.7, 71.9, 76.7, 81.3, 102.4, 110.6, 111.7, 112.1, 110.5, 109.3, 109.7, 110.4, 114.0, 114.5, 114.1, 0.1, 0.0, 0.0, 14.0, 23.4, 86.7, 85.7, 73.9, 68.9, 49.0, 37.2, 37.2, 34.0, 34.6, 27.3, 17.8, 16.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.1, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 0.2, 0.1, 61.6, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.5, 27.9, 29.6, 41.8, 44.3, 54.5, 56.9, 61.7, 62.5, 42.6, 39.2, 35.8, 0.0, 0.0, 0.0, 8.9, 19.2, 29.6, 60.5, 67.9, 82.8, 87.1, 108.1, 112.1, 113.0, 117.8, 117.7, 117.9, 115.8, 112.5, 103.2, 9.1, 0.1, 0.0, 0.0, 71.9, 97.1, 129.5, 128.2, 117.1, 82.0, 60.1, 52.7, 52.9, 52.4, 55.8, 66.9, 81.1, 86.8, 91.7, 99.3, 109.3, 110.7, 110.9, 111.5, 111.9, 112.2, 113.5, 115.6, 116.5, 112.0, 106.2, 93.3, 20.4, 0.0, 15.7, 42.2, 43.9, 45.5, 76.9, 78.9, 81.0, 82.4, 83.6, 81.3, 82.6, 103.8, 96.6, 90.7, 63.7, 45.3, 44.8, 44.3, 40.7, 0.0, 0.0, 0.0, 16.3, 29.7, 34.9, 35.4, 35.7, 33.9, 38.4, 36.2, 20.9, 0.1, 0.1, 0.0, 0.2, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.7, 62.6, 81.2, 85.5, 84.2, 82.1, 81.3, 87.2, 89.2, 91.1, 48.0, 42.7, 34.7, 0.0, 0.0, 0.0, 0.0, 63.2, 111.7, 115.3, 111.8, 113.5, 115.2, 114.3, 107.0, 105.9, 92.3, 82.2, 75.4, 72.2, 74.7, 100.2, 110.8, 114.8, 108.6, 75.6, 75.3, 70.0, 56.0, 42.2, 35.4, 0.0, 0.0, 0.0, 0.0, 0.0, 52.4, 84.7, 96.4, 118.1, 119.0, 120.3, 134.1, 130.3, 129.1, 128.9, 131.0, 126.7, 129.6, 133.0, 134.8, 134.2, 134.2, 133.5, 105.9, 80.0, 58.1, 57.2, 45.5, 36.5, 31.9, 0.2, 0.0, 0.0, 48.5, 57.5, 53.5, 53.7, 66.7, 94.5, 93.4, 116.1, 116.5, 116.5, 116.7, 111.2, 118.8, 119.6, 117.9, 95.8, 87.1, 68.5, 65.0, 54.5, 39.8, 0.2, 0.0, 0.0, 0.0, 49.2, 65.4, 87.1, 99.9, 102.1, 110.6, 113.6, 114.4, 114.5, 116.4, 116.0, 113.4, 118.5, 115.9, 108.3, 107.1, 111.1, 109.7, 109.0, 109.0, 110.7, 117.5, 118.3, 115.8, 114.4, 119.2, 119.2, 120.4, 119.5, 113.4, 116.7, 111.0, 109.8, 96.6, 95.0, 94.4, 89.7, 89.6, 76.2, 73.3, 59.5, 54.2, 50.7, 47.5, 37.8, 33.9, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 20.2, 22.1, 32.6, 33.9, 34.7, 36.2, 36.7, 36.9, 36.3, 36.7, 37.3, 37.6, 37.7, 39.1, 39.3, 43.4, 44.6, 45.2, 45.0, 0.1, 0.0, 0.0, 33.0, 38.7, 46.0, 46.0, 45.8, 45.6, 41.2, 38.6, 38.1, 35.2, 34.2, 35.7, 36.3, 36.2, 0.0, 0.0, 0.0, 31.7, 32.7, 43.9, 49.3, 62.2, 68.3, 69.0, 72.1, 74.8, 76.6, 80.6, 94.5, 93.3, 92.0, 91.8, 86.8, 87.2, 86.2, 85.9, 86.7, 92.5, 93.3, 112.8, 116.2, 113.8, 108.3, 83.0, 56.8, 50.6, 44.0, 35.5, 0.0, 0.0, 0.0, 0.0, 21.8, 91.3, 97.6, 100.3, 107.4, 112.5, 112.9, 113.7, 113.8, 113.7, 114.2, 113.7, 110.3, 103.3, 107.8, 114.2, 110.5, 102.7, 102.7, 102.4, 91.1, 81.9, 74.0, 19.1, 0.0, 6.0, 11.6, 35.1, 34.5, 34.5, 34.4, 31.4, 25.8, 27.2, 0.2, 0.0, 0.0, 25.1, 29.4, 36.6, 37.1, 36.6, 36.2, 38.1, 53.0, 49.9, 0.1, 0.0, 0.0, 31.0, 65.5, 68.9, 75.1, 89.8, 107.0, 110.2, 113.7, 104.7, 92.6, 86.6, 86.4, 82.6, 83.8, 84.8, 85.4, 89.0, 95.3, 108.9, 112.7, 115.8, 115.3, 115.9, 115.8, 116.0, 115.6, 115.9, 116.3, 116.3, 116.5, 116.2, 115.7, 114.2, 112.0, 99.8, 96.9, 79.1, 61.5, 55.5, 54.6, 54.0, 76.4, 97.2, 107.0, 122.2, 133.7, 117.1, 90.0, 0.2, 0.0, 0.0, 0.0, 0.0, 74.5, 89.2, 98.9, 116.0, 115.0, 109.4, 93.1, 90.3, 74.9, 70.4, 47.6, 44.5, 10.3, 0.1, 0.0, 0.0, 0.0, 15.5, 26.2, 27.4, 36.3, 62.0, 61.7, 61.7, 61.5, 41.8, 39.5, 31.2, 28.6, 31.6, 31.9, 33.6, 33.0, 18.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 117.8, 117.7, 0.1, 4.0, 44.3, 44.4, 44.3, 0.1]\",\n          \"[0.0, 15.0, 34.5, 34.4, 56.9, 45.5, 38.0, 36.7, 35.3, 41.0, 37.8, 33.6, 32.0, 30.5, 19.7, 19.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2,\n        \"max\": 13,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16737a51-b8eb-4428-b351-51113364e62c",
      "metadata": {
        "id": "16737a51-b8eb-4428-b351-51113364e62c"
      },
      "source": [
        "Now I will analyze the percentage of each event type appearing at least once in an event sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642",
      "metadata": {
        "id": "d70f1d49-bf17-4c26-96c9-cea06d26c642"
      },
      "outputs": [],
      "source": [
        "events_types_dict = {}\n",
        "for events_sequence in df['events_sequence']:\n",
        "    row_list = ast.literal_eval(events_sequence) #transforming string into actual list\n",
        "    unique_events = set(row_list)\n",
        "    for event in unique_events:\n",
        "        if not events_types_dict.get(event):\n",
        "            events_types_dict[event] = 0\n",
        "        events_types_dict[event] += 1\n",
        "sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "# Convert the sorted dictionary to a DataFrame\n",
        "sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "# Cast the 'event_type' column to string\n",
        "sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7",
      "metadata": {
        "id": "18cbe400-a4a2-4625-92ad-3c527827e5e7"
      },
      "source": [
        "We save in a list all event codes that appear in less than 85% of the event sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ba05e687-439c-4f60-a78e-681a6cd75090",
      "metadata": {
        "id": "ba05e687-439c-4f60-a78e-681a6cd75090"
      },
      "outputs": [],
      "source": [
        "events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage<=85].event_type)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617",
      "metadata": {
        "id": "ea15edbc-88df-41fa-b9d1-7099d50a6617"
      },
      "source": [
        "## Text preprocessing\n",
        "Before we start with text classification we need to clean the sequences of events. As seen one value of `events_sequence` contains commas and brackets even though it is a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cb37149f-424d-4374-b560-e330b3942c6e",
      "metadata": {
        "id": "cb37149f-424d-4374-b560-e330b3942c6e",
        "outputId": "83144fe4-7d49-4580-ebfa-5d141dd3b995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[2744, 4004, 2852, 4110, 2854, 4396, 1132, 4140, 4148, 2708, 4026, 1032, 1082, 4152, 4030, 4018, 4168, 4156, 4394, 152, 2742, 4410, 4406, 4068, 4408, 4412, 4066, 2744, 4026, 4148, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 4148, 2708, 4026, 4140, 4152, 4030, 4018, 4140, 4168, 4156, 2852, 2854, 4124, 2858, 2658, 2688, 3254, 3254, 3254, 2970, 4082, 4090, 4092, 2982, 3236, 4100, 2702, 4394, 1250, 2970, 2980, 2970, 2980, 2970, 2982, 2970, 2982, 4168, 4140, 3986, 2742, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4030, 4018, 4148, 4140, 4152, 4168, 4156, 4120, 2858, 2658, 2688, 3254, 3254, 2970, 2982, 2708, 2970, 2982, 4100, 2702, 1250, 4394, 2744, 4026, 4148, 2970, 2980, 4168, 4140, 4168, 3986, 2744, 4002, 2852, 4110, 2854, 2980, 2708, 4026, 4148, 2552, 4168, 4140, 4152, 4030, 4018, 4026, 4140, 4168, 4156, 2970, 2982, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 1250, 4394, 4168, 4140, 3986, 2744, 4004, 2852, 4110, 2854, 2982, 2708, 4026, 4140, 4030, 4018, 4140, 4140, 2552, 4168, 4140, 4148, 4140, 4140, 4152, 4168, 4156, 2708, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4066, 2708, 2708, 3082, 4394, 3086, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2742, 4026, 4148, 2708, 3036, 4394, 4168, 4140, 3986, 2744, 4002, 2852, 4110, 2854, 2982, 4148, 2708, 4026, 4140, 4152, 4168, 4030, 4018, 4156, 4406, 4410, 4408, 4412, 2980, 2980, 2970, 3492, 4066, 4068, 4396, 2980, 2708, 2970, 2980, 2970, 2980, 2970, 2980, 2744, 4148, 2970, 2980, 2970, 2980, 4124, 3224, 2690, 3224, 2690, 3224, 2690, 3224, 2690, 4126, 3224, 2690, 2684, 2846, 4124, 3224, 4022, 3032, 4394, 2654, 2708, 4392, 1200, 1202, 2652, 3260, 4092, 2708, 2980, 4396, 1286, 3132, 4394, 4396, 1286, 2652, 2654, 2708, 3082, 4392, 4394, 1200, 1202, 2708, 4394, 1286, 1720, 1740, 1760, 1780, 4396, 1286, 2652, 4094, 2708, 4124, 4072, 2970, 2982, 2708, 2970, 4082, 4090, 4092, 4084, 4094, 4090, 3236, 2974, 4100, 4124, 2708, 2970, 2980, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3236, 2982, 4100, 2702, 4394, 1250, 2708, 2708, 3082, 1286, 3082, 1720, 1740, 1760, 1780, 1286, 2652, 3260, 4094, 3082, 3086, 1286, 1286, 1720, 1740, 1780, 2652, 3260, 4094, 2708, 2970, 4396, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708, 2970, 4082, 4090, 4092, 4084, 4090, 4094, 2988, 3236, 4100, 2702, 4394, 1250, 2970, 4396, 2980, 2970, 4082, 4092, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2708]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.events_sequence.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21",
      "metadata": {
        "id": "2183bcea-5226-48ff-a693-7bdd70cb6e21"
      },
      "source": [
        "Also, as observed before some event types are so common they do not actually bring a lot of value (as mentioned in the paper as well). We remove those common event types\n",
        "\n",
        "The steps to clean the event sequences are:\n",
        "- keep non-common event types mentioned in list `events_low_frequency`\n",
        "- remove symbols: [] , and store sequences of events as a string without brackets and commas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca",
      "metadata": {
        "id": "b337c2ce-e0fd-49ea-b2e3-a8e71171f7ca"
      },
      "outputs": [],
      "source": [
        "df['clean_events_sequence'] = df.events_sequence.apply(ast.literal_eval).apply(lambda x: [i for i in x if i in events_low_frequency]).astype(str)\\\n",
        "                .replace(r'[\\[\\],]', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b",
      "metadata": {
        "id": "14c7dba5-3363-4b8b-95bc-6ea16f64db3b"
      },
      "source": [
        "## Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18e3f2d-8402-4608-bddc-696b656096be",
      "metadata": {
        "id": "b18e3f2d-8402-4608-bddc-696b656096be"
      },
      "source": [
        "Now we try to experiment using text techniques to transform the list events sequence:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['incident_type'].value_counts()\n",
        "df = df[~df[\"incident_type\"].isin([7, 16, 3, 6, 17])].copy()\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "cyslsE2taYSE"
      },
      "id": "cyslsE2taYSE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518",
      "metadata": {
        "id": "ac4ace38-2df1-45ac-b4ac-ca9179985518"
      },
      "outputs": [],
      "source": [
        "target = df['incident_type'].copy() # target column separated\n",
        "#le = LabelEncoder()\n",
        "#target = le.fit_transform(target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.clean_events_sequence, target, test_size=0.2,  random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951515d0-d264-4008-a0b9-862d4de245b9",
      "metadata": {
        "id": "951515d0-d264-4008-a0b9-862d4de245b9"
      },
      "source": [
        "Since the dataset is imbalanced we will use different strategies to battle that. Here we set a new sampling strategy based on a basic script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
      "metadata": {
        "id": "1491c584-b6ef-412d-a3bf-f22fb731fa03",
        "outputId": "31d5882f-4d69-4f83-d081-78cac37355c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{99: 183, 14: 157, 9: 131, 2: 129, 4: 97, 11: 59}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Define custom sampling strategy based on class distribution\n",
        "# Each non-majority class will have equal samples to 15% of the majority class plus their previous samples\n",
        "class_counts = pd.Series(y_train).value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(pd.Series(y_train).value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "sampling_strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89063fd-fac4-49af-bac6-4e7556984ea9",
      "metadata": {
        "id": "e89063fd-fac4-49af-bac6-4e7556984ea9"
      },
      "source": [
        "Starting with CountVectorizer:\n",
        "- Tokenization: Splits text into individual words (tokens).\n",
        "- Builds a Vocabulary: Creates a dictionary of unique words (tokens) from the entire corpus.\n",
        "- Counts the Occurrence: Calculates the frequency (count) of each word in each document.\n",
        "- Transforms Text into a Sparse Matrix: Returns a matrix of shape (n_samples, n_features), where n_samples is the number of documents and n_features is the number of unique words in the vocabulary.\n",
        "\n",
        "  We firstly set the sampling strategy for SMOTE:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739",
      "metadata": {
        "id": "bd228c63-bcf0-4b11-be54-39aebd1dc739"
      },
      "source": [
        "Now we set the pipeline to be used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d",
      "metadata": {
        "id": "430b9fe4-4f4b-40d2-976b-06916ce5688d"
      },
      "outputs": [],
      "source": [
        "text_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                     #('decision_tree', DecisionTreeClassifier()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    #('random_forest', RandomForestClassifier())\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199354cb-7476-434b-92fd-f5ba688b62ce",
      "metadata": {
        "id": "199354cb-7476-434b-92fd-f5ba688b62ce"
      },
      "source": [
        "Training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
      "metadata": {
        "id": "09d346e4-75de-46e1-aa17-19cd8834e324",
        "outputId": "ed30d4e3-7880-48c1-9ff1-96c51d3e7d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                ('smote',\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                ('extra_trees', ExtraTreesClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;smote&#x27;,\n",
              "                 SMOTE(k_neighbors=2, random_state=1,\n",
              "                       sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59,\n",
              "                                          14: 157, 99: 183})),\n",
              "                (&#x27;extra_trees&#x27;, ExtraTreesClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(k_neighbors=2, random_state=1,\n",
              "      sampling_strategy={2: 129, 4: 97, 9: 131, 11: 59, 14: 157, 99: 183})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "text_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f",
      "metadata": {
        "id": "3273e4d7-fdc3-41ad-b5cf-8af15e8c0d9f"
      },
      "source": [
        "Print the results for the particular split of test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
      "metadata": {
        "id": "63957f6a-e782-4f88-a226-8e41e6ea2c05",
        "outputId": "c5e53dfc-b6e1-487f-fa43-3ab3ce129a12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.85      0.79      0.81        28\n",
            "           4       0.70      0.74      0.72        19\n",
            "           9       0.91      0.42      0.57        24\n",
            "          11       1.00      0.00      0.00         5\n",
            "          13       0.65      0.93      0.77        61\n",
            "          14       0.62      0.53      0.57        30\n",
            "          99       0.54      0.47      0.50        30\n",
            "\n",
            "    accuracy                           0.68       197\n",
            "   macro avg       0.75      0.55      0.56       197\n",
            "weighted avg       0.70      0.68      0.65       197\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_predict = text_clf.predict(X_test)\n",
        "print(classification_report(y_test, clf_predict, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = TfidfVectorizer()\n",
        "embeddings = vec.fit_transform(X_train).toarray()\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)\n",
        "trees = ExtraTreesClassifier()\n",
        "X_train_res, y_train_res = smote.fit_resample(embeddings, y_train)\n",
        "\n",
        "trees.fit(X_train_res, y_train_res)\n",
        "predictions = trees.predict(vec.transform(X_test).toarray())\n",
        "print(classification_report(y_test, predictions, zero_division=1))"
      ],
      "metadata": {
        "id": "4SWVd4Mbsiz5",
        "outputId": "4a273c5e-4602-49cc-8903-0a4c9fd66e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "id": "4SWVd4Mbsiz5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TfidfVectorizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5cf8c9ab6019>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(X_train.values)\n"
      ],
      "metadata": {
        "id": "OKrALanIwbPA"
      },
      "id": "OKrALanIwbPA",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "embeddings = vectorizer.fit_transform(X_train)\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)\n",
        "X_train_res, y_train_res = smote.fit_resample(embeddings, y_train)\n",
        "le = LabelEncoder()\n",
        "y_train_res_e = le.fit_transform(y_train_res)\n",
        "y_test_e = le.transform(y_test)\n",
        "dtrain = xgb.DMatrix(data=X_train_res, label=y_train_res_e)\n",
        "dtest = xgb.DMatrix(data=vectorizer.transform(X_test), label=y_test_e)\n",
        "num_classes = len(np.unique(target))\n",
        "params = {\n",
        "    'objective': 'multi:softmax',   # Cambiar a 'multi:softprob' si necesitas probabilidades en lugar de etiquetas\n",
        "    'num_class': num_classes,       # Nmero de clases\n",
        "    'max_depth': 4,                 # Profundidad mxima del rbol\n",
        "    'learning_rate': 0.1,           # Tasa de aprendizaje\n",
        "    'n_estimators': 100,            # Nmero de rboles\n",
        "    'eval_metric': 'mlogloss'       # Mtrica para clasificacin multiclase\n",
        "}\n",
        "bst = xgb.train(params, dtrain)\n",
        "predictions = bst.predict(dtest)\n",
        "accuracy = accuracy_score(y_test_e, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "7pd9sZ47tJQ6",
        "outputId": "9a6f023b-4e68-4703-b7e0-9db3407e01c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "id": "7pd9sZ47tJQ6",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LabelEncoder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-8a315939ed92>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_train_res_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_test_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "id": "Zt4FhmDO-IPk",
        "outputId": "cdc8868d-5eb7-4042-ff48-4399e7b4cece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Zt4FhmDO-IPk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"incident_type\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "0lnEgVMlZ_4P",
        "outputId": "31281faa-dd69-4771-ebba-fd901d29e909"
      },
      "id": "0lnEgVMlZ_4P",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "incident_type\n",
              "13    318\n",
              "99    175\n",
              "14    149\n",
              "2     119\n",
              "9     117\n",
              "4      78\n",
              "11     26\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            \"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "        }\n",
        "        self.vectorizers = {\n",
        "            \"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer()\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(),\n",
        "        }\n",
        "\n",
        "    def run(self):\n",
        "        results = []\n",
        "\n",
        "        for vect_name, vectorizer in self.vectorizers.items():\n",
        "            i_vectorizer = deepcopy(vectorizer)\n",
        "            for samp_name, sampler in self.sampling_strategies.items():\n",
        "                i_sampler = deepcopy(sampler)\n",
        "                for clf_name, classifier in tqdm(self.classifiers.items()):\n",
        "                    print(f\"\\n=== Vectorizer: {vect_name} ===\")\n",
        "                    print(f\"\\n=== Sampling Strategy: {samp_name} ===\")\n",
        "                    print(f\"\\n=== Classifier: {clf_name} ===\\n\")\n",
        "\n",
        "                    accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "                    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "                    for train_index, test_index in skf.split(self.X, self.y):\n",
        "                        vectorizer = deepcopy(i_vectorizer)\n",
        "                        sampler = deepcopy(i_sampler)\n",
        "\n",
        "                        X_train, X_test = self.X[train_index], self.X[test_index]\n",
        "                        y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "\n",
        "                        X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "                        X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "                        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "                        classifier.fit(X_resampled, y_resampled)\n",
        "                        y_pred = classifier.predict(X_test)\n",
        "\n",
        "                        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "                        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "                        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "                        f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "\n",
        "                    results.append({\n",
        "                        'Vectorizer': vect_name,\n",
        "                        'Sampling': samp_name,\n",
        "                        'Model': clf_name,\n",
        "                        'Accuracy Mean': np.mean(accuracies),\n",
        "                        'Accuracy Std': np.std(accuracies),\n",
        "                        'Recall Mean': np.mean(recalls),\n",
        "                        'Recall Std': np.std(recalls),\n",
        "                        'Precision Mean': np.mean(precisions),\n",
        "                        'Precision Std': np.std(precisions),\n",
        "                        'F1 Mean': np.mean(f1s),\n",
        "                        'F1 Std': np.std(f1s),\n",
        "                    })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        return results_df\n",
        "\n",
        "le = LabelEncoder()\n",
        "target = le.fit_transform(target)\n",
        "exp = Experiment(df.clean_events_sequence, target)\n",
        "results = exp.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvxqTgKSO7dz",
        "outputId": "52a4dd90-42a6-4392-abc0-98911d3377e3"
      },
      "id": "HvxqTgKSO7dz",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:07<01:10,  7.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:10<00:36,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 30%|       | 3/10 [00:15<00:35,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:22<00:35,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [05:41<09:53, 118.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [05:52<05:27, 81.87s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [05:53<02:46, 55.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [05:54<01:16, 38.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [06:25<00:35, 35.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [07:32<00:00, 45.26s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:03<00:34,  3.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:06<00:24,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 30%|       | 3/10 [00:15<00:40,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:21<00:34,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [05:37<09:49, 117.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [05:49<05:26, 81.64s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [05:50<02:46, 55.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [05:52<01:16, 38.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [06:22<00:35, 35.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [07:29<00:00, 44.98s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:03<00:34,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:06<00:23,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:13<00:34,  4.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:19<00:31,  5.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [05:52<10:17, 123.54s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [06:03<05:40, 85.20s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [06:04<02:53, 57.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [06:06<01:19, 39.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [06:40<00:38, 38.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [07:44<00:00, 46.45s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:03<00:29,  3.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 20%|        | 2/10 [00:04<00:17,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:10<00:26,  3.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:15<00:26,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [03:38<06:18, 75.79s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [03:46<03:32, 53.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [03:47<01:47, 35.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [03:48<00:49, 24.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [04:17<00:26, 26.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [04:56<00:00, 29.69s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:03<00:32,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:06<00:24,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:12<00:32,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:18<00:30,  5.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [04:06<07:07, 85.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 60%|    | 6/10 [04:17<03:59, 59.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [04:18<02:02, 40.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [04:20<00:57, 28.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [04:36<00:24, 24.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [05:16<00:00, 31.65s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [00:05<00:51,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:09<00:34,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 30%|       | 3/10 [00:15<00:37,  5.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:23<00:38,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [05:35<09:43, 116.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [05:48<05:24, 81.23s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [05:50<02:45, 55.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [05:52<01:16, 38.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [06:24<00:36, 36.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: TFIDF ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [07:29<00:00, 44.92s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:08<01:14,  8.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:09<00:34,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:14<00:30,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:21<00:33,  5.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [02:40<04:27, 53.44s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [02:47<02:31, 37.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [02:48<01:17, 25.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [02:49<00:35, 17.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [03:31<00:25, 25.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "100%|| 10/10 [03:56<00:00, 23.62s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:06<01:02,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:08<00:32,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 30%|       | 3/10 [00:16<00:39,  5.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:23<00:36,  6.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [02:48<04:41, 56.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [02:56<02:39, 39.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [02:58<01:21, 27.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [02:59<00:38, 19.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [03:40<00:25, 25.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [04:04<00:00, 24.44s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:06<01:02,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:09<00:35,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:15<00:34,  4.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:22<00:34,  5.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [02:46<04:38, 55.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [02:54<02:38, 39.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [02:55<01:21, 27.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [02:57<00:37, 18.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [03:42<00:27, 27.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: ADASYN ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [04:07<00:00, 24.76s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:08<01:12,  8.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:09<00:31,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:13<00:27,  3.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:19<00:28,  4.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [02:46<04:41, 56.34s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [02:53<02:37, 39.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [02:54<01:20, 26.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [02:54<00:37, 18.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [03:36<00:25, 25.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [03:58<00:00, 23.88s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:06<00:58,  6.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:10<00:38,  4.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:16<00:37,  5.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:21<00:31,  5.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [01:41<02:40, 32.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 60%|    | 6/10 [01:48<01:35, 23.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:51<00:50, 16.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:54<00:24, 12.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%| | 9/10 [02:11<00:13, 13.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [02:30<00:00, 15.04s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: LogisticRegression ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 10%|         | 1/10 [00:07<01:08,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: DecisionTree ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:11<00:41,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: RandomForest ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:16<00:38,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: ExtraTreesClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:24<00:39,  6.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: GradientBoostingClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 50%|     | 5/10 [02:51<04:44, 56.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: AdaBoostClassifier ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            " 60%|    | 6/10 [02:59<02:40, 40.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: GaussianNB ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [03:00<01:22, 27.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: KNN ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [03:03<00:39, 19.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: SVM ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [03:45<00:26, 26.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vectorizer: Count ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n",
            "\n",
            "=== Classifier: XGBoost ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [04:09<00:00, 24.97s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_csv('results.csv')"
      ],
      "metadata": {
        "id": "OFCxX2cFrm0h"
      },
      "id": "OFCxX2cFrm0h",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "# ----> 8             'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "#       9             'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "Zaf0HrwOEbpu"
      },
      "id": "Zaf0HrwOEbpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import make_classification\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "sampling_strategies = {\n",
        "    \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "    \"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "    \"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "    \"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "    \"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "    \"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1)\n",
        "}\n",
        "\n",
        "text_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                     #('decision_tree', DecisionTreeClassifier()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    #('random_forest', RandomForestClassifier())\n",
        "                    ])\n",
        "clf_predict = text_clf.predict(X_test)\n",
        "print(classification_report(y_test, clf_predict, zero_division=1))\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(),\n",
        "        }\n",
        "\n",
        "le = LabelEncoder()\n",
        "target_e = le.fit_transform(target)\n",
        "vectorizer = TfidfVectorizer()\n",
        "embeddings = vectorizer.fit_transform(df.clean_events_sequence)\n",
        "results = {}\n",
        "\n",
        "for name, sampler in tqdm(sampling_strategies.items()):\n",
        "    try:\n",
        "      print(f\"\\n=== Sampling Strategy: {name} ===\")\n",
        "      X_res, y_res = sampler.fit_resample(embeddings, target_e)\n",
        "\n",
        "      experiment = SCNB()\n",
        "      results[name] = experiment.evaluate_models(X_res.toarray(), y_res)\n",
        "      experiment.reset_models()\n",
        "    except Exception as e:\n",
        "      pass"
      ],
      "metadata": {
        "id": "0p9_Rlc08l81",
        "outputId": "85ad7bdb-32e5-4acf-e887-1a33106b4552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0p9_Rlc08l81",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sampling Strategy: SMOTE ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [00:17<02:38, 17.66s/it]\u001b[A\n",
            " 20%|        | 2/10 [00:22<01:21, 10.22s/it]\u001b[A\n",
            " 30%|       | 3/10 [00:32<01:11, 10.19s/it]\u001b[A\n",
            " 40%|      | 4/10 [00:43<01:02, 10.34s/it]\u001b[A\n",
            " 50%|     | 5/10 [20:07<35:32, 426.52s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 60%|    | 6/10 [20:30<19:17, 289.30s/it]\u001b[A\n",
            " 70%|   | 7/10 [20:31<09:44, 194.85s/it]\u001b[A\n",
            " 80%|  | 8/10 [20:32<04:26, 133.11s/it]\u001b[A\n",
            " 90%| | 9/10 [21:39<01:52, 112.69s/it]\u001b[A\n",
            "100%|| 10/10 [23:47<00:00, 142.70s/it]\n",
            " 17%|        | 1/6 [23:47<1:58:56, 1427.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sampling Strategy: Borderline-SMOTE ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 10%|         | 1/10 [00:07<01:11,  7.95s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 20%|        | 2/10 [00:10<00:36,  4.60s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 30%|       | 3/10 [00:17<00:41,  5.93s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 40%|      | 4/10 [00:24<00:36,  6.09s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 50%|     | 5/10 [12:11<21:35, 259.04s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 60%|    | 6/10 [12:26<11:43, 175.87s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 70%|   | 7/10 [12:26<05:55, 118.48s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 80%|  | 8/10 [12:27<02:42, 81.03s/it] \u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 90%| | 9/10 [13:18<01:11, 71.67s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "100%|| 10/10 [14:56<00:00, 89.68s/it]\n",
            " 33%|      | 2/6 [38:44<1:14:21, 1115.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sampling Strategy: ADASYN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [00:12<01:56, 12.93s/it]\u001b[A\n",
            " 20%|        | 2/10 [00:16<00:57,  7.21s/it]\u001b[A\n",
            " 30%|       | 3/10 [00:26<00:59,  8.48s/it]\u001b[A\n",
            " 40%|      | 4/10 [00:35<00:52,  8.70s/it]\u001b[A\n",
            " 50%|     | 5/10 [19:55<35:19, 423.97s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 60%|    | 6/10 [20:16<19:07, 286.99s/it]\u001b[A\n",
            " 70%|   | 7/10 [20:16<09:39, 193.30s/it]\u001b[A\n",
            " 80%|  | 8/10 [20:17<04:24, 132.04s/it]\u001b[A\n",
            " 90%| | 9/10 [21:27<01:52, 112.65s/it]\u001b[A\n",
            "100%|| 10/10 [23:31<00:00, 141.17s/it]\n",
            " 50%|     | 3/6 [1:02:16<1:02:32, 1250.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sampling Strategy: RandomOversampler ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|         | 1/10 [00:12<01:54, 12.67s/it]\u001b[A\n",
            " 20%|        | 2/10 [00:14<00:50,  6.36s/it]\u001b[A\n",
            " 30%|       | 3/10 [00:21<00:44,  6.38s/it]\u001b[A\n",
            " 40%|      | 4/10 [00:31<00:46,  7.82s/it]\u001b[A\n",
            " 50%|     | 5/10 [13:05<23:05, 277.14s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            " 60%|    | 6/10 [13:21<12:33, 188.37s/it]\u001b[A\n",
            " 70%|   | 7/10 [13:22<06:20, 126.96s/it]\u001b[A\n",
            " 80%|  | 8/10 [13:23<02:53, 86.91s/it] \u001b[A\n",
            " 90%| | 9/10 [14:20<01:17, 77.66s/it]\u001b[A\n",
            "100%|| 10/10 [15:36<00:00, 93.69s/it]\n",
            "100%|| 6/6 [1:17:52<00:00, 778.83s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sampling Strategy: SMOTE-ENN ===\n",
            "\n",
            "=== Sampling Strategy: SMOTE-Tomek ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['RandomOversampler']"
      ],
      "metadata": {
        "id": "SMu6W1lYrkI1",
        "outputId": "d115b193-2007-4709-866b-f931c9852da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "id": "SMu6W1lYrkI1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model  Accuracy Mean  Accuracy Std  Accuracy Median  \\\n",
              "0          LogisticRegression       0.860330      0.013754         0.857143   \n",
              "1                DecisionTree       0.933708      0.023858         0.937090   \n",
              "2                RandomForest       0.958340      0.019827         0.955439   \n",
              "3        ExtraTreesClassifier       0.964367      0.017822         0.965924   \n",
              "4  GradientBoostingClassifier       0.957028      0.019163         0.956750   \n",
              "5          AdaBoostClassifier       0.157743      0.043940         0.124509   \n",
              "6                  GaussianNB       0.834381      0.008481         0.835079   \n",
              "7                         KNN       0.837272      0.016014         0.844037   \n",
              "8                         SVM       0.924008      0.012868         0.922674   \n",
              "9                     XGBoost       0.963318      0.017130         0.960682   \n",
              "\n",
              "   Recall Mean  Recall Std  Recall Median  Precision Mean  Precision Std  \\\n",
              "0     0.860330    0.013754       0.857143        0.856348       0.014742   \n",
              "1     0.933708    0.023858       0.937090        0.934313       0.026685   \n",
              "2     0.958340    0.019827       0.955439        0.958372       0.020678   \n",
              "3     0.964367    0.017822       0.965924        0.966048       0.017306   \n",
              "4     0.957028    0.019163       0.956750        0.959100       0.017760   \n",
              "5     0.157743    0.043940       0.124509        0.140034       0.048696   \n",
              "6     0.834381    0.008481       0.835079        0.843843       0.012187   \n",
              "7     0.837272    0.016014       0.844037        0.833762       0.016173   \n",
              "8     0.924008    0.012868       0.922674        0.924448       0.013004   \n",
              "9     0.963318    0.017130       0.960682        0.963791       0.017740   \n",
              "\n",
              "   Precision Median  \n",
              "0          0.852546  \n",
              "1          0.937503  \n",
              "2          0.954634  \n",
              "3          0.967660  \n",
              "4          0.957256  \n",
              "5          0.109705  \n",
              "6          0.850530  \n",
              "7          0.841537  \n",
              "8          0.923317  \n",
              "9          0.960980  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a07d4425-86e6-4ad2-9f38-723fe006e9f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Accuracy Median</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Recall Median</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>Precision Median</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.860330</td>\n",
              "      <td>0.013754</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.860330</td>\n",
              "      <td>0.013754</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.856348</td>\n",
              "      <td>0.014742</td>\n",
              "      <td>0.852546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.933708</td>\n",
              "      <td>0.023858</td>\n",
              "      <td>0.937090</td>\n",
              "      <td>0.933708</td>\n",
              "      <td>0.023858</td>\n",
              "      <td>0.937090</td>\n",
              "      <td>0.934313</td>\n",
              "      <td>0.026685</td>\n",
              "      <td>0.937503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.958340</td>\n",
              "      <td>0.019827</td>\n",
              "      <td>0.955439</td>\n",
              "      <td>0.958340</td>\n",
              "      <td>0.019827</td>\n",
              "      <td>0.955439</td>\n",
              "      <td>0.958372</td>\n",
              "      <td>0.020678</td>\n",
              "      <td>0.954634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.964367</td>\n",
              "      <td>0.017822</td>\n",
              "      <td>0.965924</td>\n",
              "      <td>0.964367</td>\n",
              "      <td>0.017822</td>\n",
              "      <td>0.965924</td>\n",
              "      <td>0.966048</td>\n",
              "      <td>0.017306</td>\n",
              "      <td>0.967660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.957028</td>\n",
              "      <td>0.019163</td>\n",
              "      <td>0.956750</td>\n",
              "      <td>0.957028</td>\n",
              "      <td>0.019163</td>\n",
              "      <td>0.956750</td>\n",
              "      <td>0.959100</td>\n",
              "      <td>0.017760</td>\n",
              "      <td>0.957256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.157743</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.124509</td>\n",
              "      <td>0.157743</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.124509</td>\n",
              "      <td>0.140034</td>\n",
              "      <td>0.048696</td>\n",
              "      <td>0.109705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.834381</td>\n",
              "      <td>0.008481</td>\n",
              "      <td>0.835079</td>\n",
              "      <td>0.834381</td>\n",
              "      <td>0.008481</td>\n",
              "      <td>0.835079</td>\n",
              "      <td>0.843843</td>\n",
              "      <td>0.012187</td>\n",
              "      <td>0.850530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.837272</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.844037</td>\n",
              "      <td>0.837272</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.844037</td>\n",
              "      <td>0.833762</td>\n",
              "      <td>0.016173</td>\n",
              "      <td>0.841537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.924008</td>\n",
              "      <td>0.012868</td>\n",
              "      <td>0.922674</td>\n",
              "      <td>0.924008</td>\n",
              "      <td>0.012868</td>\n",
              "      <td>0.922674</td>\n",
              "      <td>0.924448</td>\n",
              "      <td>0.013004</td>\n",
              "      <td>0.923317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.963318</td>\n",
              "      <td>0.017130</td>\n",
              "      <td>0.960682</td>\n",
              "      <td>0.963318</td>\n",
              "      <td>0.017130</td>\n",
              "      <td>0.960682</td>\n",
              "      <td>0.963791</td>\n",
              "      <td>0.017740</td>\n",
              "      <td>0.960980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07d4425-86e6-4ad2-9f38-723fe006e9f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a07d4425-86e6-4ad2-9f38-723fe006e9f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a07d4425-86e6-4ad2-9f38-723fe006e9f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ebe4a4d-239d-45a7-ac05-9ba37cad7abc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ebe4a4d-239d-45a7-ac05-9ba37cad7abc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ebe4a4d-239d-45a7-ac05-9ba37cad7abc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results['RandomOversampler']\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SVM\",\n          \"DecisionTree\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2449786596992123,\n        \"min\": 0.15774292713386812,\n        \"max\": 0.9643670273719748,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9240079460383029,\n          0.9337078767334782,\n          0.15774292713386812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009632645983420987,\n        \"min\": 0.008480681956933864,\n        \"max\": 0.04394033959692082,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.012868348541190552,\n          0.023858443361499844,\n          0.04394033959692082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2551113118742708,\n        \"min\": 0.12450851900393185,\n        \"max\": 0.9659239842726082,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9226736566186108,\n          0.9370904325032765,\n          0.12450851900393185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2449786596992123,\n        \"min\": 0.15774292713386812,\n        \"max\": 0.9643670273719748,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9240079460383029,\n          0.9337078767334782,\n          0.15774292713386812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009632645983420987,\n        \"min\": 0.008480681956933864,\n        \"max\": 0.04394033959692082,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.012868348541190552,\n          0.023858443361499844,\n          0.04394033959692082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2551113118742708,\n        \"min\": 0.12450851900393185,\n        \"max\": 0.9659239842726082,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9226736566186108,\n          0.9370904325032765,\n          0.12450851900393185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25070334833437313,\n        \"min\": 0.14003354163466425,\n        \"max\": 0.9660483935990886,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.924447767897815,\n          0.9343132954405716,\n          0.14003354163466425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01072794338848985,\n        \"min\": 0.012186770469811349,\n        \"max\": 0.04869600160411477,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.013004223255116673,\n          0.026684688125239678,\n          0.04869600160411477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25984539524829703,\n        \"min\": 0.10970496372836587,\n        \"max\": 0.9676598795181051,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9233174322597536,\n          0.9375028490360678,\n          0.10970496372836587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "embeddings = vectorizer.fit_transform(df.clean_events_sequence)\n",
        "class_counts = pd.Series(target).value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(pd.Series(target).value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)\n",
        "X_res, y_res = smote.fit_resample(embeddings, target)\n",
        "le = LabelEncoder()\n",
        "y_res_e = le.fit_transform(y_res)\n"
      ],
      "metadata": {
        "id": "060w7FEq1Mmh"
      },
      "id": "060w7FEq1Mmh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = SCNB()\n",
        "X_train_res, y_train_res_e = pre_process_data(X_train, y_train)\n",
        "experiment.train_classifiers(X_train_res, y_train_res_e)\n",
        "X_res, y_res = pre_process_data(df.clean_events_sequence, target)\n",
        "experiment.evaluate_models(X_res, y_res)"
      ],
      "metadata": {
        "id": "QnYfReiNzDKm",
        "outputId": "9e849f84-6d84-41bb-a264-e7f087a83883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "id": "QnYfReiNzDKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All classifiers trained successfully.\n",
            "Evaluation complete.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Model  Accuracy Mean  Accuracy Std  Accuracy Median  \\\n",
              "0  LogisticRegression       0.742848      0.046359         0.735294   \n",
              "1        DecisionTree       0.687280      0.096798         0.650327   \n",
              "2        RandomForest       0.812945      0.079332         0.764706   \n",
              "3          GaussianNB       0.680684      0.044453         0.653595   \n",
              "4                 KNN       0.638828      0.068662         0.611111   \n",
              "5                 SVM       0.791280      0.040835         0.781046   \n",
              "6             XGBoost       0.811640      0.085974         0.774510   \n",
              "\n",
              "   Recall Mean  Recall Std  Recall Median  Precision Mean  Precision Std  \\\n",
              "0     0.742848    0.046359       0.735294        0.756782       0.045676   \n",
              "1     0.687280    0.096798       0.650327        0.696068       0.093068   \n",
              "2     0.812945    0.079332       0.764706        0.822176       0.073905   \n",
              "3     0.680684    0.044453       0.653595        0.705803       0.038073   \n",
              "4     0.638828    0.068662       0.611111        0.646472       0.071641   \n",
              "5     0.791280    0.040835       0.781046        0.799608       0.035450   \n",
              "6     0.811640    0.085974       0.774510        0.817087       0.083693   \n",
              "\n",
              "   Precision Median  \n",
              "0          0.753547  \n",
              "1          0.659223  \n",
              "2          0.777173  \n",
              "3          0.696893  \n",
              "4          0.630387  \n",
              "5          0.791265  \n",
              "6          0.783971  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d73e2969-662d-4df6-9e74-3e50bb163a61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Accuracy Median</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Recall Median</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>Precision Median</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.742848</td>\n",
              "      <td>0.046359</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.742848</td>\n",
              "      <td>0.046359</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.756782</td>\n",
              "      <td>0.045676</td>\n",
              "      <td>0.753547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.687280</td>\n",
              "      <td>0.096798</td>\n",
              "      <td>0.650327</td>\n",
              "      <td>0.687280</td>\n",
              "      <td>0.096798</td>\n",
              "      <td>0.650327</td>\n",
              "      <td>0.696068</td>\n",
              "      <td>0.093068</td>\n",
              "      <td>0.659223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.812945</td>\n",
              "      <td>0.079332</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.812945</td>\n",
              "      <td>0.079332</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.822176</td>\n",
              "      <td>0.073905</td>\n",
              "      <td>0.777173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.680684</td>\n",
              "      <td>0.044453</td>\n",
              "      <td>0.653595</td>\n",
              "      <td>0.680684</td>\n",
              "      <td>0.044453</td>\n",
              "      <td>0.653595</td>\n",
              "      <td>0.705803</td>\n",
              "      <td>0.038073</td>\n",
              "      <td>0.696893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.638828</td>\n",
              "      <td>0.068662</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.638828</td>\n",
              "      <td>0.068662</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.646472</td>\n",
              "      <td>0.071641</td>\n",
              "      <td>0.630387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.791280</td>\n",
              "      <td>0.040835</td>\n",
              "      <td>0.781046</td>\n",
              "      <td>0.791280</td>\n",
              "      <td>0.040835</td>\n",
              "      <td>0.781046</td>\n",
              "      <td>0.799608</td>\n",
              "      <td>0.035450</td>\n",
              "      <td>0.791265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.811640</td>\n",
              "      <td>0.085974</td>\n",
              "      <td>0.774510</td>\n",
              "      <td>0.811640</td>\n",
              "      <td>0.085974</td>\n",
              "      <td>0.774510</td>\n",
              "      <td>0.817087</td>\n",
              "      <td>0.083693</td>\n",
              "      <td>0.783971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d73e2969-662d-4df6-9e74-3e50bb163a61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d73e2969-662d-4df6-9e74-3e50bb163a61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d73e2969-662d-4df6-9e74-3e50bb163a61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c99de89-e1dd-4cf9-aeb7-3270f55e0658\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c99de89-e1dd-4cf9-aeb7-3270f55e0658')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c99de89-e1dd-4cf9-aeb7-3270f55e0658 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"experiment\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"LogisticRegression\",\n          \"DecisionTree\",\n          \"SVM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07023159201964846,\n        \"min\": 0.6388278152791171,\n        \"max\": 0.8129454623379406,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7428479588556735,\n          0.6872795456980606,\n          0.791280402871531\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022418785215148375,\n        \"min\": 0.04083474991104546,\n        \"max\": 0.09679823584884718,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.04635905007765238,\n          0.09679823584884718,\n          0.04083474991104546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0699558711313239,\n        \"min\": 0.6111111111111112,\n        \"max\": 0.7810457516339869,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7352941176470589,\n          0.6503267973856209,\n          0.7810457516339869\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07023159201964846,\n        \"min\": 0.6388278152791171,\n        \"max\": 0.8129454623379406,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7428479588556735,\n          0.6872795456980606,\n          0.791280402871531\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022418785215148375,\n        \"min\": 0.04083474991104546,\n        \"max\": 0.09679823584884718,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.04635905007765238,\n          0.09679823584884718,\n          0.04083474991104546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0699558711313239,\n        \"min\": 0.6111111111111112,\n        \"max\": 0.7810457516339869,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7352941176470589,\n          0.6503267973856209,\n          0.7810457516339869\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06805856362626252,\n        \"min\": 0.646472089165559,\n        \"max\": 0.8221759838984815,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.756782024153418,\n          0.6960679184811273,\n          0.7996076362196127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023116936735925443,\n        \"min\": 0.03544955790983071,\n        \"max\": 0.09306769191813657,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.045675522083485735,\n          0.09306769191813657,\n          0.03544955790983071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06510310241366583,\n        \"min\": 0.6303866984704039,\n        \"max\": 0.7912654637403874,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7535474181314084,\n          0.659222655196808,\n          0.7912654637403874\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131b2808-6a94-4c7e-b5e1-952832511e85",
      "metadata": {
        "id": "131b2808-6a94-4c7e-b5e1-952832511e85"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dea2210-71e8-4c09-8a20-347a24c61512",
      "metadata": {
        "id": "7dea2210-71e8-4c09-8a20-347a24c61512"
      },
      "source": [
        "Now we calculate the cross validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb09cd66-9c74-40d7-b566-8789fcac9c48",
      "metadata": {
        "id": "eb09cd66-9c74-40d7-b566-8789fcac9c48"
      },
      "outputs": [],
      "source": [
        "class_counts = target.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy_cross_val = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(y_train.value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "cross_val_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy_cross_val, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e64929b-894e-4eab-89a5-8f3511bbf8e2",
      "metadata": {
        "id": "5e64929b-894e-4eab-89a5-8f3511bbf8e2",
        "outputId": "f256a97b-0e15-4102-c8c1-f52e9f7ff6db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6409043854696029"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = cross_val_score(cross_val_clf, df.clean_events_sequence.sample(frac=1, random_state=1), target.sample(frac=1, random_state=1),\n",
        "                        cv=4, scoring='accuracy',n_jobs = -1)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a8558d-4b91-4f10-83fd-bb11738944f9",
      "metadata": {
        "id": "d9a8558d-4b91-4f10-83fd-bb11738944f9"
      },
      "source": [
        "Create a custom scoring f1 function with zero_division parameter for cross validation to avoid nan values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9e7a78-c871-4a73-b78c-a061d729ea16",
      "metadata": {
        "id": "4b9e7a78-c871-4a73-b78c-a061d729ea16"
      },
      "outputs": [],
      "source": [
        "# Create a custom scoring function with zero_division parameter\n",
        "def custom_f1_score(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "# Wrap the custom scoring function using make_scorer\n",
        "f1_scorer = make_scorer(custom_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7745109b-673e-4128-9d46-3cdab6b2da93",
      "metadata": {
        "id": "7745109b-673e-4128-9d46-3cdab6b2da93",
        "outputId": "db9c57cf-ad7c-4133-a2e8-a63fc21a047b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.61823676 0.61774323 0.65055584 0.57616849]\n",
            "0.615676079863001\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(cross_val_clf, df.clean_events_sequence.sample(frac=1, random_state=1), target.sample(frac=1, random_state=1),\n",
        "                        cv=4, scoring=f1_scorer,n_jobs = -1)\n",
        "print(scores)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d786ce5a-f7ea-4873-ad20-e37fb230e201",
      "metadata": {
        "id": "d786ce5a-f7ea-4873-ad20-e37fb230e201"
      },
      "source": [
        "F1 is calculated as:\n",
        "$$ F1 Score= 2\\frac{PrecisionRecall}{Precision+Recall}\n",
        "\n",
        "$$\n",
        "There are some minority classes with no correct predictions ($recall=0$) resulting in a null value for the whole f1 score when using a non-custom f1 scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091c8078-9125-4d27-9bb7-4324688918bf",
      "metadata": {
        "id": "091c8078-9125-4d27-9bb7-4324688918bf"
      },
      "source": [
        "## GridsearchCV\n",
        "Now we use gridsearchCV to find the optimal parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e22f86-1790-4f29-badb-3baefd9a084d",
      "metadata": {
        "scrolled": true,
        "id": "77e22f86-1790-4f29-badb-3baefd9a084d",
        "outputId": "45d3ded7-70c6-4033-b7e7-bd8e3d77f144"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{99: 222,\n",
              " 14: 196,\n",
              " 2: 166,\n",
              " 9: 164,\n",
              " 4: 125,\n",
              " 11: 73,\n",
              " 17: 57,\n",
              " 6: 53,\n",
              " 3: 52,\n",
              " 16: 51,\n",
              " 7: 51}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_counts = target.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "sampling_strategy_grid = {class_counts.index[i]: int(max_class_count * 0.15) + class_counts.values[i]\n",
        "                     for i in range(len(y_train.value_counts().index)) if class_counts.values[i] < max_class_count}\n",
        "sampling_strategy_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a495103-d65d-4f38-9dc9-c04afadd49b0",
      "metadata": {
        "id": "6a495103-d65d-4f38-9dc9-c04afadd49b0"
      },
      "outputs": [],
      "source": [
        "grid_clf = Pipeline([\n",
        "                    ('vect', CountVectorizer()),\n",
        "                    ('smote', SMOTE(sampling_strategy=sampling_strategy_grid, random_state=1, k_neighbors=2)),\n",
        "                    ('extra_trees', ExtraTreesClassifier()),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f0c64e-3389-44a4-8060-68f6b3405a5a",
      "metadata": {
        "id": "55f0c64e-3389-44a4-8060-68f6b3405a5a",
        "outputId": "d37d1752-0dca-4627-9c94-060ffb949066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__n_estimators': 300, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
            "Best Score F1: 0.6406886229518796\n",
            "Accuracy: 0.6548246439550787\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for GridSearchCV 15%\n",
        "param_grid = {\n",
        "    'vect__max_features': [500, 1000],       # Example parameter for CountVectorizer\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (1,3)],   # Unigrams, bigrams, trigrams\n",
        "    'extra_trees__n_estimators': [100, 200, 300, 400],        # Number of trees in ExtraTrees\n",
        "    'extra_trees__max_depth': [None, 10]        # Depth of each tree\n",
        "}\n",
        "\n",
        "# Cross-validation strategy set here to replicate results\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# Define GridSearchCV with the pipeline and parameter grid\n",
        "grid_search = GridSearchCV(grid_clf, param_grid, cv=cv, scoring=f1_scorer, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "grid_search.fit(df.clean_events_sequence, target)\n",
        "\n",
        "# Output the best parameters and the best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score F1:\", grid_search.best_score_)\n",
        "print(\"Accuracy:\", str(np.mean(cross_val_score(grid_search.best_estimator_, df.clean_events_sequence, target, cv=cv, scoring='accuracy'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc6c7f72",
      "metadata": {
        "id": "cc6c7f72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043c4514",
      "metadata": {
        "id": "043c4514"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b46fda7",
      "metadata": {
        "id": "4b46fda7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "137fe5af",
      "metadata": {
        "id": "137fe5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf6a4cf-1c8e-4aba-f74f-1c81c7aee5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.8.0)\n",
            "Requirement already satisfied: datashader in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.16.3)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.6.1)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (1.20.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.13.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.24.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (1.3.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (2024.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2024.2)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2.1.1)\n",
            "Requirement already satisfied: pyct in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2.32.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (0.12.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from holoviews->umap-learn[plot]) (1.5.3)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews->umap-learn[plot]) (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (3.2.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->umap-learn[plot]) (3.0.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->umap-learn[plot]) (1.16.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (1.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (8.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->datashader->umap-learn[plot]) (3.20.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask->datashader->umap-learn[plot]) (1.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->holoviews->umap-learn[plot]) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->holoviews->umap-learn[plot]) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->holoviews->umap-learn[plot]) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install hmmlearn umap-learn umap-learn[plot] xgboost imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a85fd88",
      "metadata": {
        "id": "8a85fd88"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from gensim.models import Word2Vec\n",
        "from hmmlearn import hmm\n",
        "import umap\n",
        "import umap.plot\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';')\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "cnXTFBgEyfAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "f7ebe9cc-b582-429d-b512-cd6148407110"
      },
      "id": "cnXTFBgEyfAS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  incident_id  \\\n",
              "895         895      4604847   \n",
              "384         384      4451781   \n",
              "690         690      4465347   \n",
              "970         970      4610465   \n",
              "389         389      4451923   \n",
              "\n",
              "                                     vehicles_sequence  \\\n",
              "895  [537, 537, 537, 537, 537, 537, 537, 537, 537, ...   \n",
              "384  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n",
              "690  [638, 638, 638, 638, 638, 638, 638, 638, 638, ...   \n",
              "970  [529, 529, 529, 529, 529, 529, 529, 529, 529, ...   \n",
              "389  [637, 637, 637, 637, 637, 637, 637, 637, 637, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "895  [3658, 4068, 3658, 4068, 3658, 4068, 3658, 406...   \n",
              "384  [4068, 3658, 4068, 3658, 4066, 3658, 4068, 365...   \n",
              "690  [2742, 4002, 4110, 2708, 4026, 4148, 4140, 412...   \n",
              "970  [4066, 4068, 4068, 3658, 4068, 3658, 4068, 365...   \n",
              "389  [3636, 3658, 2956, 2956, 4066, 3636, 3658, 295...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "895  [-14388, -14257, -14222, -14127, -14090, -1381...   50.782892   \n",
              "384  [-14137, -14078, -13904, -13892, -13519, -1258...   50.911038   \n",
              "690  [-8280, -8280, -8278, -8275, -8275, -8275, -82...   50.854381   \n",
              "970  [-14271, -14121, -13619, -13600, -13028, -1292...   50.720086   \n",
              "389  [-14397, -14397, -14342, -14284, -14241, -1422...   50.805012   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "895    4.421971  [0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, ...   \n",
              "384    4.151967  [0.2, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.2, ...   \n",
              "690    2.737718  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "970    4.397469  [1.6, 2.7, 3.2, 0.0, 0.1, 0.0, 1.8, 0.0, 1.0, ...   \n",
              "389    4.600712  [0.0, 0.0, 31.7, 25.0, 1.9, 0.0, 0.0, 22.0, 27...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "895  [False, False, False, False, False, False, Fal...   \n",
              "384  [False, False, False, False, False, False, Fal...   \n",
              "690  [False, False, False, False, False, False, Fal...   \n",
              "970  [False, False, False, False, False, False, Fal...   \n",
              "389  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "895  [True, True, True, True, True, True, True, Tru...              2  \n",
              "384  [True, True, True, True, True, True, True, Tru...              9  \n",
              "690  [False, False, False, False, False, False, Fal...             13  \n",
              "970  [True, True, True, True, True, True, True, Tru...              9  \n",
              "389  [True, True, True, True, True, True, True, Tru...             13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-421907d7-933a-4268-bd91-43ce33602e4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>895</td>\n",
              "      <td>4604847</td>\n",
              "      <td>[537, 537, 537, 537, 537, 537, 537, 537, 537, ...</td>\n",
              "      <td>[3658, 4068, 3658, 4068, 3658, 4068, 3658, 406...</td>\n",
              "      <td>[-14388, -14257, -14222, -14127, -14090, -1381...</td>\n",
              "      <td>50.782892</td>\n",
              "      <td>4.421971</td>\n",
              "      <td>[0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>384</td>\n",
              "      <td>4451781</td>\n",
              "      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n",
              "      <td>[4068, 3658, 4068, 3658, 4066, 3658, 4068, 365...</td>\n",
              "      <td>[-14137, -14078, -13904, -13892, -13519, -1258...</td>\n",
              "      <td>50.911038</td>\n",
              "      <td>4.151967</td>\n",
              "      <td>[0.2, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.2, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>690</td>\n",
              "      <td>4465347</td>\n",
              "      <td>[638, 638, 638, 638, 638, 638, 638, 638, 638, ...</td>\n",
              "      <td>[2742, 4002, 4110, 2708, 4026, 4148, 4140, 412...</td>\n",
              "      <td>[-8280, -8280, -8278, -8275, -8275, -8275, -82...</td>\n",
              "      <td>50.854381</td>\n",
              "      <td>2.737718</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>970</td>\n",
              "      <td>4610465</td>\n",
              "      <td>[529, 529, 529, 529, 529, 529, 529, 529, 529, ...</td>\n",
              "      <td>[4066, 4068, 4068, 3658, 4068, 3658, 4068, 365...</td>\n",
              "      <td>[-14271, -14121, -13619, -13600, -13028, -1292...</td>\n",
              "      <td>50.720086</td>\n",
              "      <td>4.397469</td>\n",
              "      <td>[1.6, 2.7, 3.2, 0.0, 0.1, 0.0, 1.8, 0.0, 1.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>389</td>\n",
              "      <td>4451923</td>\n",
              "      <td>[637, 637, 637, 637, 637, 637, 637, 637, 637, ...</td>\n",
              "      <td>[3636, 3658, 2956, 2956, 4066, 3636, 3658, 295...</td>\n",
              "      <td>[-14397, -14397, -14342, -14284, -14241, -1422...</td>\n",
              "      <td>50.805012</td>\n",
              "      <td>4.600712</td>\n",
              "      <td>[0.0, 0.0, 31.7, 25.0, 1.9, 0.0, 0.0, 22.0, 27...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-421907d7-933a-4268-bd91-43ce33602e4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-421907d7-933a-4268-bd91-43ce33602e4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-421907d7-933a-4268-bd91-43ce33602e4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff1541ee-f939-4c1a-ad82-5f92d3b451bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff1541ee-f939-4c1a-ad82-5f92d3b451bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff1541ee-f939-4c1a-ad82-5f92d3b451bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 274,\n        \"min\": 384,\n        \"max\": 970,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          384,\n          389,\n          690\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83080,\n        \"min\": 4451781,\n        \"max\": 4610465,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4451781,\n          4451923,\n          4465347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662]\",\n          \"[637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637]\",\n          \"[638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[4068, 3658, 4068, 3658, 4066, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 4068, 4068, 4068, 4066, 4068, 4066, 3658, 4066, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 3658, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4066, 4054, 4016, 4028, 4026, 4026, 4016, 4394, 4020, 4026, 3658, 4066, 3658, 4066, 3658, 4066, 4066, 3658, 4066, 4066, 3980, 4066, 4066, 4066, 4066, 4066, 4068, 4068, 4068, 4066, 4068, 4066, 4066, 4066, 4066, 4066, 4066, 4066, 3658, 4066, 4002, 2852, 4110, 2854, 4026, 4394, 952, 2708, 2744, 4148, 4026, 4030, 4018, 4140, 4152, 4168, 4156, 4130, 2742, 2658, 2684, 2688, 3234, 2942, 2742, 2946, 2742, 4406, 4408, 4412, 4410, 4148, 2852, 2854, 4120, 2858, 2708, 3254, 4180, 3254, 3254, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3234, 2658, 2684, 2688, 2974, 4100, 2882, 2882, 2886, 2682, 4120, 2686, 4120, 2956, 2956, 2956, 2956, 3982, 4048, 4066, 2736, 2708, 2708, 4020, 4026, 4028, 2708, 2744, 4026, 4148, 2740, 4396, 4030, 4020, 2972, 3236, 2976, 4100, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2684, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4068, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 4068, 3636, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 3982, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 4066, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4148, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2684, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 3980, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 3980, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 4016, 4026, 4028, 4026, 4016, 4020, 4026, 4066, 4066, 3980, 4066, 3658, 4066, 4066, 4066, 3980, 4066, 4066, 4066, 4066, 4066, 4068, 1872, 4068, 3658, 3874, 3822, 3862, 4068, 3658, 4066, 3658, 4068, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 3658, 4066, 4066]\",\n          \"[3636, 3658, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 4066, 4124, 4124, 4126, 4124, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2684, 2684, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 3254, 4180, 4000, 4080, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 3236, 2742, 4026, 4148, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2682, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3224, 4396, 4066, 3636, 3658, 2956, 2956, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 148, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2744, 4026, 4124, 4124, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3340, 4394, 3636, 3658, 3498, 3492, 4396, 3492, 4396, 4124, 3340, 4394, 3340, 4394, 2950, 4396, 2964, 4394, 942, 4180, 946, 960, 2950, 2964, 942, 960, 2950, 2708, 2744, 4124, 2950, 2964, 942, 960, 2708, 2744, 4168, 2708, 4140, 3986, 2744, 4004, 2852, 4110, 2854, 2708, 4026, 4140, 4140, 4148, 4140, 4152, 4168, 4156, 4406, 4410, 2740, 4408, 4412, 4124, 4030, 4018, 4026, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4396, 148, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4396, 148, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2682, 2682, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2682]\",\n          \"[2742, 4002, 4110, 2708, 4026, 4148, 4140, 4128, 4152, 4026, 4030, 4018, 4168, 4156, 4070, 2402, 2844, 2742, 4148, 4406, 4408, 4410, 4412, 4070, 4066, 4068, 3632, 4120, 3254, 4180, 4120, 2858, 2658, 2688, 4120, 2708, 2708, 2852, 2854, 4120, 2858, 2658, 2688, 3254, 4180, 2708, 4168, 4140, 3234, 3986, 2742, 4004, 2852, 4110, 2854, 2708, 4026, 4148, 4140, 4152, 4168, 4156, 2740, 4068, 2852, 2854, 4120, 2858, 2658, 2688, 3620, 3254, 4180, 4030, 4018, 4026, 2708, 2942, 2742, 3254, 4180, 4168, 4140, 3986, 4002, 2852, 4110, 2854, 4026, 2708, 2742, 4148, 4140, 4152, 2740, 4168, 4156, 3254, 4180, 4068, 2958, 2942, 3254, 4180, 2942, 2958, 3254, 4180, 3254, 3254, 3254, 3254, 2980, 4030, 4018, 4026, 2970, 4082, 4092, 4090, 4084, 4094, 4090, 3234, 2974, 4100, 2744, 4026, 3254, 4180, 2958, 4168, 4140, 3986, 4004, 2852, 4110, 2854, 4026, 2708, 2744, 4026, 4026, 4030, 4018, 2552, 4168, 4140, 4140, 4148, 4140, 4152, 4168, 4156, 4406, 4410, 4408, 4412, 2942, 2958, 3254, 4180, 3254, 3254]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[-14137, -14078, -13904, -13892, -13519, -12583, -12293, -12282, -12162, -12152, -12022, -12007, -11884, -11622, -11459, -11274, -10882, -10231, -9893, -9639, -9395, -9362, -9144, -9040, -8780, -8743, -8583, -8563, -8278, -8261, -7960, -7755, -7551, -7327, -7120, -6890, -6730, -6485, -4077, -4076, -4032, -4031, -3930, -3929, -3928, -3920, -3920, -3161, -2957, -2939, -2797, -2775, -2600, -2401, -2368, -2166, -1965, -1809, -1743, -1432, -1170, -956, -641, 3, 333, 735, 1088, 1722, 1917, 2103, 2321, 2604, 2768, 2920, 3083, 3105, 3435, -7218, -7215, -7215, -7213, -7212, -7167, -7167, -7026, -7026, -7026, -7017, -7017, -7016, -7002, -7000, -6976, -6974, -6875, -6483, -6452, -6452, -6452, -6451, -6299, -6264, -6219, -6170, -6153, -6151, -6151, -6150, -6138, -6071, -6069, -6066, -6003, -5990, -5907, -5906, -5845, -5843, -5823, -5788, -5788, -5787, -5759, -5759, -5758, -5703, -5662, -5662, -5662, -5596, -5592, -5240, -5236, -5230, -4444, -4444, -4361, -4305, -4235, -4221, -4212, -4139, -4089, -4073, -4073, -4072, -4071, -4052, -4029, -4028, -4028, -3926, -3926, -3926, -3926, -3921, -3920, -3918, -3917, -3855, -3805, -3667, -3665, -3157, -3122, -3058, -3041, -3034, -3032, -3030, -3013, -2992, -2987, -2954, -2935, -2901, -2885, -2871, -2849, -2844, -2837, -2836, -2825, -2824, -2822, -2814, -2794, -2771, -2682, -2675, -2649, -2634, -2630, -2596, -2572, -2496, -2493, -2472, -2467, -2462, -2437, -2435, -2432, -2398, -2364, -2330, -2326, -2323, -2320, -2287, -2275, -2247, -2245, -2243, -2217, -2203, -2199, -2163, -2143, -2143, -2066, -2063, -2030, -2019, -2017, -1961, -1943, -1943, -1885, -1882, -1834, -1832, -1815, -1804, -1802, -1801, -1778, -1777, -1740, -1718, -1718, -1686, -1643, -1640, -1637, -1607, -1605, -1563, -1561, -1527, -1519, -1483, -1468, -1465, -1459, -1428, -1412, -1412, -1359, -1341, -1329, -1326, -1319, -1309, -1302, -1284, -1270, -1248, -1234, -1207, -1203, -1181, -1175, -1167, -1119, -1119, -1080, -1077, -1064, -1056, -1026, -1024, -1014, -1012, -993, -988, -964, -952, -938, -938, -886, -880, -862, -860, -858, -843, -841, -838, -836, -806, -802, -796, -787, -783, -746, -745, -743, -721, -715, -699, -690, -650, -637, -516, -516, -497, -317, -284, -230, -228, -210, -208, -206, -185, -180, -151, -143, -132, -71, -50, 2, 6, 57, 57, 336, 346, 491, 513, 541, 567, 571, 574, 598, 603, 631, 635, 639, 683, 686, 709, 738, 779, 809, 829, 884, 901, 931, 939, 952, 981, 992, 995, 1005, 1015, 1017, 1023, 1026, 1028, 1053, 1057, 1091, 1107, 1141, 1148, 1169, 1171, 1178, 1183, 1188, 1193, 1217, 1222, 1230, 1231, 1233, 1236, 1243, 1255, 1266, 1272, 1289, 1305, 1312, 1325, 1346, 1350, 1366, 1387, 1388, 1408, 1426, 1429, 1469, 1471, 1480, 1481, 1511, 1516, 1518, 1528, 1530, 1537, 1551, 1560, 1567, 1574, 1583, 1587, 1612, 1626, 1641, 1690, 1713, 1721, 1726, 1757, 1811, 1813, 1814, 1865, 1867, 1885, 1920, 1947, 1985, 2002, 2048, 2061, 2063, 2106, 2142, 2232, 2272, 2287, 2288, 2325, 2348, 2442, 2485, 2514, 2529, 2542, 2574, 2579, 2607, 2630, 2667, 2673, 2710, 2722, 2742, 2771, 2788, 2831, 2853, 2924, 2945, 2988, 3006, 3009, 3086, 3109, 3202, 3205, 3257, 3259, 3265, 3271, 3299, 3322, 3365, 3398, 3406, 3438, 3526, -14389, -14370, -14335, -14326, -14284, -14240, -14202, -14193, -14135, -14076, -14011, -13983, -13972, -13946, -13935, -13934, -13902, -13890, -13798, -13786, -13747, -13701, -13658, -13643, -13636, -13629, -13616, -13597, -13555, -13552, -13518, -13516, -12581, -12542, -12526, -12520, -12469, -12442, -12408, -12400, -12394, -12392, -12350, -12341, -12339, -12292, -12280, -12217, -12205, -12203, -12161, -12151, -12079, -12065, -12054, -12020, -12005, -11989, -11961, -11945, -11913, -11910, -11896, -11883, -11858, -11858, -11844, -11814, -11778, -11767, -11753, -11728, -11689, -11655, -11644, -11643, -11620, -11602, -11602, -11583, -11525, -11516, -11457, -11434, -11434, -11415, -11368, -11367, -11323, -11313, -11301, -11273, -11254, -11254, -11240, -11182, -11016, -10979, -10976, -10973, -10925, -10922, -10907, -10905, -10881, -10861, -10861, -10816, -10816, -10790, -10743, -10731, -10729, -10717, -10692, -10690, -10689, -10680, -10673, -10668, -10667, -10658, -10646, -10643, -10634, -10622, -10621, -10611, -10580, -10578, -10570, -10568, -10532, -10530, -10512, -10492, -10490, -10470, -10453, -10448, -10426, -10413, -10406, -10390, -10372, -10366, -10359, -10348, -10337, -10335, -10332, -10331, -10323, -10318, -10293, -10289, -10283, -10278, -10271, -10255, -10252, -10230, -10217, -10217, -10171, -10167, -10141, -10140, -10136, -10130, -10128, -10116, -10104, -10100, -10084, -10049, -10036, -10030, -10010, -10003, -9929, -9891, -9638, -9595, -9560, -9556, -9528, -9526, -9523, -9502, -9500, -9496, -9483, -9478, -9474, -9458, -9454, -9449, -9431, -9427, -9394, -9361, -9337, -9316, -9311, -9289, -9273, -9270, -9254, -9251, -9246, -9234, -9229, -9176, -9169, -9143, -9038, -8988, -8979, -8967, -8952, -8943, -8942, -8904, -8903, -8891, -8886, -8884, -8850, -8848, -8846, -8841, -8829, -8826, -8823, -8810, -8808, -8804, -8779, -8741, -8689, -8683, -8656, -8654, -8644, -8641, -8619, -8612, -8610, -8582, -8562, -8444, -8442, -8415, -8407, -8405, -8384, -8372, -8355, -8349, -8340, -8332, -8329, -8319, -8307, -8276, -8259, -8239, -8211, -8205, -8199, -8144, -8136, -8101, -8099, -8056, -8054, -8033, -8021, -8019, -7989, -7968, -7959, -7940, -7940, -7904, -7900, -7875, -7863, -7848, -7846, -7844, -7816, -7805, -7802, -7753, -7720, -7720, -7650, -7648, -7616, -7605, -7603, -7550, -7509, -7509, -7464, -7459, -7433, -7413, -7411, -7384, -7378, -7375, -7354, -7353, -7347, -7331, -7326, -7301, -7301, -7241, -7240, -7238, -7214, -7203, -7200, -7183, -7181, -7180, -7160, -7149, -7146, -7141, -7119, -7057, -7057, -6963, -6957, -6940, -6935, -6930, -6924, -6922, -6921, -6889, -6875, -6875, -6830, -6823, -6813, -6801, -6794, -6783, -6778, -6766, -6757, -6728, -6705, -6694, -6694, -6640, -6609, -6590, -6587, -6584, -6558, -6523, -6484, -6471, -4075, -4030, -4030, -3928, -3927, -3919, -3919, -2956, -2796, -2650, -2599, -2574, -2400, -2165, -1963, -1806, -1742, -1430, -1169, -955, -640, 4, 67, 334, 344, 427, 621, 659, 736, 776, 1089, 1105, 1724, 1755, 1918, 1944, 2104, 2139, 2323, 2346, 2605, 2628, 2769, 2785, 2922, 2943, 3084, 3436]\",\n          \"[-14397, -14397, -14342, -14284, -14241, -14225, -14225, -14172, -14110, -14062, -14055, -14051, -14036, -14036, -13973, -13936, -13902, -13887, -13871, -13871, -13812, -13772, -13765, -13751, -13744, -13714, -13697, -13655, -13641, -13641, -13599, -13594, -13543, -13530, -13526, -13510, -13409, -13409, -13319, -13296, -13278, -13276, -13275, -13111, -13101, -13101, -13047, -13024, -13010, -13007, -12959, -12942, -12938, -12916, -12888, -12882, -12872, -12820, -12820, -12753, -12747, -12703, -12695, -12692, -12684, -12661, -12652, -12632, -12606, -12442, -12442, -12419, -12408, -12406, -12387, -12344, -12342, -12313, -12281, -12271, -12195, -12144, -12144, -12078, -12074, -12071, -12069, -12069, -12055, -12051, -12031, -11893, -11887, -11864, -11848, -11816, -11799, -11788, -11775, -11775, -11732, -11717, -11693, -11647, -11636, -11606, -11592, -11574, -11523, -11519, -11506, -11484, -11474, -11448, -11367, -11367, -11210, -11208, -11166, -11151, -11146, -11084, -11061, -11034, -10943, -10926, -10903, -10653, -10653, -10653, -10180, -10180, -10174, -10031, -10009, -9958, -9954, -9938, -9892, -9889, -9797, -9786, -9740, -9730, -9730, -9662, -9635, -9630, -9621, -9588, -9573, -9545, -9529, -9506, -9489, -9468, -9400, -9400, -9335, -9309, -9294, -9281, -9278, -9231, -9219, -9216, -9212, -9172, -9137, -9137, -9121, -9069, -9028, -9019, -8981, -8971, -8920, -8899, -8899, -8829, -8818, -8812, -8793, -8786, -8784, -8777, -8741, -8736, -8725, -8711, -8562, -8562, -8513, -8483, -8468, -8451, -8439, -8405, -8404, -8392, -8391, -8359, -8357, -8330, -8247, -8247, -8208, -8115, -8057, -8057, -8011, -8006, -7948, -7927, -7922, -7899, -7869, -7869, -7783, -7763, -7731, -7713, -7710, -7694, -7662, -7630, -7623, -7607, -7607, -7563, -7539, -7503, -7475, -7466, -7448, -7448, -7381, -7334, -7306, -7287, -7287, -7135, -7083, -7054, -7036, -7036, -6985, -6972, -6966, -6953, -6931, -6911, -6890, -6883, -6865, -6856, -6852, -6820, -6814, -6793, -6776, -6776, -6734, -6726, -6681, -6671, -6666, -6654, -6651, -6633, -6617, -6617, -6540, -6524, -6513, -6511, -6495, -6474, -6474, -6441, -6385, -6378, -6373, -6371, -6354, -6343, -6322, -6314, -6299, -6289, -6265, -6260, -6251, -6248, -6239, -6230, -6228, -6144, -6114, -6107, -6091, -6091, -6048, -6018, -6011, -5998, -5958, -5948, -5935, -5918, -5918, -5865, -5848, -5806, -5804, -5784, -5770, -5757, -5751, -5737, -5726, -5709, -5697, -5676, -5666, -5651, -5641, -5624, -5624, -5607, -5594, -5594, -5538, -5490, -5478, -5472, -5448, -5441, -5432, -5400, -5393, -5391, -5308, -5279, -5207, -5190, -5187, -5177, -5154, -5138, -5123, -5107, -5107, -5043, -5034, -5007, -4994, -4983, -4976, -4961, -4957, -4948, -4944, -4939, -4917, -4903, -4900, -4884, -4840, -4834, -4831, -4813, -4645, -4524, -4524, -4462, -4454, -4441, -4391, -4377, -4372, -4358, -4353, -4337, -4326, -4317, -4315, -4304, -4292, -4291, -4284, -4284, -4279, -4276, -4274, -4187, -4185, -4151, -4143, -4121, -4111, -4107, -4095, -4060, -3990, -3990, -3902, -3891, -3882, -3853, -3851, -3835, -3785, -3744, -3735, -3720, -3702, -3675, -3503, -3503, -3422, -3399, -3387, -3364, -3331, -3285, -3263, -3232, -3219, -3192, -3175, -3156, -3129, -3129, -3027, -2994, -2991, -2965, -2951, -2879, -2860, -2860, -2776, -2685, -2652, -2638, -2576, -2490, -2478, -2354, -2354, -1242, -1238, -989, -989, -814, -797, -780, -768, -737, -734, -679, -663, -636, -636, -522, -512, -418, -398, -398, -361, -329, -316, -299, -288, -266, -251, -217, -194, -193, -187, -171, -155, -91, -16, 2, 3, 21, 21, 39, 40, 40, 43, 44, 65, 120, 121, 188, 189, 218, 218, 219, 219, 220, 221, 221, 221, 377, 378, 379, 381, 470, 488, 494, 511, 548, 549, 550, 551, 650, 682, 837, 842, 854, 957, 1353, 1353, 1355, 1355, 1357, 1358, 1358, 1402, 1414, 1418, 1419, 1421, 1429, 1432, 1445, 1447, 1449, 1456, 1458, 1488, 1516, 1517, 1517, 1559, 1655, 1683, 1691, 1748, 1863, 2038, 2048, 2165, 2217, 2252, 2260, 2274, 2298, 2317, 2333, 2333, 2381, 2399, 2414, 2439, 2440, 2467, 2467, 2565, 2568, 2570, 2582, 2594, 2604, 2606, 2615, 2628, 2631, 2631, 2649, 2652, 2654, 2673, 2676, 2778, 2784, 2787, 2813, 3049, 3049, 3098, 3124, 3130, 3142, 3143, 3162, 3205, 3223, 3227, 3243, 3289, 3301, 3308, 3320, 3324, 3345, 3350, 3363, 3365, 3376, 3402, 3406, 3418, 3440, 3454, 3454, 3468, 3485, 3504, 3528, 3529, 3539, 3559, 3566, 3573, 3576]\",\n          \"[-8280, -8280, -8278, -8275, -8275, -8275, -8251, -8250, -8249, -8246, -8246, -8245, -8232, -8230, -8223, -8189, -8170, -2318, -2318, -2302, -2302, -2302, -2300, -2296, -2258, -2258, -2257, -2253, -2180, -2180, -2027, -1957, -1956, -1956, -1871, -1815, -1574, -1556, -1554, -1501, -1436, -1435, -1435, -1396, -1395, -1303, -1106, -1092, -1080, -1063, -855, -855, -853, -853, -851, -850, -850, -850, -806, -805, -792, -789, -776, -775, -743, -742, -734, -671, -670, -670, -670, -626, -626, -372, -371, -371, -140, -116, -48, 25, 25, 139, 152, 204, 383, 385, 385, 387, 389, 414, 414, 464, 481, 483, 511, 521, 523, 578, 578, 700, 800, 801, 1088, 1088, 1139, 1139, 1429, 1429, 1491, 1492, 1521, 1522, 1585, 1657, 1658, 1658, 1666, 1725, 1725, 1726, 1753, 1753, 1754, 1810, 1919, 1925, 2020, 2020, 2196, 2196, 2474, 2785, 2792, 2815, 3019, 3021, 3021, 3023, 3025, 3059, 3059, 3059, 3108, 3108, 3109, 3166, 3166, 3168, 3178, 3186, 3187, 3188, 3197, 3199, 3212, 3213, 3222, 3225, 3320, 3320, 3505, 3505, 3538, 3539]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07230675986104353,\n        \"min\": 50.72008567460733,\n        \"max\": 50.911038159911406,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          50.911038159911406,\n          50.80501206746032,\n          50.85438073536585\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.757322012560567,\n        \"min\": 2.737717975609756,\n        \"max\": 4.600712016349206,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1519667506090805,\n          4.600712016349206,\n          2.737717975609756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0.2, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.2, 0.0, 0.2, 0.0, 0.3, 0.2, 0.2, 0.0, 0.0, 0.7, 0.1, 0.0, 0.2, 0.0, 0.1, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.2, 0.2, 0.2, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 84.1, 0.2, 0.2, 0.1, 0.2, 0.0, 0.1, 0.0, 0.1, 0.2, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.1, 16.1, 17.2, 14.5, 0.0, 0.6, 0.4, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.1, 37.2, 36.5, 36.4, 36.2, 48.0, 58.4, 50.6, 0.1, 0.0, 24.9, 63.1, 86.4, 110.4, 105.3, 98.3, 97.1, 80.9, 78.5, 74.6, 53.4, 0.0, 0.0, 91.7, 98.6, 84.3, 62.0, 57.2, 0.1, 0.0, 94.7, 96.7, 114.3, 112.3, 110.6, 58.5, 54.8, 50.7, 0.0, 0.0, 11.9, 20.0, 24.5, 30.9, 88.0, 99.6, 114.4, 113.9, 112.7, 93.8, 62.9, 58.5, 0.0, 0.0, 0.0, 79.4, 78.8, 104.1, 97.5, 94.5, 0.0, 0.0, 0.0, 62.4, 66.5, 100.6, 98.7, 88.8, 83.8, 82.6, 81.9, 53.7, 51.8, 0.0, 0.0, 0.0, 16.1, 91.0, 90.1, 89.6, 97.3, 97.0, 99.4, 98.9, 94.2, 93.4, 78.2, 68.1, 64.3, 56.5, 0.1, 0.0, 0.0, 46.3, 85.9, 105.1, 107.3, 109.7, 113.3, 113.8, 85.7, 80.8, 83.0, 73.0, 56.2, 51.7, 23.1, 15.7, 0.1, 0.0, 0.0, 0.0, 0.0, 15.2, 30.1, 77.8, 77.9, 76.6, 76.7, 56.7, 48.5, 18.1, 0.1, 0.0, 0.0, 19.4, 34.9, 53.2, 53.8, 55.0, 57.5, 57.8, 57.4, 57.4, 55.6, 55.7, 55.6, 56.0, 54.7, 47.9, 47.6, 46.8, 37.0, 34.4, 27.9, 27.0, 11.6, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 36.0, 36.5, 37.2, 37.3, 37.4, 36.4, 36.2, 19.8, 16.3, 13.0, 3.9, 19.6, 6.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.5, 36.5, 35.5, 34.4, 37.3, 34.6, 34.0, 29.8, 29.3, 28.6, 28.3, 27.5, 18.1, 0.0, 0.0, 0.0, 23.2, 36.2, 40.4, 40.5, 50.5, 55.0, 89.2, 95.0, 98.0, 104.0, 96.9, 96.6, 91.8, 88.3, 86.8, 57.5, 50.0, 0.0, 0.0, 17.6, 34.3, 77.8, 82.3, 93.2, 101.0, 107.0, 112.3, 137.3, 141.9, 148.2, 149.2, 150.7, 152.5, 155.4, 156.7, 157.4, 155.9, 155.9, 155.7, 155.6, 157.1, 156.1, 157.4, 156.8, 155.9, 155.8, 155.9, 150.9, 147.3, 117.9, 118.3, 118.8, 118.8, 118.3, 112.8, 109.7, 93.7, 91.8, 85.6, 82.2, 83.5, 83.6, 84.1, 84.1, 83.4, 85.2, 79.2, 76.6, 56.4, 25.2, 7.0, 0.1, 0.0, 58.8, 58.6, 59.0, 60.0, 60.0, 58.9, 0.1, 0.0, 27.3, 69.4, 84.2, 72.2, 71.5, 0.1, 0.0, 95.8, 79.1, 64.1, 62.7, 0.0, 0.0, 105.5, 104.3, 90.7, 84.5, 82.2, 52.0, 42.3, 0.0, 0.0, 30.1, 47.0, 97.4, 82.4, 60.9, 0.1, 0.0, 21.3, 65.4, 0.0, 0.0, 42.7, 75.8, 79.5, 0.1, 0.0, 81.4, 85.1, 110.7, 107.5, 101.6, 93.6, 59.1, 35.5, 27.5, 25.5, 24.5, 0.0, 0.0, 39.0, 70.8, 118.3, 116.7, 115.4, 117.4, 114.8, 115.0, 0.1, 0.0, 38.9, 83.9, 97.6, 106.3, 84.4, 80.7, 0.0, 0.0, 92.3, 104.6, 113.3, 109.4, 113.3, 105.2, 99.2, 93.3, 78.2, 38.4, 36.0, 32.2, 0.0, 0.0, 0.0, 0.0, 15.2, 24.5, 38.9, 41.7, 82.8, 91.2, 99.3, 102.4, 117.9, 119.4, 119.0, 0.1, 0.0, 76.7, 90.4, 91.0, 0.2, 0.0, 65.6, 86.7, 97.2, 0.2, 0.0, 0.0, 48.3, 79.9, 83.5, 72.1, 35.9, 0.2, 0.0, 0.0, 0.0, 16.6, 86.0, 97.5, 97.6, 117.8, 115.0, 110.0, 76.8, 73.8, 0.1, 0.0, 0.0, 0.0, 106.7, 117.3, 0.1, 0.0, 0.0, 0.0, 61.7, 65.1, 100.6, 86.0, 58.7, 0.0, 0.0, 0.0, 0.0, 29.7, 0.0, 8.5, 15.8, 25.7, 71.6, 70.9, 61.0, 56.6, 0.0, 0.0, 0.0, 0.0, 0.0, 36.1, 82.9, 88.9, 88.8, 87.6, 86.3, 86.5, 86.8, 86.7, 85.6, 85.0, 85.0, 86.0, 85.8, 86.2, 86.9, 86.2, 86.2, 90.2, 115.7, 117.1, 122.5, 125.4, 153.0, 153.2, 155.1, 153.7, 153.5, 152.5, 146.5, 144.4, 152.4, 153.5, 153.7, 154.3, 154.3, 154.5, 154.3, 155.2, 154.0, 153.5, 150.7, 149.3, 142.9, 136.7, 109.1, 105.2, 104.9, 105.2, 95.6, 60.6, 55.1, 0.2, 0.0, 0.0, 36.3, 45.2, 84.5, 84.2, 84.1, 84.5, 84.5, 83.9, 82.0, 75.5, 58.4, 56.8, 57.9, 58.0, 39.9, 36.4, 34.7, 0.1, 0.0, 0.0, 21.7, 27.0, 37.0, 36.9, 37.0, 39.8, 39.9, 39.8, 43.0, 46.4, 46.4, 41.0, 41.2, 41.6, 31.5, 36.8, 0.2, 0.0, 0.0, 31.1, 39.6, 47.8, 48.3, 48.4, 47.9, 46.0, 41.2, 36.9, 35.1, 39.0, 38.7, 0.0, 0.0, 21.5, 38.0, 38.9, 47.1, 51.9, 52.2, 56.8, 56.3, 55.3, 55.0, 55.0, 51.5, 52.4, 51.8, 51.9, 56.9, 58.7, 61.7, 63.0, 61.9, 55.0, 0.1, 0.0, 16.1, 26.3, 72.7, 74.2, 78.3, 77.8, 65.2, 49.8, 44.7, 0.0, 0.0, 43.9, 49.3, 84.9, 83.6, 83.3, 85.9, 99.4, 115.9, 114.9, 113.2, 111.9, 112.4, 107.3, 88.8, 0.0, 0.0, 0.0, 22.7, 32.7, 43.4, 96.4, 94.7, 90.0, 90.2, 95.0, 94.3, 91.7, 89.7, 89.5, 70.5, 15.8, 0.0, 0.0, 0.0, 20.4, 30.1, 84.7, 102.9, 109.5, 109.9, 110.0, 99.8, 88.0, 83.6, 0.0, 0.0, 0.0, 88.9, 90.1, 101.8, 94.6, 91.3, 0.0, 0.0, 0.0, 39.5, 50.5, 93.6, 111.5, 111.4, 116.1, 116.0, 114.6, 84.6, 81.4, 62.1, 15.3, 0.2, 0.0, 0.0, 42.8, 46.4, 51.1, 93.5, 109.9, 112.2, 112.5, 112.0, 111.9, 107.8, 84.8, 72.7, 51.1, 0.2, 0.0, 0.0, 101.4, 107.7, 109.6, 107.7, 98.5, 81.8, 77.2, 72.5, 0.1, 0.0, 0.0, 19.5, 38.8, 60.6, 80.4, 90.2, 96.2, 94.7, 88.7, 76.2, 0.2, 0.0, 0.0, 0.0, 33.0, 36.5, 30.1, 29.9, 30.5, 34.4, 31.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.1, 83.3, 0.1, 0.0, 0.0, 0.1, 0.1, 83.5, 0.1, 0.2, 0.2, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 26.4, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.0]\",\n          \"[0.0, 0.0, 31.7, 25.0, 1.9, 0.0, 0.0, 22.0, 27.0, 17.1, 10.4, 0.8, 0.0, 0.0, 33.4, 54.7, 25.5, 0.5, 0.0, 0.0, 50.0, 51.0, 48.6, 51.2, 53.1, 55.9, 65.8, 0.4, 0.0, 0.0, 40.8, 52.1, 84.4, 67.2, 57.9, 0.9, 0.0, 0.0, 39.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.6, 72.0, 80.3, 80.5, 71.6, 57.1, 54.8, 54.1, 57.0, 40.1, 0.2, 0.0, 0.0, 41.9, 51.3, 93.8, 99.1, 100.1, 105.8, 114.8, 109.5, 81.9, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 17.2, 79.5, 81.0, 99.8, 102.3, 101.1, 0.3, 0.0, 0.0, 81.5, 87.6, 91.0, 93.6, 93.8, 9.9, 0.0, 0.0, 37.7, 42.1, 62.5, 54.6, 42.3, 29.6, 1.7, 0.0, 0.0, 25.1, 57.5, 56.3, 88.3, 96.3, 84.0, 65.0, 52.4, 53.7, 57.5, 55.7, 40.1, 29.7, 0.1, 0.0, 0.0, 83.6, 84.1, 63.9, 48.0, 43.1, 34.4, 35.5, 36.7, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.4, 35.2, 52.0, 50.6, 60.0, 77.6, 78.0, 90.3, 87.5, 2.2, 0.0, 0.0, 91.4, 115.9, 116.5, 107.5, 64.8, 70.9, 72.5, 62.4, 50.2, 30.2, 3.0, 0.0, 0.0, 46.6, 62.9, 83.4, 96.2, 98.0, 91.4, 83.7, 81.0, 76.6, 0.1, 0.0, 0.0, 0.0, 67.6, 116.2, 115.0, 115.0, 95.5, 0.0, 0.0, 0.0, 86.1, 96.6, 100.6, 113.0, 115.0, 114.6, 108.8, 76.8, 72.3, 47.5, 0.1, 0.0, 0.0, 12.0, 64.7, 77.4, 87.3, 88.9, 78.0, 78.6, 83.4, 83.2, 62.3, 59.7, 0.5, 0.0, 0.0, 11.7, 0.2, 0.0, 0.0, 30.9, 43.4, 66.0, 43.3, 40.9, 0.9, 0.0, 0.0, 54.0, 53.1, 45.2, 52.7, 53.9, 54.0, 42.5, 16.0, 0.7, 0.0, 0.0, 38.4, 51.1, 53.2, 27.8, 1.8, 0.0, 0.0, 32.6, 30.3, 0.2, 0.0, 0.0, 22.9, 27.3, 0.1, 0.0, 0.0, 37.6, 39.2, 37.9, 33.9, 20.5, 35.4, 44.0, 42.1, 36.8, 32.9, 33.4, 42.3, 42.1, 0.3, 0.0, 0.0, 19.9, 41.0, 75.0, 63.4, 56.0, 48.4, 44.4, 3.6, 0.0, 0.0, 69.8, 53.0, 32.7, 30.8, 0.9, 0.0, 0.0, 0.0, 12.4, 20.9, 34.6, 41.8, 67.6, 69.0, 60.3, 49.2, 40.4, 40.7, 37.4, 35.6, 34.2, 35.3, 42.6, 50.8, 50.2, 44.3, 22.2, 2.7, 0.0, 0.0, 41.8, 90.0, 94.9, 70.7, 36.0, 25.3, 0.2, 0.0, 0.0, 24.1, 37.3, 56.4, 55.2, 61.7, 75.0, 84.2, 89.8, 93.9, 91.0, 86.2, 94.4, 108.6, 109.4, 109.9, 98.2, 41.3, 40.9, 0.9, 0.0, 0.0, 37.7, 111.2, 122.5, 123.4, 145.6, 151.9, 155.3, 146.7, 144.6, 146.0, 24.5, 40.9, 46.8, 67.9, 67.5, 68.8, 69.6, 54.6, 0.7, 0.0, 0.0, 61.2, 73.3, 99.1, 98.7, 89.9, 89.3, 86.2, 85.6, 84.6, 84.7, 84.5, 79.3, 76.1, 73.2, 56.5, 38.8, 38.0, 37.7, 0.7, 0.0, 0.0, 0.0, 13.4, 14.7, 23.5, 80.8, 72.7, 74.6, 80.4, 81.9, 80.1, 87.6, 96.4, 99.7, 112.9, 126.8, 127.8, 130.7, 130.7, 128.8, 127.7, 127.5, 128.4, 128.0, 134.8, 134.8, 126.6, 109.8, 103.2, 78.2, 0.0, 0.0, 0.0, 97.1, 110.4, 119.4, 124.3, 124.0, 122.7, 129.9, 121.7, 105.4, 81.8, 54.9, 0.1, 0.0, 0.0, 79.2, 84.3, 83.4, 85.6, 85.3, 88.9, 85.9, 83.6, 82.9, 76.4, 48.2, 0.0, 0.0, 0.0, 77.9, 78.7, 78.5, 77.1, 73.8, 0.0, 0.0, 0.0, 76.1, 35.1, 29.5, 28.3, 29.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 72.8, 89.3, 96.9, 73.5, 70.3, 28.6, 0.0, 0.0, 0.0, 111.9, 110.7, 0.0, 0.0, 0.0, 13.4, 51.6, 66.2, 94.8, 107.3, 126.9, 123.3, 115.9, 106.5, 104.7, 99.6, 79.0, 62.3, 31.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.7, 19.0, 20.1, 21.0, 17.8, 17.4, 19.8, 18.8, 75.0, 124.7, 135.0, 124.4, 87.6, 43.2, 0.0, 0.0, 0.0, 55.9, 86.0, 108.2, 128.5, 129.5, 135.3, 135.3, 133.1, 133.4, 133.5, 135.3, 125.6, 103.8, 101.6, 91.1, 83.2, 79.8, 80.2, 62.9, 59.3, 55.7, 47.2, 47.4, 36.6, 32.9, 30.4, 0.1, 0.0, 0.0, 0.0, 16.6, 17.0, 17.4, 17.5, 27.2, 38.7, 67.6, 67.6, 52.6, 36.6, 38.8, 49.4, 70.7, 75.1, 82.2, 86.5, 83.4, 83.0, 95.1, 90.8, 85.3, 61.8, 0.1, 0.0, 0.0, 0.0, 25.3, 80.2, 103.5, 103.8, 116.5, 139.7, 142.9, 140.1, 138.9]\",\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 13,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          9,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events_list = []\n",
        "events_pre_incident = []\n",
        "events_post_incident = []\n",
        "\n",
        "for i, (events, seconds_to_incident_sequence, vehicles_sequence, train_kph_sequence, dj_ac_state_sequence, dj_dc_state_sequence) in tqdm(enumerate(zip(df[\"events_sequence\"],\n",
        "                                                                                                                                                      df[\"seconds_to_incident_sequence\"],\n",
        "                                                                                                                                                      df[\"vehicles_sequence\"],\n",
        "                                                                                                                                                      df[\"train_kph_sequence\"],\n",
        "                                                                                                                                                      df[\"dj_ac_state_sequence\"],\n",
        "                                                                                                                                                      df[\"dj_dc_state_sequence\"])), total=len(df)):\n",
        "    events = ast.literal_eval(events)\n",
        "    seconds_to_incident_sequence = ast.literal_eval(seconds_to_incident_sequence)\n",
        "    vehicles_sequence = ast.literal_eval(vehicles_sequence)\n",
        "    train_kph_sequence = ast.literal_eval(train_kph_sequence)\n",
        "    dj_ac_state_sequence = ast.literal_eval(dj_ac_state_sequence)\n",
        "    dj_dc_state_sequence = ast.literal_eval(dj_dc_state_sequence)\n",
        "\n",
        "\n",
        "    pre_incidents = []\n",
        "    pre_incidents_vehicles = []\n",
        "    pre_incidents_kph = []\n",
        "    pre_incidents_ac = []\n",
        "    pre_incidents_dc = []\n",
        "\n",
        "\n",
        "    post_incidents = []\n",
        "    post_incidents_vehicles = []\n",
        "    post_incidents_kph = []\n",
        "    post_incidents_ac = []\n",
        "    post_incidents_dc = []\n",
        "\n",
        "    event_seq = []\n",
        "    prev_event = 0\n",
        "\n",
        "    for event, time_to_incident, vehicle, kph, ac, dc in zip(events, seconds_to_incident_sequence, vehicles_sequence, train_kph_sequence, dj_ac_state_sequence, dj_dc_state_sequence):\n",
        "      #if event != prev_event:\n",
        "      event_seq.append(str(event))\n",
        "      if time_to_incident <= 0:\n",
        "          pre_incidents.append(str(event))\n",
        "          pre_incidents_vehicles.append(str(vehicle))\n",
        "          pre_incidents_kph.append(str(kph))\n",
        "          pre_incidents_ac.append(str(ac))\n",
        "          pre_incidents_dc.append(str(dc))\n",
        "      else:\n",
        "          post_incidents.append(str(event))\n",
        "          post_incidents_vehicles.append(str(vehicle))\n",
        "          post_incidents_kph.append(str(kph))\n",
        "          post_incidents_ac.append(str(ac))\n",
        "          post_incidents_dc.append(str(dc))\n",
        "      #prev_event = event\n",
        "\n",
        "    # Append the pre and post incident lists to the main lists\n",
        "    events_pre_incident.append(pre_incidents)\n",
        "    events_post_incident.append(post_incidents)\n",
        "    events_list.append(event_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs6FuHq84zef",
        "outputId": "4a43108b-c44f-41a1-d63a-b57faf758154"
      },
      "id": "Rs6FuHq84zef",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1011/1011 [00:15<00:00, 64.88it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "tuples_post = []\n",
        "tuples_pre = []\n",
        "\n",
        "for post_events in tqdm(events_post_incident):\n",
        "  prev_post_event = 0\n",
        "  for post_event in post_events:\n",
        "    if prev_post_event != 0:\n",
        "      tup = [prev_post_event, post_event]\n",
        "      prev_post_event = post_event\n",
        "      if tup not in tuples_post:\n",
        "        tuples_post.append(tup)\n",
        "    else:\n",
        "      prev_post_event = post_event\n",
        "\n",
        "for pre_events in tqdm(events_pre_incident):\n",
        "  prev_pre_event = 0\n",
        "  for pre_event in pre_events:\n",
        "    if prev_pre_event != 0:\n",
        "      tup = [prev_pre_event, pre_event]\n",
        "      prev_pre_event = pre_event\n",
        "      if tup not in tuples_pre:\n",
        "        tuples_pre.append(tup)\n",
        "    else:\n",
        "      prev_pre_event = pre_event"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOwIIe9Yi4VZ",
        "outputId": "bc7a36bf-6b46-4e3b-8d01-eac3b180621a"
      },
      "id": "oOwIIe9Yi4VZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1011/1011 [00:08<00:00, 123.91it/s]\n",
            "100%|| 1011/1011 [00:10<00:00, 97.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for post in tuples_post:\n",
        "  if post in tuples_pre:\n",
        "    c += 1\n",
        "c/len(tuples_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkg-WzIgoMcg",
        "outputId": "48063f99-b2cf-420d-983e-22676db0471b"
      },
      "id": "vkg-WzIgoMcg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4953556864521976"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for pre in tuples_pre:\n",
        "  if pre in tuples_post:\n",
        "    c += 1\n",
        "c/len(tuples_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7kfduUHpOgW",
        "outputId": "d915bf94-6cdd-47e6-d272-86b4e472d0d9"
      },
      "id": "t7kfduUHpOgW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4728078711212023"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_events_pre_incident = []\n",
        "tuples_removed = 0\n",
        "\n",
        "for prev_events in tqdm(events_pre_incident):\n",
        "  cleaned_events = []\n",
        "  prev_pre_event = 0\n",
        "  for pre_event in prev_events:\n",
        "    if prev_pre_event != 0:\n",
        "      tup = [prev_pre_event, pre_event]\n",
        "      if tup not in tuples_post:\n",
        "        cleaned_events.append(prev_pre_event)\n",
        "      else:\n",
        "        tuples_removed += 1\n",
        "    else:\n",
        "      prev_pre_event = pre_event\n",
        "  cleaned_events.append(pre_event)\n",
        "  cleaned_events_pre_incident.append(cleaned_events)\n",
        "cleaned_events_pre_incident[0]"
      ],
      "metadata": {
        "id": "Q_tE3kjAqKQj",
        "outputId": "aa5a0981-ffc9-4c4f-d11e-26e768e6c7a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Q_tE3kjAqKQj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1011/1011 [01:07<00:00, 14.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "cleaned_events_pre_incident = []\n",
        "tuples_removed = 0\n",
        "\n",
        "for prev_events in tqdm(events_pre_incident):\n",
        "    cleaned_events = []\n",
        "    prev_pre_event = None  # Usa None para identificar el primer elemento\n",
        "\n",
        "    for pre_event in prev_events:\n",
        "        if prev_pre_event is not None:\n",
        "            tup = [prev_pre_event, pre_event]\n",
        "\n",
        "            if tup not in tuples_post:\n",
        "                cleaned_events.append(prev_pre_event)\n",
        "            else:\n",
        "                tuples_removed += 1\n",
        "\n",
        "        prev_pre_event = pre_event\n",
        "\n",
        "    if prev_pre_event is not None:\n",
        "        cleaned_events.append(prev_pre_event)\n",
        "    cleaned_events_pre_incident.append(cleaned_events)\n",
        "\n",
        "cleaned_events_pre_incident[0]\n"
      ],
      "metadata": {
        "id": "k5rmXT4TzJmN",
        "outputId": "18052d69-92fb-4ad3-845c-66237f4b36c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k5rmXT4TzJmN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1011/1011 [00:16<00:00, 60.09it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1132',\n",
              " '4026',\n",
              " '1082',\n",
              " '2742',\n",
              " '4092',\n",
              " '2982',\n",
              " '1250',\n",
              " '1250',\n",
              " '2982',\n",
              " '4394',\n",
              " '2708',\n",
              " '3036',\n",
              " '3986']"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuples_removed"
      ],
      "metadata": {
        "id": "uWmUMWstu2eT",
        "outputId": "54145744-b8a4-4736-cbcf-41c4b02cdcb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uWmUMWstu2eT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191311"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"incident_type\").count()[\"incident_id\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "SLY3DamcRZf5",
        "outputId": "f2b2edae-be83-4b96-f667-ead715f7fa60"
      },
      "id": "SLY3DamcRZf5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "incident_type\n",
              "2     119\n",
              "3       5\n",
              "4      78\n",
              "6       6\n",
              "7       4\n",
              "9     117\n",
              "11     26\n",
              "13    318\n",
              "14    149\n",
              "16      4\n",
              "17     10\n",
              "99    175\n",
              "Name: incident_id, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = []\n",
        "for events in cleaned_events_pre_incident:\n",
        "  lens.append(len(events))\n",
        "print(np.mean(lens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSmmOtV7iiu1",
        "outputId": "07185d16-be85-4c8b-b5fc-1de533382930"
      },
      "id": "oSmmOtV7iiu1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.22650840751731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 4\n",
        "word2vec = Word2Vec(sentences=cleaned_events_pre_incident, vector_size=vector_size, window=9, sg=1, min_count=4, workers=-1)\n",
        "embeddings = []\n",
        "labels = df[\"incident_type\"]\n",
        "actual_events = []\n",
        "\n",
        "for events in tqdm(cleaned_events_pre_incident):\n",
        "  embedding = np.zeros(vector_size)\n",
        "  denominator = 0\n",
        "  for event in events:\n",
        "    if event in word2vec.wv:\n",
        "      embedding += word2vec.wv[event]\n",
        "      denominator += 1\n",
        "\n",
        "  embeddings.append(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgIbXBmK8c3M",
        "outputId": "fde2a02b-9c13-4281-fcef-8073a22b2a88"
      },
      "id": "kgIbXBmK8c3M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (0) did not equal expected count (1011)\n",
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied raw word count (0) did not equal expected count (9328)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (0) did not equal expected count (1011)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied raw word count (0) did not equal expected count (9328)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (0) did not equal expected count (1011)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied raw word count (0) did not equal expected count (9328)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (0) did not equal expected count (1011)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied raw word count (0) did not equal expected count (9328)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (0) did not equal expected count (1011)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied raw word count (0) did not equal expected count (9328)\n",
            "100%|| 1011/1011 [00:00<00:00, 24517.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoders = {\n",
        "            'CountVectorizer': CountVectorizer(),\n",
        "            'TfidfVectorizer': TfidfVectorizer()\n",
        "        }\n",
        "embedding_methods = {}\n",
        "data = [\" \".join(sentence) for sentence in events_pre_incident]\n",
        "for name, encoder in tqdm(encoders.items()):\n",
        "    embedding_methods[name] = encoder.fit_transform(data).toarray()"
      ],
      "metadata": {
        "id": "e1mwYV83eq-5",
        "outputId": "79b950bb-fbd3-4e04-ab7c-387e7fee8a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e1mwYV83eq-5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 2/2 [00:02<00:00,  1.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "umap_model = umap.UMAP(n_components=2, min_dist=0.1, n_neighbors=200, metric='euclidean')\n",
        "X_umap = umap_model.fit_transform(embedding_methods[\"TfidfVectorizer\"])\n",
        "umap.plot.points(umap_model, labels=df[\"incident_type\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "DdZrSzNI6QnD",
        "outputId": "74aee04c-9cfb-4387-ec79-b3da952e1217"
      },
      "id": "DdZrSzNI6QnD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "X = embedding_methods[\"TfidfVectorizer\"]\n",
        "y = encoded_labels\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert y_train to a Series to easily compute class counts\n",
        "y_train_series = pd.Series(y_train)\n",
        "class_counts = y_train_series.value_counts()\n",
        "max_class_count = max(class_counts.values)\n",
        "\n",
        "# Define the sampling strategy for SMOTE\n",
        "sampling_strategy = {cls: int(max_class_count * 0.20) + count\n",
        "                     for cls, count in class_counts.items() if count < max_class_count}\n",
        "\n",
        "print('Original training dataset shape:', Counter(y_train))\n",
        "\n",
        "# Apply SMOTE only to the training set\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print('Resampled training dataset shape:', Counter(y_train_res))\n",
        "print('Original test dataset shape:', Counter(y_test))\n"
      ],
      "metadata": {
        "id": "pkdYB_LJepcB",
        "outputId": "f8bfd659-c16a-479c-b4e0-5c8fac4a159b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pkdYB_LJepcB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training dataset shape: Counter({7: 254, 11: 130, 8: 118, 0: 99, 5: 95, 2: 68, 6: 18, 10: 7, 3: 6, 1: 5, 9: 4, 4: 4})\n",
            "Resampled training dataset shape: Counter({7: 254, 11: 180, 8: 168, 0: 149, 5: 145, 2: 118, 6: 68, 10: 57, 3: 56, 1: 55, 9: 54, 4: 54})\n",
            "Original test dataset shape: Counter({7: 64, 11: 45, 8: 31, 5: 22, 0: 20, 2: 10, 6: 8, 10: 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = CountVectorizer().fit_transform(X_train).toarray()\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=1, k_neighbors=2)\n",
        "X_train_res, y_train_res = smote.fit_resample(embeddings, y_train)\n",
        "X_test_res = CountVectorizer().fit_transform(X_test).toarray()\n"
      ],
      "metadata": {
        "id": "UGZEX19Lm8jq"
      },
      "id": "UGZEX19Lm8jq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(data=X_train_res, label=y_train_res)\n",
        "dtest = xgb.DMatrix(data=X_test_res, label=y_test)\n",
        "num_classes = len(np.unique(labels))\n",
        "params = {\n",
        "    'objective': 'multi:softmax',   # Cambiar a 'multi:softprob' si necesitas probabilidades en lugar de etiquetas\n",
        "    'num_class': num_classes,       # Nmero de clases\n",
        "    'max_depth': 4,                 # Profundidad mxima del rbol\n",
        "    'learning_rate': 0.1,           # Tasa de aprendizaje\n",
        "    'n_estimators': 100,            # Nmero de rboles\n",
        "    'eval_metric': 'mlogloss'       # Mtrica para clasificacin multiclase\n",
        "}\n",
        "num_rounds = 100\n",
        "#bst = xgb.train(params, dtrain, num_rounds)\n",
        "bst = ExtraTreesClassifier().fit(X_train_res, y_train_res)\n",
        "predictions = bst.predict(X_test_res)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "CriDx-7ZaqZ1",
        "outputId": "5bf71efa-7310-41a2-954e-fb652d8e56ac"
      },
      "id": "CriDx-7ZaqZ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "X has 576 features, but ExtraTreesClassifier is expecting 864 features as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-d6dae3627f2c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#bst = xgb.train(params, dtrain, num_rounds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 576 features, but ExtraTreesClassifier is expecting 864 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f6f454",
      "metadata": {
        "id": "a6f6f454"
      },
      "outputs": [],
      "source": [
        "class SCNB:\n",
        "    def __init__(self):\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(),\n",
        "        }\n",
        "        self.models = {}\n",
        "        self.embedding_methods = {}\n",
        "        self.ensemble_model = None\n",
        "        self.hmm_model = None\n",
        "\n",
        "    def train_classifiers(self, X, y):\n",
        "        \"\"\"Entrena cada clasificador popular junto con XGBoost.\"\"\"\n",
        "        for name, clf in self.classifiers.items():\n",
        "            clf.fit(X, y)\n",
        "            self.models[name] = clf\n",
        "        print(\"All classifiers trained successfully.\")\n",
        "\n",
        "    def reset_models(self):\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(),\n",
        "        }\n",
        "\n",
        "    def generate_embeddings(self, words_list):\n",
        "        \"\"\"Genera embeddings para una lista de palabras usando distintos encoders.\"\"\"\n",
        "        encoders = {\n",
        "            'CountVectorizer': CountVectorizer(),\n",
        "            'OneHotEncoder': OneHotEncoder(sparse=False),\n",
        "            'TfidfVectorizer': TfidfVectorizer()\n",
        "        }\n",
        "\n",
        "        for name, encoder in encoders.items():\n",
        "            self.embedding_methods[name] = encoder.fit_transform(words_list).toarray()\n",
        "\n",
        "        word2vec_model = Word2Vec(sentences=[words_list], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        self.embedding_methods['Word2Vec'] = [word2vec_model.wv[word] for word in words_list if word in word2vec_model.wv]\n",
        "        print(\"Embeddings generated successfully.\")\n",
        "\n",
        "    def evaluate_models(self, X, y):\n",
        "        results = []\n",
        "        skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "        for name, model in tqdm(self.classifiers.items()):\n",
        "            accuracies, recalls, precisions = [], [], []\n",
        "            for train_index, test_index in skf.split(X, y):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "                accuracies.append(accuracy_score(y_test, y_pred))\n",
        "                recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "                precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "            results.append({\n",
        "                'Model': name,\n",
        "                'Accuracy Mean': np.mean(accuracies),\n",
        "                'Accuracy Std': np.std(accuracies),\n",
        "                'Accuracy Median': np.median(accuracies),\n",
        "                'Recall Mean': np.mean(recalls),\n",
        "                'Recall Std': np.std(recalls),\n",
        "                'Recall Median': np.median(recalls),\n",
        "                'Precision Mean': np.mean(precisions),\n",
        "                'Precision Std': np.std(precisions),\n",
        "                'Precision Median': np.median(precisions),\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        return results_df\n",
        "\n",
        "    def train_ensemble_model(self, weights=None):\n",
        "        \"\"\"Crea y entrena un modelo de ensamblaje usando los mejores modelos entrenados.\"\"\"\n",
        "        estimators = [(name, model) for name, model in self.models.items()]\n",
        "        self.ensemble_model = VotingClassifier(estimators=estimators, voting='soft', weights=weights)\n",
        "        print(\"Ensemble model created successfully.\")\n",
        "\n",
        "    def train_hidden_markov_model(self, X, n_components=2):\n",
        "        \"\"\"Entrena un modelo Hidden Markov.\"\"\"\n",
        "        self.hmm_model = hmm.GaussianHMM(n_components=n_components)\n",
        "        self.hmm_model.fit(X)\n",
        "        print(\"Hidden Markov Model trained successfully.\")\n",
        "\n",
        "    def analyze_hmm(self):\n",
        "        \"\"\"Analiza el modelo Hidden Markov mostrando matrices de transicin y dems estadsticas.\"\"\"\n",
        "        if self.hmm_model:\n",
        "            print(\"Transition matrix:\", self.hmm_model.transmat_)\n",
        "            print(\"Means:\", self.hmm_model.means_)\n",
        "            print(\"Covars:\", self.hmm_model.covars_)\n",
        "        else:\n",
        "            print(\"HMM model not trained yet.\")\n",
        "\n",
        "    def dimensionality_reduction_with_umap(self, X, y, min_dist_values=[0.1, 0.5], n_neighbors_values=[5, 10]):\n",
        "        \"\"\"Aplica reduccin de dimensionalidad usando UMAP y muestra scatter plots.\"\"\"\n",
        "        for min_dist in min_dist_values:\n",
        "            for n_neighbors in n_neighbors_values:\n",
        "                umap_model = umap.UMAP(min_dist=min_dist, n_neighbors=n_neighbors)\n",
        "                X_umap = umap_model.fit_transform(X)\n",
        "\n",
        "                scatter_matrix(pd.DataFrame(X_umap), alpha=0.2, figsize=(10, 10), diagonal='kde', c=y)\n",
        "                plt.title(f\"UMAP Clustering (min_dist={min_dist}, n_neighbors={n_neighbors})\")\n",
        "                plt.show()\n",
        "\n",
        "        print(\"Dimensionality reduction with UMAP completed.\")\n",
        "\n",
        "    def clustering_with_algorithms(self, X, y):\n",
        "        \"\"\"Realiza clustering usando algoritmos populares y muestra scatter plots.\"\"\"\n",
        "        clusterers = {\n",
        "            'KMeans': KMeans(n_clusters=len(np.unique(y))),\n",
        "            'Agglomerative': AgglomerativeClustering(n_clusters=len(np.unique(y))),\n",
        "            'DBSCAN': DBSCAN()\n",
        "        }\n",
        "\n",
        "        for name, clusterer in clusterers.items():\n",
        "            clusters = clusterer.fit_predict(X)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            scatter_matrix(pd.DataFrame(X), alpha=0.2, figsize=(10, 10), diagonal='kde', c=clusters)\n",
        "            plt.title(f\"Clustering with {name}\")\n",
        "            plt.show()\n",
        "\n",
        "        print(\"Clustering with various algorithms completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67650822",
      "metadata": {
        "id": "67650822"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "# Supongamos que tienes un DataFrame `df` con variables `X` y `y` definidas.\n",
        "\n",
        "# Crear instancia de SCNB\n",
        "scnb = SCNB()\n",
        "\n",
        "# Entrenar clasificadores\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "scnb.train_classifiers(X, y)\n",
        "\n",
        "# Generar embeddings para una lista de palabras\n",
        "words_list = [\"gato\", \"perro\", \"pez\", \"pjaro\"]\n",
        "scnb.generate_embeddings(words_list)\n",
        "\n",
        "# Evaluar modelos\n",
        "results_df = scnb.evaluate_models(X, y)\n",
        "print(results_df)\n",
        "\n",
        "# Entrenar modelo de ensamblaje\n",
        "scnb.train_ensemble_model()\n",
        "\n",
        "# Entrenar y analizar un modelo HMM\n",
        "scnb.train_hidden_markov_model(X)\n",
        "scnb.analyze_hmm()\n",
        "\n",
        "# Red\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}