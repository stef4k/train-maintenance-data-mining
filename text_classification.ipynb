{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stef4k/train-maintenance-data-mining/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Importation"
      ],
      "metadata": {
        "id": "vXgvhkss9klA"
      },
      "id": "vXgvhkss9klA"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9",
      "metadata": {
        "id": "a04bb8ce-c910-492e-b169-c9cd7952bef9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import ast\n",
        "import pickle\n",
        "from joblib import Parallel, delayed\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import parallel_backend\n",
        "import threading\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Experiment`\n",
        "\n",
        "This class is a pipeline that automates the process of training and testing using cross-validation and prepares the system for ensemble evaluations. This class was developed as pipeline to do experiments more easily, since we want to test all possible model, sampling strategies and vectorizers available.\n",
        "\n",
        "One main limitation is the business knowledge we have, since we don not really understand at a very specific level this dataset, like what exactly each incident is, or what does each event in the events sequence represent, we didn't take any apriori assumtios of the data, and we decided to find by bute force what is the best vectorizer, sampling strategy and model for the given dataset. Additionally, we also tested different representations of the sequences in an attempt of removing any noise we were not aware of. These kinds of knowledge limitations impacted on the results we presented since we are treating the dataset as a black box in certain aspects.\n",
        "\n",
        "For the experiments, we are trateing the sequences of events as if they were words in a text. Therefore, we treated this problem as text classification and defined the pipeline as such. Therefore, we will test the **TFIDF Vectorier, Count Vectorizer and Word2Vec** to understand whichone can infere the best embedding space for the provided event sequences.\n",
        "\n",
        "Since we are dealing with a very small data sample (around 1k observations) we wanted to train our models in oversampled data using different sampling methods and find our which can improve the models performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`__init__(self, X, y)`**\n",
        "\n",
        "This class is initialized with the training data and the target column. Whithin this method it:\n",
        "  - Splits `X` (features) and `y` (labels) into training and test sets using **stratified sampling** to ensure class balance.\n",
        "  - Encodes categorical labels (`y`) into numerical values using `LabelEncoder`.\n",
        "\n",
        "We also initialize the following attributes to be accessible in all parts of the pipeline:\n",
        "  - **`self.X_train`, `self.X_test`, `self.y_train`, `self.y_test`:** Prepared splits for training and testing.\n",
        "  - **`self.trai`ed_models` and `self.trained_vectorizers`:** Empty dictionaries to store trained models and vectorizers.\n",
        "  - **`self.results`:** Stores evaluation results for comparison.\n",
        "  - **`sampling_strategies`:** A dictionary of techniques to handle class imbalance, we are using `SMOTE`, `Borderline-SMOTE`, `ADASYN`, `RandomOversampler`, `SMOTE-ENN`, `SMOTE-Tomek`.\n",
        "  - **`vectorizers`:** A dictionary of methods for text representation, we are using `TFIDF`, `Count`,`Word2Vec`\n",
        "  - **`classifiers`:** A set of preconfigured machine learning models, such as `LogisticRegression`,`DecisionTree`,`RandomForest`,`ExtraTreesClassifier`,`GradientBoostingClassifier`,`AdaBoostClassifier`,`GaussianNB`,`KNN`,`SVM`,`XGBoost`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`duplicate_minor_classes(self, X, y, min_instances=5)`**\n",
        "\n",
        "Balances the dataset by duplicating underrepresented classes until they meet the minimum instance threshold.\n",
        "\n",
        "1. Identifies **minor classes** with fewer samples than `min_instances`.\n",
        "2. Duplicates rows corresponding to these classes.\n",
        "3. Merges the duplicated data back with the original dataset.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name)`**\n",
        "\n",
        "Using cross-validation it evaluates a single combination of **Model**, **Vectorizer** and **Sampler**. It returns a list of evaluation metrics (mean and standard deviation) for the specified combination.\n",
        "\n",
        "1. Splits `X` and `y` into 5 folds using **StratifiedKFold**.\n",
        "2. For each fold:\n",
        "   - Transforms the data with the given vectorizer.\n",
        "   - Balances the data using the sampler.\n",
        "   - Trains the model on the resampled training data.\n",
        "   - Predicts on the validation data.\n",
        "3. Calculates metrics:\n",
        "   - Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1 Score\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **`training(self)`**\n",
        "\n",
        "Runs experiments for all combinations of **Model**, **Vectorizer** and **Sampler**.\n",
        "\n",
        "1. Balances the training data using `duplicate_minor_classes`.\n",
        "2. Constructs a task list of all vectorizer-sampler-model combinations.\n",
        "3. Uses parallel processing to execute each task:\n",
        "   - For each combination, calls `test()` to evaluate.\n",
        "4. Aggregates results into a DataFrame for easy comparison.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_task(self, task, progress_bar)`**\n",
        "\n",
        "Handles a single task from the `training()` pipeline to run it in parallel. Returns evaluation metrics for the task.\n",
        "\n",
        "1. Unpacks the task (vectorizer, sampler, model).\n",
        "2. Executes `test()` for the task.\n",
        "3. Updates the progress bar.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`test_ensemble(self)`**\n",
        "\n",
        "Evaluates the performance of an ensemble model across multiple folds. Returns evaluation metrics for the ensemble model.\n",
        "\n",
        "1. Splits the data using `StratifiedKFold`.\n",
        "2. For each fold:\n",
        "   - Trains all models, vectorizers, and samplers on the training data.\n",
        "   - Constructs an ensemble model using `EnsembleModel`.\n",
        "   - Tests the ensemble on the validation set.\n",
        "3. Calculates metrics for the ensembleâ€™s performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **`_process_fold(self, X_train, X_test, y_train, y_test)`**\n",
        "\n",
        "Handles training and evaluation for a single fold in `test_ensemble` to be executed in parallel along all other folds. Returns evaluation metrics for the ensemble model for that fold.\n",
        "\n",
        "1. Trains all vectorizers and models on the training data.\n",
        "2. Stores trained models and vectorizers for the fold.\n",
        "3. Fits an ensemble model on the predictions.\n",
        "4. Evaluates the ensemble on the validation set.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fr_q4Q0M63DE"
      },
      "id": "Fr_q4Q0M63DE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Word2VecVectorizer`\n",
        "This class converts sentences into numerical vectors using Word2Vec, which captures the semantic meaning of words. This class was defined to provide an interface similar to Scikit-Learn interface and avoid syntaxis issues later on in the `Experiment` class.\n",
        "\n",
        " - `__init__`: Lets you configure how the Word2Vec model works:\n",
        "   - `size` is the number of dimensions for word vectors (e.g., 100-dimensional space).\n",
        "   - `window` is the maximum distance between the current and predicted words.\n",
        "   - `min_count` is the minimum number of times a word must appear to be included in the model.\n",
        "   - `workers` determines how many CPU threads to use for training (faster with more workers).\n",
        " - `fit`: Takes a list of sentences, splits them into words, and trains a Word2Vec model to learn relationships between words.\n",
        " - `transform`: Takes sentences and converts them into vectors. It does this by averaging the vectors of all words in a sentence. If a word isn't in the Word2Vec model, it is ignored, and zeros are used instead.\n",
        " - `fit_transform`: A convenience method that combines the `fit` (training) and `transform` (vectorizing) steps.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SgzoRMgu6W0K"
      },
      "id": "SgzoRMgu6W0K"
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(TransformerMixin):\n",
        "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
        "        self.size = size\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.w2v_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        sentences = [sentence.split() for sentence in X]\n",
        "        self.w2v_model = Word2Vec(sentences, vector_size=self.size, window=self.window,\n",
        "                                  min_count=self.min_count, workers=self.workers)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_data = np.array([\n",
        "            np.mean([self.w2v_model.wv[word] for word in sentence.split() if word in self.w2v_model.wv]\n",
        "                    or [np.zeros(self.\n",
        "                                 size)], axis=0)\n",
        "            for sentence in X\n",
        "        ])\n",
        "        return csr_matrix(transformed_data)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "metadata": {
        "id": "fOHHiU-pDaet"
      },
      "id": "fOHHiU-pDaet",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoSampler(TransformerMixin):\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return X, y\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X, y\n",
        "\n",
        "    def fit_resample(self, X, y=None):\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "B4W8MlJVFVf-"
      },
      "id": "B4W8MlJVFVf-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.le = LabelEncoder()\n",
        "        self.y = self.le.fit_transform(y)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "        self.y_train = self.le.transform(self.y_train)\n",
        "        self.y_test = self.le.transform(self.y_test)\n",
        "        self.trained_models = {}\n",
        "        self.trained_vectorizers = {}\n",
        "        self.trainer_samplers = {}\n",
        "        self.results = []\n",
        "        self.sampling_strategies = {\n",
        "            \"SMOTE\": SMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"Borderline-SMOTE\": BorderlineSMOTE(sampling_strategy='auto', random_state=1, k_neighbors=3),\n",
        "            \"ADASYN\": ADASYN(sampling_strategy='auto', random_state=1, n_neighbors=3),\n",
        "            \"RandomOversampler\": RandomOverSampler(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-ENN\": SMOTEENN(sampling_strategy='auto', random_state=1),\n",
        "            \"SMOTE-Tomek\": SMOTETomek(sampling_strategy='auto', random_state=1),\n",
        "            \"NoSamp\": NoSampler()\n",
        "        }\n",
        "\n",
        "        self.vectorizers = {\n",
        "            \"TFIDF\": TfidfVectorizer(),\n",
        "            \"Count\": CountVectorizer(),\n",
        "            \"Word2Vec\": Word2VecVectorizer(size=100, window=5, min_count=1)\n",
        "        }\n",
        "        self.classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(),\n",
        "            'DecisionTree': DecisionTreeClassifier(),\n",
        "            'RandomForest': RandomForestClassifier(),\n",
        "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "            'GaussianNB': GaussianNB(),\n",
        "            'KNN': KNeighborsClassifier(),\n",
        "            'SVM': SVC(probability=True),\n",
        "            'XGBoost': XGBClassifier(objective=\"multi:softmax\", num_class=len(np.unique(y)), eval_metric=\"mlogloss\", use_label_encoder=False, n_jobs = 2),\n",
        "        }\n",
        "\n",
        "\n",
        "    def duplicate_minor_classes(self, X, y, min_instances=10):\n",
        "        X = X.reset_index(drop=True)\n",
        "        y  = y.reset_index(drop=True)\n",
        "        class_counts = y.value_counts()\n",
        "\n",
        "        minor_classes = class_counts[class_counts <= min_instances].index\n",
        "\n",
        "        minor_class_rows = X.loc[y.isin(minor_classes)]\n",
        "        minor_class_labels = y.loc[y.isin(minor_classes)]\n",
        "\n",
        "        duplicated_X = pd.concat([minor_class_rows] * 2, ignore_index=True)\n",
        "        duplicated_y = pd.concat([minor_class_labels] * 2, ignore_index=True)\n",
        "\n",
        "        X_balanced = pd.concat([X, duplicated_X], ignore_index=True)\n",
        "        y_balanced = pd.concat([y, duplicated_y], ignore_index=True)\n",
        "\n",
        "        X_balanced.reset_index(drop=True, inplace=True)\n",
        "        y_balanced.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return X_balanced, y_balanced\n",
        "\n",
        "\n",
        "    def test(self, model, model_name, vectorizer, vectorizer_name, sampler, sampler_name):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        accuracies, recalls, precisions, f1s = [], [], [], []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "\n",
        "            X_train, y_train = self.duplicate_minor_classes(X_train, pd.Series(y_train))\n",
        "\n",
        "\n",
        "            X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test = vectorizer.transform(X_test).toarray()\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "            model.fit(X_resampled, y_resampled)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "            recalls.append(recall_score(y_test, y_pred, average=\"weighted\"))\n",
        "            precisions.append(precision_score(y_test, y_pred, average=\"weighted\"))\n",
        "            f1s.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "        return [\n",
        "            model_name,\n",
        "            vectorizer_name,\n",
        "            sampler_name,\n",
        "            np.mean(accuracies),\n",
        "            np.std(accuracies),\n",
        "            np.mean(recalls),\n",
        "            np.std(recalls),\n",
        "            np.mean(precisions),\n",
        "            np.std(precisions),\n",
        "            np.mean(f1s),\n",
        "            np.std(f1s),\n",
        "        ]\n",
        "\n",
        "    def training(self):\n",
        "        results = []\n",
        "        task_list = []\n",
        "\n",
        "        for vect_name, vectorizer in self.vectorizers.items():\n",
        "            for samp_name, sampler in self.sampling_strategies.items():\n",
        "                for clf_name, model in self.classifiers.items():\n",
        "                    task_list.append(\n",
        "                        (clf_name, vect_name, samp_name, deepcopy(model), deepcopy(vectorizer), deepcopy(sampler))\n",
        "                    )\n",
        "\n",
        "        progress_bar = tqdm(total=len(task_list))\n",
        "        with parallel_backend(\"threading\"):\n",
        "            parallel_results = Parallel(n_jobs=-1)(\n",
        "                delayed(self._process_task)(task, progress_bar) for task in task_list\n",
        "            )\n",
        "\n",
        "        results.extend(parallel_results)\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Save results and models\n",
        "        self.results = pd.DataFrame(\n",
        "            results,\n",
        "            columns=[\n",
        "                \"Model\",\n",
        "                \"Vectorizer\",\n",
        "                \"Sampler\",\n",
        "                \"Accuracy Mean\",\n",
        "                \"Accuracy Std\",\n",
        "                \"Recall Mean\",\n",
        "                \"Recall Std\",\n",
        "                \"Precision Mean\",\n",
        "                \"Precision Std\",\n",
        "                \"F1 Mean\",\n",
        "                \"F1 Std\",\n",
        "            ],\n",
        "        )\n",
        "        return self.results\n",
        "\n",
        "    def _process_task(self, task, progress_bar):\n",
        "        clf_name, vect_name, samp_name, model, vectorizer, sampler = task\n",
        "        result = self.test(\n",
        "            model=model,\n",
        "            model_name=clf_name,\n",
        "            vectorizer=vectorizer,\n",
        "            vectorizer_name=vect_name,\n",
        "            sampler=sampler,\n",
        "            sampler_name=samp_name,\n",
        "        )\n",
        "        progress_bar.update(1)\n",
        "        return result\n",
        "\n",
        "    def test_ensemble(self):\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        tasks = []\n",
        "\n",
        "        for train_index, test_index in skf.split(self.X, self.y):\n",
        "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
        "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
        "            X_train, y_train = self.duplicate_minor_classes(X_train, pd.Series(y_train))\n",
        "            tasks.append((X_train, X_test, y_train, y_test))\n",
        "\n",
        "        total_tasks = len(tasks)\n",
        "        progress_bar = tqdm(total=total_tasks, desc=\"Processing folds\")\n",
        "        lock = threading.Lock()  # Lock to manage updates safely across threads\n",
        "\n",
        "        def process_with_progress(*args):\n",
        "            result = self._process_fold(*args)\n",
        "            with lock:\n",
        "                progress_bar.update(1)\n",
        "            return result\n",
        "\n",
        "        with parallel_backend(\"threading\"):\n",
        "            results = Parallel(n_jobs=-1)(\n",
        "                delayed(process_with_progress)(X_train, X_test, y_train, y_test)\n",
        "                for X_train, X_test, y_train, y_test in tasks\n",
        "            )\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        accuracies, recalls, precisions, f1s = zip(*results)\n",
        "\n",
        "        return [\n",
        "            \"Ensemble\", \"Multiple\", \"Multiple\",\n",
        "            np.mean(accuracies), np.std(accuracies),\n",
        "            np.mean(recalls), np.std(recalls),\n",
        "            np.mean(precisions), np.std(precisions),\n",
        "            np.mean(f1s), np.std(f1s)\n",
        "        ]\n",
        "\n",
        "    def _process_fold(self, X_train, X_test, y_train, y_test):\n",
        "        fold_trained_models = {}\n",
        "        fold_trained_vectorizers = {}\n",
        "\n",
        "        for vectorizer_name, vectorizer_i in self.vectorizers.items():\n",
        "            vectorizer = deepcopy(vectorizer_i)\n",
        "            X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
        "            X_test_vect = vectorizer.transform(X_test).toarray()\n",
        "            fold_trained_vectorizers[vectorizer_name] = vectorizer\n",
        "\n",
        "            for sampler_name, sampler_i in self.sampling_strategies.items():\n",
        "                sampler = deepcopy(sampler_i)\n",
        "                X_resampled, y_resampled = sampler.fit_resample(X_train_vect, y_train)\n",
        "\n",
        "                for model_name, model in self.classifiers.items():\n",
        "                    trained_model = deepcopy(model)\n",
        "                    trained_model.fit(X_resampled, y_resampled)\n",
        "                    fold_trained_models[(vectorizer_name, sampler_name, model_name)] = trained_model\n",
        "\n",
        "        ensemble = EnsembleModel(fold_trained_models, fold_trained_vectorizers)\n",
        "        ensemble.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = ensemble.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "        return accuracy, recall, precision, f1\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z5-kRVEJxLjj"
      },
      "id": "Z5-kRVEJxLjj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`EnsembleModel`\n",
        "\n",
        "This class combines predictions from multiple models to make a more accurate \"group decision.\"\n",
        " - `__init__`: Takes two things:\n",
        "   - A dictionary of trained models.\n",
        "   - A dictionary of vectorizers (tools that convert text into numbers).\n",
        "   It stores these for use during prediction and training.\n",
        " - `_generate_prediction_matrix`: This creates a matrix where:\n",
        "   - Each row corresponds to an input sample.\n",
        "   - Each column is a model's prediction probabilities for each class.\n",
        " - `fit`: Uses an optimization algorithm (`differential_evolution`) to find the best set of weights for combining the model predictions. The goal is to maximize prediction performance (e.g., F1-score).\n",
        " - `predict`: Uses the optimized weights to combine predictions from all models and makes the final decision by selecting the class with the highest combined probability."
      ],
      "metadata": {
        "id": "JmL3JegE6lTx"
      },
      "id": "JmL3JegE6lTx"
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModel:\n",
        "    def __init__(self, trained_models, trained_vectorizers):\n",
        "\n",
        "        self.trained_models = trained_models\n",
        "        self.trained_vectorizers = trained_vectorizers\n",
        "        self.optimized_weights = None\n",
        "\n",
        "    def _generate_prediction_matrix(self, X):\n",
        "        predictions = {}\n",
        "        for (vect_name, samp_name, clf_name), model in self.trained_models.items():\n",
        "            vectorizer = deepcopy(self.trained_vectorizers[vect_name])\n",
        "            X_vect = vectorizer.transform(X).toarray()\n",
        "\n",
        "            predictions[(vect_name, samp_name, clf_name)] = model.predict_proba(X_vect)\n",
        "\n",
        "        return np.stack(list(predictions.values()), axis=2)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        pred_matrix = self._generate_prediction_matrix(X_train)\n",
        "\n",
        "        def fitness(weights):\n",
        "            weighted_pred = np.tensordot(pred_matrix, weights, axes=([2], [0]))\n",
        "            final_pred = np.argmax(weighted_pred, axis=1)\n",
        "            return -f1_score(y_train, final_pred, average='weighted')\n",
        "\n",
        "        num_models = pred_matrix.shape[2]\n",
        "        bounds = [(0, 1)] * num_models\n",
        "        result = differential_evolution(fitness, bounds)\n",
        "\n",
        "        self.optimized_weights = result.x\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.optimized_weights is None:\n",
        "            raise ValueError(\"The ensemble model must be trained using `train_ensemble` before prediction.\")\n",
        "\n",
        "        pred_matrix = self._generate_prediction_matrix(X)\n",
        "        weighted_pred = np.tensordot(pred_matrix, self.optimized_weights, axes=([2], [0]))\n",
        "        ensemble_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return ensemble_pred\n"
      ],
      "metadata": {
        "id": "6CDFeUgXDg3F"
      },
      "id": "6CDFeUgXDg3F",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Representations`\n",
        "\n",
        "This class creates different ways to represent sequences of events for machine learning analysis.\n",
        " - `representation_a`: Focuses on filtering events:\n",
        "   - Counts the frequency of each event in all sequences.\n",
        "   - Keeps only the events that occur less than 85% of the time, filtering out common noise.\n",
        "   - Outputs a \"cleaned\" sequence of events and the labels (e.g., incident types).\n",
        " - `representation_b`: Splits event sequences into two parts:\n",
        "   - Events *before* an incident (labeled with the incident type).\n",
        "   - Events *after* an incident (labeled as \"unknown\").\n",
        " - `representation_c`: Breaks sequences into overlapping chunks:\n",
        "   - For example, if you have a sequence of 50 events, it divides them into smaller parts (e.g., chunks of 30 events with 15 overlapping).\n",
        "   - Each chunk is labeled with the incident type.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7kLLXN5Y6viF"
      },
      "id": "7kLLXN5Y6viF"
    },
    {
      "cell_type": "code",
      "source": [
        "class Representations:\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def representation_a(self, df):\n",
        "            events_types_dict = {}\n",
        "            for events_sequence in df['events_sequence']:\n",
        "                row_list = ast.literal_eval(events_sequence)\n",
        "                unique_events = set(row_list)\n",
        "                for event in unique_events:\n",
        "                    if not events_types_dict.get(event):\n",
        "                        events_types_dict[event] = 0\n",
        "                    events_types_dict[event] += 1\n",
        "\n",
        "            sorted_dict = dict(sorted(events_types_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "            sorted_events_perc_df = pd.DataFrame(list(sorted_dict.items()), columns=['event_type', 'frequency'])\n",
        "            sorted_events_perc_df['percentage'] = sorted_events_perc_df['frequency'] / df.shape[0] * 100\n",
        "            sorted_events_perc_df['event_type'] = sorted_events_perc_df['event_type'].astype(str)\n",
        "\n",
        "            events_low_frequency = list(map(int, list(sorted_events_perc_df[sorted_events_perc_df.percentage <= 85].event_type)))\n",
        "\n",
        "            df['clean_events_sequence'] = (\n",
        "                df['events_sequence']\n",
        "                .apply(ast.literal_eval)\n",
        "                .apply(lambda x: [i for i in x if i in events_low_frequency])\n",
        "                .astype(str)\n",
        "                .replace(r'[\\[\\],]', '', regex=True)\n",
        "            )\n",
        "\n",
        "            self.y = df['incident_type'].copy()\n",
        "            self.X = df['clean_events_sequence'].copy()\n",
        "            return self.X, self.y\n",
        "\n",
        "  def representation_b(self, df):\n",
        "\n",
        "    before_incident = []\n",
        "    after_incident = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        before_events = \" \".join([str(event) for event, time in zip(events, seconds) if time <= 0])\n",
        "        if before_events:\n",
        "            before_incident.append({\n",
        "                \"events_sequence\": before_events,\n",
        "                \"class\": incident_type\n",
        "            })\n",
        "\n",
        "        after_events = \" \".join([str(event) for event, time in zip(events, seconds) if time > 0])\n",
        "        if after_events:\n",
        "            after_incident.append({\n",
        "                \"events_sequence\": after_events,\n",
        "                \"class\": 100\n",
        "            })\n",
        "\n",
        "    before_df = pd.DataFrame(before_incident)\n",
        "    after_df = pd.DataFrame(after_incident)\n",
        "\n",
        "    return before_df, after_df\n",
        "\n",
        "\n",
        "  def representation_c(self, df, sequence_length=30):\n",
        "\n",
        "    overlapping_sequences = []\n",
        "    step = sequence_length // 2\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        events = ast.literal_eval(row['events_sequence'])\n",
        "        seconds = ast.literal_eval(row['seconds_to_incident_sequence'])\n",
        "        incident_type = row['incident_type']\n",
        "\n",
        "        for i in range(0, len(events) - sequence_length + 1, step):\n",
        "            sequence = [str(i) for i in events[i:i + sequence_length]]\n",
        "            seconds_slice = seconds[i:i + sequence_length]\n",
        "            sequence_class = incident_type\n",
        "\n",
        "            overlapping_sequences.append({\"sequence\": \" \".join(sequence), \"class\": sequence_class})\n",
        "\n",
        "    sequences_df = pd.DataFrame(overlapping_sequences)\n",
        "    return sequences_df.sequence, sequences_df['class']\n"
      ],
      "metadata": {
        "id": "3zsHqb8oDiyJ"
      },
      "id": "3zsHqb8oDiyJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "ic7u7acl7qJj"
      },
      "id": "ic7u7acl7qJj"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
      "metadata": {
        "id": "a174a224-01e6-49d4-bc6b-9334422de2bf",
        "outputId": "c13b907f-55be-4f66-ec2e-6e2c2168b394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     incident_id                                  vehicles_sequence  \\\n",
              "570      4459461  [709, 709, 709, 709, 709, 709, 709, 709, 709, ...   \n",
              "18       4433937  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n",
              "\n",
              "                                       events_sequence  \\\n",
              "570  [2956, 2956, 4066, 3636, 3658, 2956, 2956, 295...   \n",
              "18   [2742, 4148, 4168, 4140, 3986, 4004, 2852, 411...   \n",
              "\n",
              "                          seconds_to_incident_sequence  approx_lat  \\\n",
              "570  [-14398, -14396, -14370, -14338, -14338, -1430...   50.737828   \n",
              "18   [-12722, -12722, -12716, -12709, -12684, -1252...   50.875950   \n",
              "\n",
              "     approx_lon                                 train_kph_sequence  \\\n",
              "570    4.283797  [44.9, 41.2, 0.0, 0.0, 0.0, 39.0, 80.3, 68.2, ...   \n",
              "18     3.190591  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                  dj_ac_state_sequence  \\\n",
              "570  [False, False, False, False, False, False, Fal...   \n",
              "18   [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                  dj_dc_state_sequence  incident_type  \n",
              "570  [True, True, True, True, True, True, True, Tru...             17  \n",
              "18   [True, True, True, False, False, False, False,...             14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6071db9d-afc6-4d68-ba57-49830740010b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incident_id</th>\n",
              "      <th>vehicles_sequence</th>\n",
              "      <th>events_sequence</th>\n",
              "      <th>seconds_to_incident_sequence</th>\n",
              "      <th>approx_lat</th>\n",
              "      <th>approx_lon</th>\n",
              "      <th>train_kph_sequence</th>\n",
              "      <th>dj_ac_state_sequence</th>\n",
              "      <th>dj_dc_state_sequence</th>\n",
              "      <th>incident_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>4459461</td>\n",
              "      <td>[709, 709, 709, 709, 709, 709, 709, 709, 709, ...</td>\n",
              "      <td>[2956, 2956, 4066, 3636, 3658, 2956, 2956, 295...</td>\n",
              "      <td>[-14398, -14396, -14370, -14338, -14338, -1430...</td>\n",
              "      <td>50.737828</td>\n",
              "      <td>4.283797</td>\n",
              "      <td>[44.9, 41.2, 0.0, 0.0, 0.0, 39.0, 80.3, 68.2, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4433937</td>\n",
              "      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n",
              "      <td>[2742, 4148, 4168, 4140, 3986, 4004, 2852, 411...</td>\n",
              "      <td>[-12722, -12722, -12716, -12709, -12684, -1252...</td>\n",
              "      <td>50.875950</td>\n",
              "      <td>3.190591</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[True, True, True, False, False, False, False,...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6071db9d-afc6-4d68-ba57-49830740010b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6071db9d-afc6-4d68-ba57-49830740010b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6071db9d-afc6-4d68-ba57-49830740010b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b414f24-907c-4f93-9dcf-740af49bf497\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b414f24-907c-4f93-9dcf-740af49bf497')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b414f24-907c-4f93-9dcf-740af49bf497 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"incident_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18048,\n        \"min\": 4433937,\n        \"max\": 4459461,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4433937,\n          4459461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624]\",\n          \"[709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 709, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091, 1091]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"events_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[2742, 4148, 4168, 4140, 3986, 4004, 2852, 4110, 2854, 2708, 2744, 4148, 4030, 4018, 4140, 4152, 2852, 2854, 4168, 4156, 3490, 4396, 1032, 4124, 2658, 2858, 2688, 3254, 3254, 3254, 4180, 4124, 2708, 2970, 4092, 4082, 4090, 4084, 4090, 4094, 3236, 2974, 4100, 2744, 4148, 4066, 4068, 2742, 4026, 4148, 2852, 2854, 4120, 2858, 2658, 2688, 2886, 4120, 3632, 2682, 2686, 4066, 2708, 2744, 4026, 4148, 3636, 3658, 4124, 2682, 4066, 3636, 3658, 4078, 4066, 3636, 3658, 4078, 4066, 3636, 3658, 4066, 3636, 3658, 4066, 3636, 3658, 4078, 4066, 3636, 3658, 4078, 4068, 3636, 3658, 4124, 2400, 4180, 4066, 2708, 2742, 4148, 3636, 3658, 4120, 2940, 4066, 4120, 3636, 3658, 4068, 3636, 3658, 4078, 4068, 3636, 3658, 4078, 4068, 3636, 3658, 2682, 2682, 4068, 3636, 3658, 4068, 3636, 3658, 4120, 4068, 3636, 3658, 4120, 4078, 3982, 2682, 4048, 4068, 2736, 2708, 4020, 4028, 4016, 4026, 4020, 4114, 4168, 4140, 4140, 4152, 4168, 4156, 4168, 4114, 4168, 4140, 4114, 3986, 4002, 4032, 4028, 2852, 4110, 2854, 4016, 4026, 4020, 4026, 4140, 4152, 4168, 4156, 3490, 4396, 4068, 4068, 4068, 4068, 2742, 4070, 4148, 4120, 2858, 2658, 2688, 2970, 4082, 4092, 4090, 4094, 4084, 4090, 3234, 4066, 2974, 4100, 3234, 3636, 3658, 4120, 4066, 3636, 3658, 4068, 3636, 3658, 4078, 3980, 4068, 3636, 3658, 4078, 4068, 3636, 3658, 4078, 4068, 3636, 3658, 4078, 4068, 3636, 3658, 4078, 4068, 2708, 3234, 4054, 4020, 4028, 2708, 2740, 4396, 4030, 4020, 4026, 2972, 3234, 2976, 4100, 4168, 4140, 4140, 4152, 4168, 4156, 2098, 2566, 4394, 2058, 4168, 4156, 4168, 4140, 3986, 4004, 4032, 4028, 2852, 4110, 2854, 2058, 4396, 2708, 2742, 4026, 4148, 4394, 4030, 4026, 4020, 4140, 4152, 4168, 4156, 4396, 4408, 4068, 3636, 3658, 4120, 2682, 4068, 3636, 3658, 4078, 4120, 4068, 3636, 3658, 4120, 4068, 3636, 3658, 4120]\",\n          \"[2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 2708, 2742, 4026, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 4120, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 2708, 2744, 4026, 4148, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4068, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2684, 4124, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 4066, 3636, 3658, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 3982, 2682, 3620, 4054, 4068, 2708, 2736, 2708, 4020, 4026, 4028, 3240, 3532, 4028, 4392, 4026, 4054, 2708, 2742, 4026, 4148, 4030, 4020, 4024, 2744, 4056, 4032, 2708, 4026, 2740, 2708, 3548, 4394, 4030, 4018, 4026, 3634, 4126, 2682, 4148, 4126, 2708, 2892, 4054, 2736, 4016, 4020, 3240, 3532, 4392, 4018, 4026, 4032, 4056, 2740, 2744, 2740, 3240, 3548, 4394, 4126, 4126, 4030, 4018, 4026, 3548, 4394, 2708, 3982, 4124, 4054, 2736, 2708, 4068, 3634, 2708, 4020, 4026, 4028, 4056, 4032, 2708, 2744, 4026, 4030, 4018, 4026, 4126, 4068, 2708, 3636, 3658, 2744, 4068, 3548, 4394, 4056, 3636, 3658, 2742, 4026, 4148, 4068, 3636, 3658, 4120, 2956, 2956, 2956, 2956, 2956, 4016, 4026, 4020, 4016, 4082, 4092, 4094, 4080, 2744, 4026, 4148, 2708, 4020, 4124, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2956, 2708, 4022, 3506, 2742, 4050, 4032, 2708, 4026, 4030, 2740, 4018, 4122, 2708, 2744, 4148, 2892, 4066, 4054, 2736, 4020, 4016, 4026, 4028, 3240, 3532, 4028, 4032, 4054, 4392, 4026, 4024, 3548, 4026, 4016, 4020, 4026, 4024, 3506, 2744, 4056, 4148, 4032, 2708, 4026, 4030, 4018, 4026, 3548, 4394, 4072, 3982, 4124, 2682, 4054, 2736, 2708, 2708, 3532, 4018, 4032, 4056, 4392, 4026, 2740, 3240, 3548, 4394, 4030, 4018, 3506, 3548, 4394, 2892, 3548, 4394, 4054, 2736, 4066, 4020, 4016, 4024, 4026, 4028, 4124, 3506, 2744, 4056, 4032, 4066, 2708, 4026, 2740, 2744, 2740, 4030, 4018, 4026, 3634, 4072, 2744]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds_to_incident_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[-12722, -12722, -12716, -12709, -12684, -12525, -12523, -12523, -12521, -12518, -12518, -12487, -12484, -12483, -12479, -12477, -12417, -12416, -12415, -12412, -12410, -12410, -12405, -12389, -12330, -12330, -12329, -12318, -12317, -12292, -12292, -12256, -12247, -12231, -12202, -12201, -12201, -12172, -12172, -12172, -12119, -12023, -12021, -11984, -11984, -11983, -11982, -11865, -11865, -11865, -11832, -11831, -11828, -11771, -11770, -11770, -11716, -10557, -10548, -10220, -10013, -10012, -10000, -9675, -9675, -9675, -9220, -9220, -9209, -9058, -8667, -8608, -8608, -8603, -8432, -8377, -8377, -8372, -8080, -8022, -8022, -7650, -7601, -7601, -7346, -7291, -7291, -7284, -6946, -6871, -6871, -6865, -6397, -6300, -6300, -6026, -5486, -5113, -5095, -5087, -4718, -4718, -4358, -4358, -4356, -4304, -3451, -3107, -3105, -3105, -2640, -2596, -2596, -2588, -2242, -2195, -2195, -2180, -1944, -1886, -1886, -1858, -1856, -1503, -1478, -1478, -1171, -1128, -1128, -1088, -909, -882, -882, -877, -855, -290, -274, -274, -274, -272, -271, -246, -246, -245, -245, -235, 1268, 1268, 1277, 1369, 1369, 1381, 1384, 1421, 1501, 1501, 1513, 1537, 1538, 1698, 1698, 1699, 1700, 1700, 1702, 1738, 1738, 1750, 1750, 1776, 1778, 1788, 1790, 1806, 1807, 1832, 2531, 2836, 3215, -6541, -6499, -6397, -6267, -6205, -6196, -6196, -6154, -6125, -6125, -6124, -6096, -6095, -6095, -6040, -6023, -5944, -5942, -5925, -4480, -4480, -4473, -3942, -3917, -3917, -3264, -3244, -3244, -3233, -3146, -3055, -3032, -3032, -3022, -2783, -2756, -2756, -2744, -2510, -2489, -2489, -2477, -2311, -2295, -2295, -2284, -1898, -1887, -1642, -272, -270, -244, -243, -238, -237, -235, -234, -234, -198, -173, -56, -52, 1270, 1279, 1370, 1370, 1383, 1385, 1391, 1391, 1391, 1392, 1423, 1425, 1503, 1515, 1539, 1699, 1699, 1701, 1702, 1702, 1703, 1724, 1724, 1739, 1739, 1739, 1739, 1742, 1750, 1751, 1752, 1777, 1778, 1789, 1791, 1810, 1816, 1834, 1871, 1871, 1976, 2220, 2532, 2540, 2540, 2542, 2546, 2838, 2846, 2846, 2860, 3216, 3302, 3302, 3316]\",\n          \"[-14398, -14396, -14370, -14338, -14338, -14301, -14231, -14225, -14218, -14204, -14188, -14175, -14175, -14093, -14091, -14048, -14035, -14010, -13989, -13958, -13958, -13916, -13889, -13877, -13857, -13814, -13803, -13803, -13750, -13734, -13705, -13698, -13697, -13686, -13684, -13658, -13653, -13632, -13620, -13516, -13516, -13478, -13418, -13409, -13407, -13399, -13358, -13354, -13336, -13300, -13300, -13263, -13232, -13221, -13204, -13194, -13192, -13171, -13146, -13111, -13111, -13067, -13039, -13027, -13003, -12959, -12953, -12908, -12893, -12857, -12845, -12845, -12806, -12794, -12783, -12773, -12764, -12735, -12728, -12681, -12666, -12647, -12567, -12534, -12525, -12249, -12249, -11830, -11772, -11772, -11655, -11640, -11628, -11583, -11574, -11539, -11529, -11519, -11509, -11498, -11474, -11404, -11404, -11355, -11343, -11302, -11296, -11252, -11227, -11214, -11191, -11168, -11118, -11118, -11075, -11045, -11044, -11005, -10994, -10968, -10944, -10911, -10911, -10881, -10869, -10816, -10807, -10795, -10748, -10744, -10729, -10625, -10625, -10613, -10585, -10579, -10552, -10550, -10538, -10537, -10497, -10482, -10467, -10450, -10450, -10418, -10396, -10364, -10294, -10255, -10233, -10233, -10221, -10210, -10178, -10166, -10134, -10122, -10120, -10057, -10029, -10029, -9985, -9974, -9969, -9899, -9874, -9864, -9864, -9822, -9819, -9783, -9763, -9735, -9719, -9710, -9694, -9680, -9649, -9603, -9567, -9505, -9505, -9487, -9452, -9448, -9420, -9417, -9414, -9397, -9393, -9391, -9388, -9366, -9358, -9354, -9334, -9329, -9324, -9292, -9284, -9253, -9222, -9222, -9170, -9165, -9138, -9134, -9118, -9113, -9092, -9088, -9085, -9068, -9063, -9004, -9000, -8976, -8912, -8912, -8899, -8852, -8848, -8824, -8805, -8795, -8789, -8754, -8741, -8725, -8711, -8696, -8640, -8634, -8615, -8581, -8581, -8533, -8526, -8474, -8465, -8457, -8435, -8425, -8423, -8396, -8391, -8384, -8372, -8368, -8354, -8342, -8327, -8306, -8306, -8248, -8247, -8233, -8227, -8162, -8136, -8126, -8088, -8088, -8043, -8001, -7987, -7965, -7929, -7921, -7912, -7858, -7832, -7832, -7782, -7769, -7736, -7734, -7721, -7709, -7695, -7689, -7671, -7650, -7641, -7615, -7615, -7564, -7553, -7534, -7526, -7513, -7503, -7470, -7445, -7445, -7405, -7361, -7339, -7307, -7293, -7277, -7260, -7260, -7175, -7126, -7115, -7113, -7046, -7030, -7030, -6976, -6964, -6925, -6914, -6905, -6886, -6872, -6859, -6843, -6843, -6769, -6760, -6733, -6719, -6707, -6700, -6689, -6683, -6679, -6669, -6663, -6655, -6606, -6581, -6575, -6552, -6530, -6493, -6435, -6418, -6299, -6299, -6238, -5248, -5248, -5222, -5126, -5110, -5093, -5086, -5065, -5011, -5005, -5000, -4991, -4987, -4983, -4969, -4964, -4951, -4949, -4938, -4911, -4907, -4894, -4866, -4844, -4844, -4812, -4793, -4770, -4760, -4740, -4731, -4720, -4687, -4673, -4673, -4579, -4577, -4538, -4525, -4491, -4465, -4465, -4441, -4423, -4380, -4371, -4350, -4340, -4328, -4316, -4281, -4235, -4235, -4201, -4166, -4153, -4138, -4129, -4111, -4101, -4082, -4064, -4041, -4041, -3998, -3989, -3976, -3967, -3957, -3948, -3942, -3925, -3903, -3890, -3816, -3816, -3807, -3766, -3738, -3729, -3718, -3691, -3682, -3665, -3627, -3627, -3604, -3578, -3561, -3517, -3513, -3507, -3503, -3482, -3466, -3437, -3437, -3369, -3363, -3349, -3347, -3306, -3284, -3279, -3277, -3273, -3267, -3187, -3183, -3179, -3141, -3110, -3110, -3065, -3057, -2997, -2975, -2954, -2932, -2915, -2880, -2874, -2864, -2845, -2820, -2815, -2774, -2737, -2737, -2717, -2665, -2658, -2607, -2601, -2582, -2581, -2579, -2562, -2559, -2539, -2536, -2533, -2519, -2516, -2483, -2452, -2452, -2398, -2394, -2376, -2373, -2362, -2359, -2344, -2340, -2337, -2324, -2320, -2298, -2294, -2291, -2264, -2261, -2221, -2101, -2101, -2084, -2035, -1980, -1977, -1955, -1953, -1929, -1916, -1914, -1890, -1887, -1877, -1853, -1852, -1827, -1811, -1811, -1765, -1699, -1694, -1689, -1678, -1657, -1631, -1631, -1598, -1596, -1525, -1523, -1487, -1477, -1458, -1436, -1411, -1411, -1369, -1340, -1330, -1313, -1273, -1255, -1255, -1208, -1190, -1164, -1158, -1157, -1148, -1147, -1127, -1122, -1101, -1087, -1047, -1047, -1015, -978, -922, -914, -911, -905, -868, -864, -843, -824, -824, -777, -742, -733, -718, -709, -708, -686, -652, -623, -623, -601, -584, -553, -543, -521, -487, -483, -449, -439, -403, -384, -384, -337, -324, -312, -300, -292, -262, -254, -183, -159, -120, 26, 72, 88, 88, 88, 88, 90, 90, 104, 109, 109, 109, 138, 138, 138, 138, 139, 139, 267, 267, 267, 268, 271, 272, 348, 361, 361, 362, 366, 366, 371, 381, 392, 392, 407, 408, 408, 421, 449, 452, 457, 458, 483, 532, 553, 554, 561, 561, 601, 601, 601, 602, 602, 602, 602, 603, 713, 715, 721, 733, 733, 762, 769, 779, 780, 780, 799, 799, 811, 846, 848, 860, 861, 862, 875, 897, 914, 920, 920, 920, 929, 930, 946, 946, 947, 950, 951, 951, 972, 983, 989, 1048, 1048, 1315, 1322, 1565, 1565, 1621, 1777, 1777, 1784, 1784, 1784, 1877, 1979, 1979, 3356, 3500, 3527, 3544, 3591, 3598, -7100, -7099, -7098, -6827, -6642, -6642, -6633, -5344, -4969, -4969, -4969, -4967, -4967, -4045, -3951, -3899, -3878, -3869, -3848, -3846, -3800, -3785, -3743, -3730, -3711, -3697, -3654, -3641, -3632, -3574, -3571, -3531, -3522, -3506, -3496, -3493, -3484, -3463, -3454, -3431, -3423, -3408, -3400, -3387, -3379, -3357, -3327, -3313, -3290, -3283, -3271, -3263, -3255, -3244, -3236, -3205, -3189, -3163, -3155, -3139, -3131, -3126, -3117, -3110, -3102, -3097, -3066, -3057, -3044, -3034, -2978, -2972, -2952, -2843, -2802, -2738, -2732, -2726, -2726, -2725, -2721, -2721, -2717, -2716, -2716, -2683, -2665, -234, -206, 54, 55, 91, 92, 100, 101, 112, 112, 141, 141, 141, 141, 141, 141, 142, 163, 170, 270, 271, 275, 275, 357, 358, 364, 364, 364, 365, 369, 369, 373, 374, 374, 495, 495, 541, 544, 544, 556, 556, 557, 558, 564, 604, 604, 604, 604, 604, 605, 606, 606, 637, 637, 651, 652, 657, 712, 712, 796, 806, 806, 862, 864, 878, 882, 883, 920, 923, 923, 925, 926, 932, 932, 933, 934, 937, 937, 942, 1003, 1005, 1021, 1022, 1022, 1026, 1036, 1869]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09766741200085291,\n        \"min\": 50.737827774049215,\n        \"max\": 50.8759503527027,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.8759503527027,\n          50.737827774049215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7730136432135155,\n        \"min\": 3.1905905750000003,\n        \"max\": 4.283796953131991,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.1905905750000003,\n          4.283796953131991\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_kph_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.578125, 16.625, 0.21875, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.390625, 0.15625, 0.0, 0.0, 0.0, 0.171875, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.21875, 0.0, 0.0, 0.0, 0.15625, 0.0, 0.0, 0.0, 2.40625, 0.0, 0.0, 0.0, 162.71875, 12.0625, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.84375, 0.046875, 0.0, 0.0, 0.0, 0.171875, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.15625, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.953125, 0.734375, 0.734375, 0.109375, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.265625, 0.109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 114.65625, 0.09375, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.15625, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.9375, 0.375, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0]\",\n          \"[44.9, 41.2, 0.0, 0.0, 0.0, 39.0, 80.3, 68.2, 54.8, 38.1, 0.1, 0.0, 0.0, 99.9, 99.6, 87.4, 73.3, 48.1, 0.1, 0.0, 0.0, 53.3, 93.1, 88.5, 63.5, 0.1, 0.0, 0.0, 37.6, 83.4, 81.2, 79.8, 79.4, 76.7, 75.4, 54.0, 50.4, 21.6, 0.1, 0.0, 0.0, 22.0, 86.6, 99.0, 103.5, 100.0, 59.2, 48.7, 0.0, 0.0, 0.0, 54.9, 96.0, 98.8, 101.2, 98.3, 97.1, 65.7, 0.0, 0.0, 0.0, 32.8, 85.1, 96.8, 102.6, 115.2, 113.4, 77.7, 65.3, 0.1, 0.0, 0.0, 62.9, 88.1, 106.0, 119.6, 129.5, 141.7, 136.0, 76.4, 60.8, 57.5, 31.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.7, 78.6, 93.5, 111.1, 113.3, 114.1, 110.8, 106.3, 96.5, 76.7, 0.1, 0.0, 0.0, 74.2, 94.0, 108.8, 108.5, 106.7, 87.6, 82.1, 61.1, 0.2, 0.0, 0.0, 33.0, 90.7, 92.6, 88.5, 87.5, 60.0, 0.1, 0.0, 0.0, 11.0, 26.3, 85.5, 86.2, 84.8, 60.6, 43.5, 0.2, 0.0, 0.0, 0.0, 38.4, 42.8, 76.3, 76.7, 76.3, 76.2, 75.0, 57.5, 0.0, 0.0, 0.0, 32.4, 50.5, 51.1, 32.8, 0.2, 0.0, 0.0, 0.0, 13.8, 85.2, 95.5, 91.1, 89.9, 89.9, 0.1, 0.0, 0.0, 47.8, 67.7, 75.8, 57.3, 0.2, 0.0, 0.0, 26.7, 34.7, 82.6, 77.5, 70.9, 65.6, 61.3, 48.2, 37.5, 30.9, 31.7, 0.0, 0.0, 0.0, 0.0, 24.0, 28.3, 39.2, 38.4, 38.2, 38.6, 39.2, 38.9, 38.4, 38.2, 38.7, 38.7, 38.0, 26.2, 21.1, 19.3, 18.9, 0.3, 0.0, 0.0, 28.1, 27.7, 37.8, 37.7, 37.3, 36.7, 35.5, 35.3, 34.6, 32.3, 36.0, 29.6, 29.7, 0.2, 0.0, 0.0, 0.0, 29.3, 29.7, 35.0, 36.4, 36.5, 36.9, 38.3, 37.2, 34.4, 37.6, 34.7, 31.1, 29.5, 0.5, 0.0, 0.0, 25.4, 25.3, 31.0, 29.6, 37.5, 60.7, 70.6, 72.6, 79.2, 76.6, 71.5, 66.1, 65.7, 62.6, 49.6, 0.1, 0.0, 0.0, 68.4, 70.0, 72.3, 70.1, 53.4, 21.2, 0.2, 0.0, 0.0, 31.3, 51.7, 48.7, 44.3, 49.5, 33.6, 0.1, 0.0, 0.0, 0.0, 31.2, 46.7, 77.2, 78.2, 82.4, 79.6, 75.6, 74.3, 68.0, 29.3, 0.6, 0.0, 0.0, 85.0, 105.0, 131.5, 129.8, 120.1, 94.1, 0.0, 0.0, 0.0, 46.2, 101.9, 101.2, 93.5, 53.3, 0.1, 0.0, 0.0, 66.8, 100.2, 97.9, 97.5, 0.2, 0.0, 0.0, 67.3, 84.0, 93.7, 92.3, 90.7, 85.0, 56.1, 0.2, 0.0, 0.0, 67.6, 79.9, 86.6, 86.9, 87.1, 86.7, 83.5, 79.3, 74.6, 61.7, 58.7, 54.7, 33.6, 35.3, 36.0, 34.1, 34.7, 24.8, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.2, 49.3, 37.7, 37.1, 37.4, 55.4, 67.3, 74.0, 83.8, 85.2, 87.0, 87.9, 87.0, 81.0, 80.5, 91.0, 89.6, 81.1, 51.1, 0.1, 0.0, 0.0, 22.7, 80.3, 117.8, 127.8, 122.6, 105.9, 80.1, 0.1, 0.0, 0.0, 126.0, 128.3, 93.7, 68.7, 0.0, 0.0, 0.0, 0.0, 25.4, 109.2, 109.0, 101.6, 98.2, 94.7, 75.8, 0.1, 0.0, 0.0, 0.0, 74.4, 94.5, 113.8, 119.6, 112.9, 100.6, 51.5, 0.1, 0.0, 0.0, 63.8, 82.6, 104.0, 114.0, 114.1, 114.3, 109.9, 72.8, 21.7, 0.0, 0.0, 0.0, 0.0, 31.5, 86.1, 86.0, 85.6, 57.5, 41.1, 0.0, 0.0, 0.0, 0.0, 17.7, 52.7, 106.9, 106.9, 107.0, 107.0, 39.4, 0.0, 0.0, 0.0, 64.9, 75.8, 77.3, 77.6, 52.0, 36.2, 35.8, 35.5, 35.0, 34.2, 28.9, 28.5, 28.0, 0.0, 0.0, 0.0, 14.1, 23.3, 26.2, 22.7, 26.8, 27.5, 32.1, 35.4, 35.1, 37.8, 35.3, 28.8, 26.7, 0.1, 0.0, 0.0, 0.0, 11.4, 21.2, 35.6, 36.3, 35.8, 37.3, 38.4, 47.6, 47.4, 45.8, 45.8, 46.0, 44.2, 44.3, 0.0, 0.0, 0.0, 32.4, 42.4, 47.7, 46.8, 44.8, 43.9, 40.6, 39.8, 39.2, 36.5, 36.0, 36.6, 36.0, 35.4, 32.7, 29.7, 0.0, 0.0, 0.0, 0.0, 28.2, 35.8, 35.8, 55.9, 57.8, 68.0, 77.8, 80.0, 107.0, 106.6, 106.5, 80.3, 75.0, 0.0, 0.0, 0.0, 34.5, 92.7, 83.6, 71.6, 44.6, 0.1, 0.0, 0.0, 0.0, 0.0, 114.2, 114.6, 107.0, 100.7, 59.1, 0.0, 0.0, 0.0, 49.9, 103.7, 100.5, 77.9, 0.0, 0.0, 0.0, 32.5, 77.7, 99.5, 98.0, 97.7, 95.5, 95.1, 59.1, 48.6, 28.6, 0.0, 0.0, 0.0, 0.0, 18.3, 96.8, 105.8, 108.7, 106.3, 63.3, 50.6, 0.0, 0.0, 0.0, 40.3, 105.6, 116.4, 112.5, 109.0, 107.2, 55.2, 0.0, 0.0, 0.0, 0.0, 24.8, 90.8, 103.5, 125.4, 143.5, 142.0, 112.1, 87.4, 0.0, 0.0, 0.0, 52.7, 79.4, 100.6, 116.3, 126.0, 131.5, 118.6, 55.2, 26.0, 24.8, 17.9, 0.0, 0.8, 0.8, 0.8, 1.4, 0.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.5, 49.7, 72.0, 130.8, 131.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 32.6, 70.6, 85.5, 97.9, 97.3, 93.9, 95.6, 83.2, 80.2, 75.5, 72.0, 72.4, 89.6, 100.7, 102.1, 103.3, 114.3, 114.3, 112.2, 112.7, 114.1, 117.6, 113.5, 114.5, 116.7, 120.2, 127.2, 129.8, 134.9, 134.0, 138.1, 134.5, 137.1, 137.8, 135.8, 132.9, 131.1, 131.8, 132.9, 132.2, 133.2, 134.8, 130.3, 129.0, 126.7, 125.3, 125.1, 127.6, 130.5, 133.2, 134.6, 123.7, 115.5, 105.2, 95.9, 74.3, 73.9, 35.8, 27.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.7, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_ac_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\",\n          \"[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dj_dc_state_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\",\n          \"[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incident_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 14,\n        \"max\": 17,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          14,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv('sncb_data_challenge.csv', delimiter=';', index_col=0)\n",
        "df.sample(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Raw Dataset\n",
        "We want to test the performance of the pre-defined pipeline as a baseline for future experiments. That is, the data won't have any further transformation other than those defined in the `Experiment` class."
      ],
      "metadata": {
        "id": "5JiAkAiE3qUo"
      },
      "id": "5JiAkAiE3qUo"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['events_sequence'], df.incident_type\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "NZWqprZKULJC",
        "outputId": "d557e5b8-9dfe-4bd9-dee9-df22f9abbc72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NZWqprZKULJC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|â–         | 3/210 [01:25<1:38:26, 28.53s/it]\n",
            "\n",
            "  0%|          | 0/210 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/210 [00:09<32:42,  9.39s/it]\u001b[A\n",
            "  1%|          | 2/210 [00:18<32:08,  9.27s/it]\u001b[A\n",
            "  1%|â–         | 3/210 [00:29<34:44, 10.07s/it]\u001b[A\n",
            "  2%|â–         | 4/210 [00:43<39:10, 11.41s/it]\u001b[A\n",
            "  2%|â–         | 5/210 [01:15<1:05:17, 19.11s/it]\u001b[A\n",
            "  3%|â–Ž         | 6/210 [01:19<47:41, 14.03s/it]  \u001b[A\n",
            "  3%|â–Ž         | 7/210 [01:25<38:23, 11.35s/it]\u001b[A\n",
            "  4%|â–         | 8/210 [04:43<3:58:05, 70.72s/it]\u001b[A\n",
            "  4%|â–         | 9/210 [09:42<7:55:55, 142.07s/it]\u001b[A\n",
            "  5%|â–         | 10/210 [09:58<5:43:29, 103.05s/it]\u001b[A\n",
            "  5%|â–Œ         | 11/210 [10:10<4:09:08, 75.12s/it] \u001b[A\n",
            "  6%|â–Œ         | 12/210 [10:27<3:10:00, 57.58s/it]\u001b[A\n",
            "  6%|â–Œ         | 13/210 [10:51<2:35:57, 47.50s/it]\u001b[A\n",
            "  7%|â–‹         | 14/210 [27:17<18:00:43, 330.83s/it]\u001b[A\n",
            "  7%|â–‹         | 15/210 [27:49<13:02:58, 240.92s/it]\u001b[A\n",
            "  8%|â–Š         | 16/210 [27:54<9:08:37, 169.68s/it] \u001b[A\n",
            "  8%|â–Š         | 17/210 [28:00<6:28:14, 120.70s/it]\u001b[A\n",
            "  9%|â–Š         | 18/210 [31:03<7:26:04, 139.40s/it]\u001b[A\n",
            "  9%|â–‰         | 19/210 [33:53<7:52:37, 148.47s/it]\u001b[A\n",
            " 10%|â–‰         | 20/210 [34:11<5:46:00, 109.27s/it]\u001b[A\n",
            " 10%|â–ˆ         | 21/210 [34:21<4:10:09, 79.41s/it] \u001b[A\n",
            " 10%|â–ˆ         | 22/210 [34:38<3:10:27, 60.79s/it]\u001b[A\n",
            " 11%|â–ˆ         | 23/210 [35:03<2:35:44, 49.97s/it]\u001b[A\n",
            " 11%|â–ˆâ–        | 24/210 [37:01<3:38:12, 70.39s/it]\u001b[A\n",
            " 12%|â–ˆâ–        | 25/210 [37:36<3:04:49, 59.94s/it]\u001b[A\n",
            " 12%|â–ˆâ–        | 26/210 [37:41<2:12:39, 43.26s/it]\u001b[A\n",
            " 13%|â–ˆâ–Ž        | 27/210 [37:46<1:37:16, 31.89s/it]\u001b[A\n",
            " 13%|â–ˆâ–Ž        | 28/210 [41:15<4:18:16, 85.15s/it]\u001b[A\n",
            " 14%|â–ˆâ–        | 29/210 [44:02<5:30:40, 109.62s/it]\u001b[A\n",
            " 14%|â–ˆâ–        | 30/210 [44:17<4:03:28, 81.16s/it] \u001b[A\n",
            " 15%|â–ˆâ–        | 31/210 [44:24<2:55:32, 58.84s/it]\u001b[A\n",
            " 15%|â–ˆâ–Œ        | 32/210 [44:38<2:15:12, 45.57s/it]\u001b[A\n",
            " 16%|â–ˆâ–Œ        | 33/210 [45:03<1:56:06, 39.36s/it]\u001b[A\n",
            " 16%|â–ˆâ–Œ        | 34/210 [1:01:31<15:50:06, 323.90s/it]\u001b[A\n",
            " 17%|â–ˆâ–‹        | 35/210 [1:02:01<11:27:17, 235.64s/it]\u001b[A\n",
            " 17%|â–ˆâ–‹        | 36/210 [1:02:04<8:01:23, 166.00s/it] \u001b[A\n",
            " 18%|â–ˆâ–Š        | 37/210 [1:02:10<5:39:45, 117.83s/it]\u001b[A\n",
            " 18%|â–ˆâ–Š        | 38/210 [1:04:34<6:00:32, 125.77s/it]\u001b[A\n",
            " 19%|â–ˆâ–Š        | 39/210 [1:05:16<4:47:11, 100.77s/it]\u001b[A\n",
            " 19%|â–ˆâ–‰        | 40/210 [1:05:37<3:37:20, 76.71s/it] \u001b[A\n",
            " 20%|â–ˆâ–‰        | 41/210 [1:05:52<2:44:01, 58.23s/it]\u001b[A\n",
            " 20%|â–ˆâ–ˆ        | 42/210 [1:06:15<2:13:44, 47.77s/it]\u001b[A\n",
            " 20%|â–ˆâ–ˆ        | 43/210 [1:06:33<1:47:54, 38.77s/it]\u001b[A\n",
            " 21%|â–ˆâ–ˆ        | 44/210 [1:06:39<1:19:58, 28.91s/it]\u001b[A\n",
            " 21%|â–ˆâ–ˆâ–       | 45/210 [1:07:18<1:27:45, 31.91s/it]\u001b[A\n",
            " 22%|â–ˆâ–ˆâ–       | 46/210 [1:07:32<1:12:43, 26.60s/it]\u001b[A\n",
            " 22%|â–ˆâ–ˆâ–       | 47/210 [1:07:45<1:00:41, 22.34s/it]\u001b[A\n",
            " 23%|â–ˆâ–ˆâ–Ž       | 48/210 [1:09:48<2:22:18, 52.71s/it]\u001b[A\n",
            " 23%|â–ˆâ–ˆâ–Ž       | 49/210 [1:11:50<3:16:41, 73.30s/it]\u001b[A\n",
            "  1%|          | 2/210 [1:14:10<128:33:47, 2225.13s/it]\n",
            "\n",
            " 24%|â–ˆâ–ˆâ–       | 51/210 [1:12:27<1:59:52, 45.23s/it]\u001b[A\n",
            " 25%|â–ˆâ–ˆâ–       | 52/210 [1:12:50<1:41:38, 38.60s/it]\u001b[A\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 53/210 [1:13:22<1:35:32, 36.51s/it]\u001b[A\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 54/210 [1:28:13<12:41:41, 292.96s/it]\u001b[A\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 55/210 [1:28:55<9:22:33, 217.77s/it] \u001b[A\n",
            " 27%|â–ˆâ–ˆâ–‹       | 56/210 [1:29:07<6:40:27, 156.02s/it]\u001b[A\n",
            " 27%|â–ˆâ–ˆâ–‹       | 57/210 [1:29:18<4:46:24, 112.32s/it]\u001b[A\n",
            " 28%|â–ˆâ–ˆâ–Š       | 58/210 [1:32:45<5:56:42, 140.80s/it]\u001b[A\n",
            " 28%|â–ˆâ–ˆâ–Š       | 59/210 [1:35:44<6:23:04, 152.22s/it]\u001b[A\n",
            " 29%|â–ˆâ–ˆâ–Š       | 60/210 [1:35:50<4:31:31, 108.61s/it]\u001b[A\n",
            " 29%|â–ˆâ–ˆâ–‰       | 61/210 [1:35:55<3:12:21, 77.46s/it] \u001b[A\n",
            " 30%|â–ˆâ–ˆâ–‰       | 62/210 [1:36:03<2:19:40, 56.62s/it]\u001b[A\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 63/210 [1:36:13<1:44:23, 42.61s/it]\u001b[A\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 64/210 [1:40:57<4:39:35, 114.90s/it]\u001b[A\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 65/210 [1:41:08<3:22:38, 83.85s/it] \u001b[A\n",
            " 31%|â–ˆâ–ˆâ–ˆâ–      | 66/210 [1:41:11<2:22:58, 59.57s/it]\u001b[A\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 67/210 [1:41:14<1:41:28, 42.58s/it]\u001b[A\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 68/210 [1:41:39<1:27:58, 37.17s/it]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 69/210 [1:41:46<1:06:24, 28.26s/it]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 70/210 [1:42:07<1:01:04, 26.18s/it]\u001b[A\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 71/210 [1:42:16<48:20, 20.86s/it]  \u001b[A\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 72/210 [1:42:32<44:29, 19.35s/it]\u001b[A\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 73/210 [1:42:46<40:25, 17.70s/it]\u001b[A\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 74/210 [1:42:53<32:51, 14.50s/it]\u001b[A\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 75/210 [1:43:18<39:46, 17.68s/it]\u001b[A\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 76/210 [1:43:21<30:02, 13.45s/it]\u001b[A\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 77/210 [1:43:25<23:16, 10.50s/it]\u001b[A\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 78/210 [1:47:11<2:45:43, 75.33s/it]\u001b[A\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 79/210 [1:48:38<2:51:39, 78.62s/it]\u001b[A\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 80/210 [1:49:00<2:13:56, 61.82s/it]\u001b[A\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 81/210 [1:49:07<1:37:08, 45.19s/it]\u001b[A\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 82/210 [1:49:22<1:17:33, 36.36s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 83/210 [1:49:47<1:09:31, 32.84s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 84/210 [1:58:41<6:24:32, 183.12s/it]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 85/210 [1:59:08<4:44:13, 136.43s/it]\u001b[A\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 86/210 [1:59:13<3:20:15, 96.90s/it] \u001b[A\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/210 [1:59:18<2:22:01, 69.28s/it]\u001b[A\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/210 [2:02:53<3:49:52, 113.06s/it]\u001b[A\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/210 [2:04:23<3:33:59, 106.11s/it]\u001b[A\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 90/210 [2:04:45<2:41:45, 80.88s/it] \u001b[A\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 91/210 [2:04:53<1:57:10, 59.08s/it]\u001b[A\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/210 [2:05:08<1:29:57, 45.74s/it]\u001b[A\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/210 [2:05:28<1:14:21, 38.13s/it]\u001b[A\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 94/210 [2:06:26<1:25:23, 44.17s/it]\u001b[A\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 95/210 [2:06:53<1:14:35, 38.92s/it]\u001b[A\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 96/210 [2:07:00<55:26, 29.18s/it]  \u001b[A\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 97/210 [2:07:04<40:59, 21.76s/it]\u001b[A\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 98/210 [2:10:57<2:38:53, 85.12s/it]\u001b[A\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 99/210 [2:12:24<2:38:18, 85.57s/it]\u001b[A\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 100/210 [2:12:43<2:00:46, 65.87s/it]\u001b[A\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 101/210 [2:12:50<1:27:24, 48.11s/it]\u001b[A\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 102/210 [2:13:03<1:07:35, 37.55s/it]\u001b[A\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 103/210 [2:13:22<57:10, 32.06s/it]  \u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 104/210 [2:21:19<4:52:28, 165.55s/it]\u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 105/210 [2:21:43<3:35:23, 123.08s/it]\u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 106/210 [2:21:48<2:31:59, 87.69s/it] \u001b[A\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 107/210 [2:21:52<1:47:10, 62.43s/it]\u001b[A\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/210 [2:25:41<3:11:13, 112.49s/it]\u001b[A\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/210 [2:27:04<2:54:30, 103.67s/it]\u001b[A\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/210 [2:27:31<2:14:11, 80.51s/it] \u001b[A\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 111/210 [2:27:44<1:39:37, 60.38s/it]\u001b[A\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 112/210 [2:28:04<1:18:51, 48.28s/it]\u001b[A\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 113/210 [2:28:25<1:04:45, 40.06s/it]\u001b[A\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/210 [2:29:36<1:18:55, 49.32s/it]\u001b[A\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 115/210 [2:30:06<1:08:42, 43.39s/it]\u001b[A\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 116/210 [2:30:18<53:32, 34.18s/it]  \u001b[A\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 117/210 [2:30:31<43:02, 27.77s/it]\u001b[A\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 118/210 [2:32:21<1:20:24, 52.44s/it]\u001b[A\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 119/210 [2:33:29<1:26:41, 57.16s/it]\u001b[A\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 120/210 [2:33:54<1:11:16, 47.51s/it]\u001b[A\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 121/210 [2:34:05<54:15, 36.58s/it]  \u001b[A\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 122/210 [2:34:24<45:41, 31.15s/it]\u001b[A\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 123/210 [2:34:51<43:32, 30.02s/it]\u001b[A\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 124/210 [2:39:16<2:23:51, 100.37s/it]\u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 125/210 [2:39:45<1:52:02, 79.09s/it] \u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 126/210 [2:39:53<1:20:41, 57.64s/it]\u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 127/210 [2:40:03<59:52, 43.29s/it]  \u001b[A\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 128/210 [2:43:52<2:15:18, 99.01s/it]\u001b[A\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/210 [2:45:23<2:10:40, 96.79s/it]\u001b[A\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/210 [2:45:34<1:34:28, 70.86s/it]\u001b[A\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 131/210 [2:45:37<1:06:39, 50.62s/it]\u001b[A\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 132/210 [2:45:46<49:32, 38.11s/it]  \u001b[A\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 133/210 [2:45:54<37:21, 29.11s/it]\u001b[A\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 134/210 [2:49:23<1:45:19, 83.15s/it]\u001b[A\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 135/210 [2:49:33<1:16:25, 61.14s/it]\u001b[A\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 136/210 [2:49:36<53:50, 43.66s/it]  \u001b[A\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 137/210 [2:49:39<38:17, 31.47s/it]\u001b[A\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 138/210 [2:50:06<36:00, 30.01s/it]\u001b[A\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 139/210 [2:50:38<36:28, 30.82s/it]\u001b[A\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 140/210 [2:51:08<35:32, 30.47s/it]\u001b[A\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 141/210 [2:51:37<34:38, 30.12s/it]\u001b[A\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 142/210 [2:52:26<40:21, 35.60s/it]\u001b[A\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 143/210 [2:52:29<28:55, 25.91s/it]\u001b[A\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 144/210 [2:52:59<29:46, 27.07s/it]\u001b[A\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 145/210 [2:53:49<36:53, 34.05s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 146/210 [2:54:17<34:22, 32.22s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 147/210 [2:54:43<31:49, 30.31s/it]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 148/210 [2:55:51<43:08, 41.76s/it]\u001b[A\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 149/210 [2:57:20<56:50, 55.90s/it]\u001b[A\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/210 [2:57:50<48:00, 48.02s/it]\u001b[A\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 151/210 [2:58:20<41:59, 42.71s/it]\u001b[A\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 152/210 [2:59:10<43:14, 44.73s/it]\u001b[A\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 153/210 [2:59:46<40:07, 42.24s/it]\u001b[A\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 154/210 [3:11:34<3:45:47, 241.91s/it]\u001b[A\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 155/210 [3:12:19<2:47:46, 183.03s/it]\u001b[A\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 156/210 [3:12:46<2:02:29, 136.11s/it]\u001b[A\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 157/210 [3:13:15<1:31:45, 103.88s/it]\u001b[A\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 158/210 [3:14:18<1:19:32, 91.78s/it] \u001b[A\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 159/210 [3:15:44<1:16:26, 89.94s/it]\u001b[A\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 160/210 [3:16:12<59:32, 71.44s/it]  \u001b[A\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 161/210 [3:16:42<48:03, 58.84s/it]\u001b[A\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 162/210 [3:17:35<45:40, 57.09s/it]\u001b[A\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 163/210 [3:18:06<38:41, 49.39s/it]\u001b[A\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 164/210 [3:18:35<33:13, 43.33s/it]\u001b[A\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 165/210 [3:19:25<33:49, 45.11s/it]\u001b[A\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 166/210 [3:19:50<28:51, 39.35s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 167/210 [3:20:16<25:08, 35.08s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 168/210 [3:21:24<31:28, 44.96s/it]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 169/210 [3:22:54<40:05, 58.67s/it]\u001b[A\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 170/210 [3:23:25<33:30, 50.26s/it]\u001b[A\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 171/210 [3:23:53<28:22, 43.65s/it]\u001b[A\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 172/210 [3:24:37<27:47, 43.88s/it]\u001b[A\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 173/210 [3:25:08<24:37, 39.94s/it]\u001b[A\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 174/210 [3:36:27<2:18:59, 231.64s/it]\u001b[A\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 175/210 [3:37:05<1:41:10, 173.43s/it]\u001b[A\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 176/210 [3:37:13<1:10:08, 123.78s/it]\u001b[A\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 177/210 [3:37:38<51:47, 94.17s/it]   \u001b[A\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 178/210 [3:37:47<36:37, 68.66s/it]\u001b[A\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 179/210 [3:38:56<35:32, 68.79s/it]\u001b[A\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 180/210 [3:39:16<27:02, 54.09s/it]\u001b[A\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 181/210 [3:39:35<21:08, 43.73s/it]\u001b[A\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 182/210 [3:39:53<16:41, 35.76s/it]\u001b[A\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 183/210 [3:40:28<16:06, 35.81s/it]\u001b[A\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 184/210 [3:40:29<10:54, 25.17s/it]\u001b[A\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 185/210 [3:41:17<13:20, 32.02s/it]\u001b[A\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 186/210 [3:41:46<12:27, 31.16s/it]\u001b[A\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 187/210 [3:42:14<11:32, 30.09s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 188/210 [3:43:01<12:57, 35.35s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 189/210 [3:44:06<15:31, 44.34s/it]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 190/210 [3:44:37<13:23, 40.19s/it]\u001b[A\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 191/210 [3:45:07<11:47, 37.22s/it]\u001b[A\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 192/210 [3:45:59<12:25, 41.44s/it]\u001b[A\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 193/210 [3:46:33<11:08, 39.32s/it]\u001b[A\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 194/210 [3:55:18<49:18, 184.91s/it]\u001b[A\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 195/210 [3:56:07<36:05, 144.39s/it]\u001b[A\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 196/210 [3:56:35<25:30, 109.33s/it]\u001b[A\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 197/210 [3:57:03<18:23, 84.88s/it] \u001b[A\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 198/210 [3:58:08<15:47, 78.95s/it]\u001b[A\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 199/210 [3:59:45<15:30, 84.55s/it]\u001b[A\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 200/210 [4:00:13<11:13, 67.33s/it]\u001b[A\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 201/210 [4:00:40<08:17, 55.31s/it]\u001b[A\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 202/210 [4:01:14<06:30, 48.81s/it]\u001b[A\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 203/210 [4:01:43<05:01, 43.12s/it]\u001b[A\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 204/210 [4:07:13<12:53, 129.00s/it]\u001b[A\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 205/210 [4:07:45<08:20, 100.09s/it]\u001b[A\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 206/210 [4:07:59<04:57, 74.28s/it] \u001b[A\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 207/210 [4:08:18<02:52, 57.61s/it]\u001b[A\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 208/210 [4:08:37<01:31, 45.83s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 209/210 [4:08:55<00:37, 37.48s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 210/210 [4:09:33<00:00, 71.30s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp1.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp1.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nnYJCXfWsMjY",
        "outputId": "44d5e13a-5de2-43b2-df02-0ddc0b1bf4a1"
      },
      "id": "nnYJCXfWsMjY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_52ed133b-8ea6-4592-8954-6738e485fa48\", \"exp1.pkl\", 3432959)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, after trainign 180 models with different parameters, we can see that the `GradientBoostingClassifier` had an outstanding performance in comparison to the other models. We'll take the results of a 73.46% mean F1-score and 1.7% std in the K-Fold validation as our baseline for future comparisons."
      ],
      "metadata": {
        "id": "0uZwZBTf8Qv-"
      },
      "id": "0uZwZBTf8Qv-"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "DwWKw3k6UVqB",
        "outputId": "710f3cf9-7e88-4e4d-d1bd-e843072cf81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "id": "DwWKw3k6UVqB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "94   GradientBoostingClassifier      Count             ADASYN       0.699298   \n",
              "104  GradientBoostingClassifier      Count  RandomOversampler       0.694333   \n",
              "74   GradientBoostingClassifier      Count              SMOTE       0.693347   \n",
              "84   GradientBoostingClassifier      Count   Borderline-SMOTE       0.688407   \n",
              "54   GradientBoostingClassifier      TFIDF        SMOTE-Tomek       0.677515   \n",
              "124  GradientBoostingClassifier      Count        SMOTE-Tomek       0.680500   \n",
              "34   GradientBoostingClassifier      TFIDF  RandomOversampler       0.677486   \n",
              "64   GradientBoostingClassifier      TFIDF             NoSamp       0.679496   \n",
              "24   GradientBoostingClassifier      TFIDF             ADASYN       0.673555   \n",
              "134  GradientBoostingClassifier      Count             NoSamp       0.680491   \n",
              "\n",
              "     Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "94       0.009880     0.699298    0.009880        0.693292       0.009541   \n",
              "104      0.019053     0.694333    0.019053        0.705052       0.017707   \n",
              "74       0.023312     0.693347    0.023312        0.698465       0.015648   \n",
              "84       0.021736     0.688407    0.021736        0.684475       0.023663   \n",
              "54       0.032724     0.677515    0.032724        0.708091       0.018617   \n",
              "124      0.015156     0.680500    0.015156        0.681979       0.012754   \n",
              "34       0.034528     0.677486    0.034528        0.686205       0.026626   \n",
              "64       0.027137     0.679496    0.027137        0.691487       0.023965   \n",
              "24       0.022593     0.673555    0.022593        0.697297       0.016998   \n",
              "134      0.018784     0.680491    0.018784        0.689769       0.025222   \n",
              "\n",
              "      F1 Mean    F1 Std  \n",
              "94   0.691044  0.009947  \n",
              "104  0.689394  0.018435  \n",
              "74   0.687498  0.021960  \n",
              "84   0.680387  0.022421  \n",
              "54   0.677958  0.028411  \n",
              "124  0.675060  0.014813  \n",
              "34   0.674007  0.031581  \n",
              "64   0.671905  0.024160  \n",
              "24   0.671654  0.016708  \n",
              "134  0.669836  0.018454  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.699298</td>\n",
              "      <td>0.009880</td>\n",
              "      <td>0.699298</td>\n",
              "      <td>0.009880</td>\n",
              "      <td>0.693292</td>\n",
              "      <td>0.009541</td>\n",
              "      <td>0.691044</td>\n",
              "      <td>0.009947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.705052</td>\n",
              "      <td>0.017707</td>\n",
              "      <td>0.689394</td>\n",
              "      <td>0.018435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.693347</td>\n",
              "      <td>0.023312</td>\n",
              "      <td>0.693347</td>\n",
              "      <td>0.023312</td>\n",
              "      <td>0.698465</td>\n",
              "      <td>0.015648</td>\n",
              "      <td>0.687498</td>\n",
              "      <td>0.021960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.688407</td>\n",
              "      <td>0.021736</td>\n",
              "      <td>0.688407</td>\n",
              "      <td>0.021736</td>\n",
              "      <td>0.684475</td>\n",
              "      <td>0.023663</td>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.022421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.032724</td>\n",
              "      <td>0.677515</td>\n",
              "      <td>0.032724</td>\n",
              "      <td>0.708091</td>\n",
              "      <td>0.018617</td>\n",
              "      <td>0.677958</td>\n",
              "      <td>0.028411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.015156</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.015156</td>\n",
              "      <td>0.681979</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>0.675060</td>\n",
              "      <td>0.014813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.677486</td>\n",
              "      <td>0.034528</td>\n",
              "      <td>0.677486</td>\n",
              "      <td>0.034528</td>\n",
              "      <td>0.686205</td>\n",
              "      <td>0.026626</td>\n",
              "      <td>0.674007</td>\n",
              "      <td>0.031581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.679496</td>\n",
              "      <td>0.027137</td>\n",
              "      <td>0.679496</td>\n",
              "      <td>0.027137</td>\n",
              "      <td>0.691487</td>\n",
              "      <td>0.023965</td>\n",
              "      <td>0.671905</td>\n",
              "      <td>0.024160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.673555</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.673555</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.697297</td>\n",
              "      <td>0.016998</td>\n",
              "      <td>0.671654</td>\n",
              "      <td>0.016708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.680491</td>\n",
              "      <td>0.018784</td>\n",
              "      <td>0.680491</td>\n",
              "      <td>0.018784</td>\n",
              "      <td>0.689769</td>\n",
              "      <td>0.025222</td>\n",
              "      <td>0.669836</td>\n",
              "      <td>0.018454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac503c95-3ed6-4689-be36-0a6c56fe7a5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83c6387d-03ec-4642-96c1-1ce836d9f79e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83c6387d-03ec-4642-96c1-1ce836d9f79e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83c6387d-03ec-4642-96c1-1ce836d9f79e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"ADASYN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008718023804336845,\n        \"min\": 0.6735550894990978,\n        \"max\": 0.6992976637565234,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735550894990978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007533888121982147,\n        \"min\": 0.00987965098702527,\n        \"max\": 0.03452770497976163,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.022592547630823866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008718023804336845,\n        \"min\": 0.6735550894990978,\n        \"max\": 0.6992976637565234,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735550894990978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007533888121982147,\n        \"min\": 0.00987965098702527,\n        \"max\": 0.03452770497976163,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.022592547630823866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008632778629395467,\n        \"min\": 0.6819785350143458,\n        \"max\": 0.7080914142615653,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6972972589833883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0056642362176959945,\n        \"min\": 0.009540814487384995,\n        \"max\": 0.026625564094362193,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0169983066383649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007866143527520535,\n        \"min\": 0.669836055763601,\n        \"max\": 0.6910439143921288,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6716540110754181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006418536526410559,\n        \"min\": 0.009947033990819459,\n        \"max\": 0.03158140601409704,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0167084519863505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "h5ZsapdFUWGY",
        "outputId": "8688f73b-b5d4-4a98-c4ea-b14419098958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h5ZsapdFUWGY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [4:26:26<00:00, 3197.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None the less, using the 180 models to build an ensemble model did not improve the results of the F1 score, since it only achieved a 69.53% mean F1-score with 2.11% of std."
      ],
      "metadata": {
        "id": "cPRerlPW8fhe"
      },
      "id": "cPRerlPW8fhe"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "NBkQcsuUUY1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "dae3ec40-f2d4-4337-c2ad-4caf83205eed"
      },
      "id": "NBkQcsuUUY1h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple      0.675574     0.019847    0.675574   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.019847       0.676288      0.019961  0.667454  0.018378  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fafffc7-06d8-41b3-8821-e3290335194f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.675574</td>\n",
              "      <td>0.019847</td>\n",
              "      <td>0.675574</td>\n",
              "      <td>0.019847</td>\n",
              "      <td>0.676288</td>\n",
              "      <td>0.019961</td>\n",
              "      <td>0.667454</td>\n",
              "      <td>0.018378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fafffc7-06d8-41b3-8821-e3290335194f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fafffc7-06d8-41b3-8821-e3290335194f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fafffc7-06d8-41b3-8821-e3290335194f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f1ec16aa-4d03-407f-ba57-3970aef99e36\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1ec16aa-4d03-407f-ba57-3970aef99e36 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6755743061990928,\n        \"max\": 0.6755743061990928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6755743061990928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019846856091082086,\n        \"max\": 0.019846856091082086,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019846856091082086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6755743061990928,\n        \"max\": 0.6755743061990928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6755743061990928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019846856091082086,\n        \"max\": 0.019846856091082086,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019846856091082086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.676288026479922,\n        \"max\": 0.676288026479922,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.676288026479922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019961168147456174,\n        \"max\": 0.019961168147456174,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.019961168147456174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6674541593719706,\n        \"max\": 0.6674541593719706,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6674541593719706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0183776098684052,\n        \"max\": 0.0183776098684052,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0183776098684052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Representation A: Keep only the events that occur less than 85% of the time\n",
        "We took the paper provided by SCNB as inspiration to filter out some inherent noise that could affect the results of the previous experiment."
      ],
      "metadata": {
        "id": "buth96_X8LJe"
      },
      "id": "buth96_X8LJe"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_a(df)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "_aqzrdn9ukm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d8d099-46b9-4786-f583-898b207d74a7"
      },
      "id": "_aqzrdn9ukm_",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 210/210 [3:00:22<00:00, 51.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp2.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp2.pkl')"
      ],
      "metadata": {
        "id": "r3Z6xbDwn3QA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "73676113-0ac0-4a2c-c654-47facda07d2e"
      },
      "id": "r3Z6xbDwn3QA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3e74f71-376e-4aa9-bddb-61959f101948\", \"exp2.pkl\", 689091)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the following table we can see that filtering out the noise negatively impacted the model, since this time we achieved a 3 percentag points lower mean F1-score than our base line, i.e. 70.65% with an almost 3x greater standar deviation."
      ],
      "metadata": {
        "id": "stKf5SUS-B0N"
      },
      "id": "stKf5SUS-B0N"
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "vJRyX1Ef2S00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "e24197a9-bbbf-43e8-aaec-5ad109f497d5"
      },
      "id": "vJRyX1Ef2S00",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Model Vectorizer            Sampler  Accuracy Mean  \\\n",
              "104  GradientBoostingClassifier      Count  RandomOversampler       0.692362   \n",
              "4    GradientBoostingClassifier      TFIDF              SMOTE       0.677564   \n",
              "134  GradientBoostingClassifier      Count             NoSamp       0.685451   \n",
              "74   GradientBoostingClassifier      Count              SMOTE       0.678501   \n",
              "9                       XGBoost      TFIDF              SMOTE       0.679564   \n",
              "94   GradientBoostingClassifier      Count             ADASYN       0.678520   \n",
              "59                      XGBoost      TFIDF        SMOTE-Tomek       0.676564   \n",
              "84   GradientBoostingClassifier      Count   Borderline-SMOTE       0.675545   \n",
              "124  GradientBoostingClassifier      Count        SMOTE-Tomek       0.673599   \n",
              "64   GradientBoostingClassifier      TFIDF             NoSamp       0.676569   \n",
              "\n",
              "     Accuracy Std  Recall Mean  Recall Std  Precision Mean  Precision Std  \\\n",
              "104      0.015539     0.692362    0.015539        0.713046       0.015279   \n",
              "4        0.026962     0.677564    0.026962        0.704565       0.021570   \n",
              "134      0.010444     0.685451    0.010444        0.701284       0.012506   \n",
              "74       0.023227     0.678501    0.023227        0.680099       0.023338   \n",
              "9        0.029786     0.679564    0.029786        0.676154       0.037139   \n",
              "94       0.020992     0.678520    0.020992        0.674466       0.023335   \n",
              "59       0.022819     0.676564    0.022819        0.679385       0.027989   \n",
              "84       0.015661     0.675545    0.015661        0.679817       0.011690   \n",
              "124      0.011871     0.673599    0.011871        0.681708       0.008188   \n",
              "64       0.028997     0.676569    0.028997        0.689269       0.031692   \n",
              "\n",
              "      F1 Mean    F1 Std  \n",
              "104  0.689194  0.014109  \n",
              "4    0.677456  0.025040  \n",
              "134  0.675476  0.008441  \n",
              "74   0.672320  0.023137  \n",
              "9    0.670813  0.030060  \n",
              "94   0.670713  0.021415  \n",
              "59   0.669826  0.022084  \n",
              "84   0.669716  0.014653  \n",
              "124  0.668974  0.013821  \n",
              "64   0.667489  0.029637  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c80da962-6fb2-4986-8d0e-41e384f24a85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>RandomOversampler</td>\n",
              "      <td>0.692362</td>\n",
              "      <td>0.015539</td>\n",
              "      <td>0.692362</td>\n",
              "      <td>0.015539</td>\n",
              "      <td>0.713046</td>\n",
              "      <td>0.015279</td>\n",
              "      <td>0.689194</td>\n",
              "      <td>0.014109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.677564</td>\n",
              "      <td>0.026962</td>\n",
              "      <td>0.677564</td>\n",
              "      <td>0.026962</td>\n",
              "      <td>0.704565</td>\n",
              "      <td>0.021570</td>\n",
              "      <td>0.677456</td>\n",
              "      <td>0.025040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.685451</td>\n",
              "      <td>0.010444</td>\n",
              "      <td>0.685451</td>\n",
              "      <td>0.010444</td>\n",
              "      <td>0.701284</td>\n",
              "      <td>0.012506</td>\n",
              "      <td>0.675476</td>\n",
              "      <td>0.008441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.678501</td>\n",
              "      <td>0.023227</td>\n",
              "      <td>0.678501</td>\n",
              "      <td>0.023227</td>\n",
              "      <td>0.680099</td>\n",
              "      <td>0.023338</td>\n",
              "      <td>0.672320</td>\n",
              "      <td>0.023137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE</td>\n",
              "      <td>0.679564</td>\n",
              "      <td>0.029786</td>\n",
              "      <td>0.679564</td>\n",
              "      <td>0.029786</td>\n",
              "      <td>0.676154</td>\n",
              "      <td>0.037139</td>\n",
              "      <td>0.670813</td>\n",
              "      <td>0.030060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>ADASYN</td>\n",
              "      <td>0.678520</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.678520</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.674466</td>\n",
              "      <td>0.023335</td>\n",
              "      <td>0.670713</td>\n",
              "      <td>0.021415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.679385</td>\n",
              "      <td>0.027989</td>\n",
              "      <td>0.669826</td>\n",
              "      <td>0.022084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>Borderline-SMOTE</td>\n",
              "      <td>0.675545</td>\n",
              "      <td>0.015661</td>\n",
              "      <td>0.675545</td>\n",
              "      <td>0.015661</td>\n",
              "      <td>0.679817</td>\n",
              "      <td>0.011690</td>\n",
              "      <td>0.669716</td>\n",
              "      <td>0.014653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>Count</td>\n",
              "      <td>SMOTE-Tomek</td>\n",
              "      <td>0.673599</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.673599</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.681708</td>\n",
              "      <td>0.008188</td>\n",
              "      <td>0.668974</td>\n",
              "      <td>0.013821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>NoSamp</td>\n",
              "      <td>0.676569</td>\n",
              "      <td>0.028997</td>\n",
              "      <td>0.676569</td>\n",
              "      <td>0.028997</td>\n",
              "      <td>0.689269</td>\n",
              "      <td>0.031692</td>\n",
              "      <td>0.667489</td>\n",
              "      <td>0.029637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c80da962-6fb2-4986-8d0e-41e384f24a85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c80da962-6fb2-4986-8d0e-41e384f24a85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c80da962-6fb2-4986-8d0e-41e384f24a85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-480ce585-0e21-4fc1-8fb9-3212b527ab90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-480ce585-0e21-4fc1-8fb9-3212b527ab90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-480ce585-0e21-4fc1-8fb9-3212b527ab90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"XGBoost\",\n          \"GradientBoostingClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TFIDF\",\n          \"Count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RandomOversampler\",\n          \"SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005519352039372778,\n        \"min\": 0.6735989855143151,\n        \"max\": 0.6923620933521925,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735989855143151,\n          0.6775642588889432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069657189326862235,\n        \"min\": 0.010443541729230555,\n        \"max\": 0.029785851049938618,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01187084230264346,\n          0.026961722730560852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005519352039372778,\n        \"min\": 0.6735989855143151,\n        \"max\": 0.6923620933521925,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6735989855143151,\n          0.6775642588889432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069657189326862235,\n        \"min\": 0.010443541729230555,\n        \"max\": 0.029785851049938618,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.01187084230264346,\n          0.026961722730560852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013525709401644402,\n        \"min\": 0.6744655315633677,\n        \"max\": 0.7130464872749165,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.681708156357779,\n          0.7045650650043218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009368102952934727,\n        \"min\": 0.008188026193425122,\n        \"max\": 0.03713883755484578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.008188026193425122,\n          0.02156968703496574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006374818771861471,\n        \"min\": 0.6674892832876439,\n        \"max\": 0.6891937311417309,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6689739460552422,\n          0.6774558687531858\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0072278786108977335,\n        \"min\": 0.008441444307940946,\n        \"max\": 0.030060373708929743,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.013820769427991299,\n          0.02503964919473056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "iiBWV2LYwC0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c7f16e-964b-43d9-ffae-cdd2e5b0077d"
      },
      "id": "iiBWV2LYwC0k",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing folds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [3:07:44<00:00, 2252.97s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we built an ensemble model to test if we could achieve a better mean F1-score. Unlike the 1st experiment, we achieced a mea F1-score 2 percentage points greater than the ensemble of the 1st experiment. Nonetheless, it was not enought to outperform the baseline model and also it had a slightly greater standard deviation."
      ],
      "metadata": {
        "id": "gLJiO0G7-iJr"
      },
      "id": "gLJiO0G7-iJr"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "ulsxTrri2UsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6c8a49a9-1928-4cf0-b4c5-4984f87cd58a"
      },
      "id": "ulsxTrri2UsF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model Vectorizer   Sampler Accuracy Mean Accuracy Std Recall Mean  \\\n",
              "0  Ensemble   Multiple  Multiple      0.684485     0.009068    0.684485   \n",
              "\n",
              "  Recall Std Precision Mean Precision Std   F1 Mean    F1 Std  \n",
              "0   0.009068       0.671497       0.02027  0.669622  0.013434  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad597886-d9aa-4695-aa60-a93e4bda9824\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Sampler</th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>F1 Mean</th>\n",
              "      <th>F1 Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>Multiple</td>\n",
              "      <td>0.684485</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>0.684485</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>0.671497</td>\n",
              "      <td>0.02027</td>\n",
              "      <td>0.669622</td>\n",
              "      <td>0.013434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad597886-d9aa-4695-aa60-a93e4bda9824')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad597886-d9aa-4695-aa60-a93e4bda9824 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad597886-d9aa-4695-aa60-a93e4bda9824');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c17e3800-5bc8-4ad2-ae79-aa77665e2483\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ensemble_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c17e3800-5bc8-4ad2-ae79-aa77665e2483 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ensemble_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble_results",
              "summary": "{\n  \"name\": \"ensemble_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ensemble\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vectorizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sampler\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Multiple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6844851972882017,\n        \"max\": 0.6844851972882017,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6844851972882017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.009067607265627584,\n        \"max\": 0.009067607265627584,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.009067607265627584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6844851972882017,\n        \"max\": 0.6844851972882017,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6844851972882017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.009067607265627584,\n        \"max\": 0.009067607265627584,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.009067607265627584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6714970825116477,\n        \"max\": 0.6714970825116477,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6714970825116477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0202704073322489,\n        \"max\": 0.0202704073322489,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0202704073322489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.6696223467346046,\n        \"max\": 0.6696223467346046,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6696223467346046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.013433611988409247,\n        \"max\": 0.013433611988409247,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.013433611988409247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation B: Split events into those before and after the incident"
      ],
      "metadata": {
        "id": "MuLCNXm59Wcd"
      },
      "id": "MuLCNXm59Wcd"
    },
    {
      "cell_type": "code",
      "source": [
        "df_before, df_after = Representations(df).representation_b(df)\n",
        "X, y = pd.concat([df_before.events_sequence, df_after.events_sequence]), pd.concat([df_before['class'], df_after['class']])\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "razuBz2VOucS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362ddde5-c693-46c4-f1ca-b96fffa2e0a1"
      },
      "id": "razuBz2VOucS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|â–ˆâ–ˆâ–Š       | 58/210 [6:45:29<33:44:54, 799.31s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('exp3.pkl', 'wb') as f:\n",
        "    pickle.dump(exp, f)\n",
        "files.download('exp3.pkl')"
      ],
      "metadata": {
        "id": "T0CkuDvsIWPk"
      },
      "id": "T0CkuDvsIWPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "eVEC5TGedBmj"
      },
      "id": "eVEC5TGedBmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "dVbpIzWPHctr"
      },
      "id": "dVbpIzWPHctr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "AkbQGcBtHfDi"
      },
      "id": "AkbQGcBtHfDi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representation C: Generates fixed length overlappng and non-overlaping sequences out of the provided sequences"
      ],
      "metadata": {
        "id": "aseee5o49YQk"
      },
      "id": "aseee5o49YQk"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = Representations(df).representation_c(df, sequence_length=100)\n",
        "exp = Experiment(X, y)\n",
        "results = exp.training()"
      ],
      "metadata": {
        "id": "A7frHCFPeHhB"
      },
      "id": "A7frHCFPeHhB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=['F1 Mean', \"F1 Std\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "ebD6mRosHlvl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ebD6mRosHlvl"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results = pd.DataFrame(exp.test_ensemble()).T\n",
        "ensemble_results.columns = [\"Model\",\"Vectorizer\",\"Sampler\",\"Accuracy Mean\",\"Accuracy Std\",\"Recall Mean\",\"Recall Std\",\"Precision Mean\",\"Precision Std\",\"F1 Mean\",\"F1 Std\"]"
      ],
      "metadata": {
        "id": "rpIj_0FDHlvm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rpIj_0FDHlvm"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results"
      ],
      "metadata": {
        "id": "fXlUulj9Hlvn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fXlUulj9Hlvn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "7Vk_xyb-G2Pm"
      },
      "id": "7Vk_xyb-G2Pm"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NRhYv80u-4_"
      },
      "id": "5NRhYv80u-4_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}